{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "953491e7",
   "metadata": {},
   "source": [
    "# Author: Tim Harmling\n",
    "- **Description:** Creates a Dataset that can be used from our Handwriting Model with *.jpg and *.txt files. The *.txt files contain the text of the handwritten text in the image. The *.jpg files contain the cropped images of the handwritten text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83f47b37997236a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cd42883ee81fb9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from builtins import print\n",
    "\n",
    "import tensorflow as tf\n",
    "# import keras_cv\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from tensorflow import keras\n",
    "#from keras_cv import bounding_box\n",
    "#from keras_cv import visualization\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.models import Sequential, model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "from keras.callbacks import EarlyStopping\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b42bc920771a3c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "he = 0\n",
    "print(bool(he))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de25d596d2429a23",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"../data_zettel/Annotations\"\n",
    "\n",
    "# Get all XML file paths in path_annot and sort them\n",
    "xml_files = sorted(\n",
    "    [\n",
    "        os.path.join(path, file_name)\n",
    "        for file_name in os.listdir(path)\n",
    "        if file_name.endswith(\".xml\")\n",
    "    ]\n",
    ")\n",
    " \n",
    "# Get all JPEG image file paths in path_images and sort them\n",
    "jpg_files = sorted(\n",
    "    [\n",
    "        os.path.join(path, file_name)\n",
    "        for file_name in os.listdir(path)\n",
    "        if file_name.endswith(\".jpg\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec2c06c5208d6f5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_box(bbox):\n",
    "    xmin = float(bbox.find(\"xmin\").text)\n",
    "    ymin = float(bbox.find(\"ymin\").text)\n",
    "    xmax = float(bbox.find(\"xmax\").text)\n",
    "    ymax = float(bbox.find(\"ymax\").text)\n",
    "    return [xmin, ymin, xmax, ymax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2298a2e644551a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_annotation_fake(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    image_name = root.find(\"filename\").text\n",
    "    image_path = f'../data_zettel/filled_resized/{image_name}'\n",
    "\n",
    "    boxes = []\n",
    "    classes = []\n",
    "    main_classes = []\n",
    "    sub_classes = []\n",
    "    main_boxes = []\n",
    "    sub_boxes = []\n",
    "    values = []\n",
    "    \n",
    "    for obj in root.iter(\"object\"):\n",
    "        cls = obj.find(\"name\").text\n",
    "        classes.append(cls)\n",
    "        \n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        boxes.append(create_box(bbox))\n",
    "        \n",
    "        # main labels\n",
    "        if (cls == 'Wohnsitz_waehrend_Ausbildung') or (cls == 'Ausbildung') or (cls == 'Person') or (cls == 'Wohnsitz'):\n",
    "            main_classes.append(cls)\n",
    "            bbox = obj.find(\"bndbox\")\n",
    "            main_boxes.append(create_box(bbox))\n",
    "        else:\n",
    "            attributes = obj.findall(\"attributes/attribute\")\n",
    "            for attribute in attributes:\n",
    "                value_element = attribute.find(\"value\")\n",
    "                value = value_element.text\n",
    "                if value is None:\n",
    "                    continue\n",
    "                elif value is None or value.lower() in [\"true\", \"false\"]:\n",
    "                    continue\n",
    "                \n",
    "                # Versuche, den Wert in einen Float zu konvertieren\n",
    "                try:\n",
    "                    float_value = float(value)\n",
    "                    int_value = int(float_value)\n",
    "                    values.append(str(int_value))  # Hier wird der Integer in einen String umgewandelt\n",
    "                except ValueError:\n",
    "                    # Wenn die Konvertierung fehlschlägt, füge den originalen Wert zur Liste hinzu\n",
    "                    values.append(value)\n",
    "                break\n",
    "            \n",
    "            bbox = obj.find(\"bndbox\")\n",
    "            sub_boxes.append(create_box(bbox))\n",
    "            sub_classes.append(cls)\n",
    "    return image_path,main_boxes,main_classes,values, sub_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44b0a934b7186a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bounding_box.model import load_weight_model, predict_image,plot_image, get_templated_data, edit_sub_boxes_cut_links, edit_sub_boxes_cut_top\n",
    "from bounding_box.template import build_templating_data\n",
    "org_ms_boxes_person, org_ms_boxes_wohnsitz, org_ms_boxes_ausbildung, org_ms_boxes_wwa, person_class_ids, ausbildung_class_ids, wohnsitz_class_ids, wwa_class_ids, widthOrgImag, heightOrgImag = build_templating_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66a646b3a4297da",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bounding_box.model import load_weight_model, predict_image,plot_image, get_templated_data, edit_sub_boxes_cut_links, edit_sub_boxes_cut_top\n",
    "from bounding_box.template import build_templating_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e876bac39505990b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sort_box_to_class(sub_boxes, sub_classes_numbers, sub_classes_string, values):\n",
    "    new_sub_boxes = []\n",
    "    new_values = []\n",
    "    new_sub_box_classes = []\n",
    "    new_sub_box_number = []\n",
    "    cls_values = [8, 5, 3, 4,\n",
    "                  14, 16, 17, 9, 11, 18, 19, 20,\n",
    "                  22, 25, 26, 23, 24, 27, 28, 29, 33, 30, 31,  34]\n",
    "    comment_strings = [\n",
    "        \"Ausbildung_Staette\",\n",
    "        \"Ausbilung_Abschluss\",\n",
    "        \"Ausbildung_Amt\",\n",
    "        \"Ausbildung_Foerderungsnummer\",\n",
    "        \n",
    "        \"Person_Name\",\n",
    "        \"Person_Vorname\",\n",
    "        \"Person_Geburtsname\",\n",
    "        \"Person_Geburtsort\",\n",
    "        \"Person_Geburtsdatum\",\n",
    "        \"Person_Familienstand_seit\",\n",
    "        \"Person_Stattsangehörigkeit_eigene\",\n",
    "        \"Person_Kinder\",\n",
    "        \n",
    "        \"Wohnsitz_Strasse\",\n",
    "        \"Wohnsitz_Hausnummer\",\n",
    "        \"Wohnsitz_Adresszusatz\",\n",
    "        \"Wohnsitz_Land\",\n",
    "        \"Wohnsitz_Postleitzahl\",\n",
    "        \"Wohnsitz_Ort\",\n",
    "        \n",
    "        \"Wohnsitz_waehrend_Ausbildung_Strasse\",\n",
    "        \"Wohnsitz_waehrend_Ausbildung_Hausnummer\",\n",
    "        \"Wohnsitz_waehrend_Ausbildung_Adresszusatz\",\n",
    "        \"Wohnsitz_waehrend_Ausbildung_Land\",\n",
    "        \"Wohnsitz_waehrend_Ausbildung_Postleitzahl\",\n",
    "        \"Wohnsitz_waehrend_Ausbildung_ort\"\n",
    "    ]\n",
    "    for j,class_string in enumerate(sub_classes_string):\n",
    "        for i, comment_string in enumerate(comment_strings):\n",
    "            if class_string == comment_string:\n",
    "                for x, sub_class_number in enumerate(sub_classes_numbers):\n",
    "                    if cls_values[i] == sub_class_number:\n",
    "                        new_sub_class_number = cls_values[i]\n",
    "                        new_sub_box = sub_boxes[x]\n",
    "                        \n",
    "                        value = values[j]\n",
    "                        new_sub_class_string = class_string\n",
    "                        \n",
    "                        new_sub_box_number.append(new_sub_class_number)\n",
    "                        new_sub_boxes.append(new_sub_box)\n",
    "                        new_values.append(value)\n",
    "                        new_sub_box_classes.append(new_sub_class_string)\n",
    "        \n",
    "    return new_sub_boxes, new_values, new_sub_box_classes, new_sub_box_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4955cb22409e20f3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from bounding_box.template import get_for_main_bbox_sub_bboxes\n",
    "ImageInfo = namedtuple('ImageInfo', ['path', 'boxes', 'values', 'classes','numbers'])\n",
    "image_list = []\n",
    "for xml_file in tqdm(xml_files): \n",
    "    image_path, main_boxes, main_classes,values, sub_classes = parse_annotation_fake(xml_file)\n",
    "    # confidence = [[0.9, 0.9, 1, 1]]\n",
    "    # main_classes = [[0,1,2,3]]\n",
    "    # main_boxes = [main_boxes]\n",
    "    import os\n",
    "\n",
    "   \n",
    "    base_name = os.path.basename(xml_file)\n",
    "    file_name, file_extension = os.path.splitext(base_name)\n",
    "    desired_part = file_name.split('_')[-1]\n",
    "    bbox_model = load_weight_model(r\"../bounding_box\\workspace\\models\\main_bbox_detector_model.h5\",4)\n",
    "    image_path = f\"../data_zettel/filled_resized/image_{desired_part}.jpg\"\n",
    "    main_boxes, confidence, classes, ratios = predict_image(image_path, bbox_model)\n",
    "    \n",
    "    ausbildung, person, wohnsitz, wwa, best_predicted = get_templated_data(main_boxes, confidence, classes, org_ms_boxes_person,\n",
    "                                                                       org_ms_boxes_wohnsitz, org_ms_boxes_ausbildung,\n",
    "                                                                       org_ms_boxes_wwa, person_class_ids,\n",
    "                                                                       ausbildung_class_ids, wohnsitz_class_ids,\n",
    "                                                                       wwa_class_ids)\n",
    "    from bounding_box.ressize import scale_up\n",
    "    ausbildung, person, wohnsitz, wwa = edit_sub_boxes_cut_top(ausbildung, person, wohnsitz, wwa)\n",
    "    ausbildung, person, wohnsitz, wwa = scale_up( ausbildung, person, wohnsitz, wwa, ratios)\n",
    "    print(desired_part)\n",
    "    plot_image(image_path, ausbildung, person, wohnsitz, wwa, best_predicted)\n",
    "    \n",
    "    \n",
    "    sub_boxes = ausbildung[0] + person[0] + wohnsitz[0] + wwa[0]\n",
    "    sub_classes_number = ausbildung[1] + person[1] + wohnsitz[1] + wwa[1]\n",
    "    new_sub_boxes, new_values, sub_classes_string, new_sub_box_number = sort_box_to_class(sub_boxes,sub_classes_number,sub_classes,values)\n",
    "    \n",
    "    #sub_boxes = edit_sub_boxes_cut_top(ausbildung, person, wohnsitz, wwa)\n",
    "    #sub_boxes = edit_sub_boxes_cut_links(ausbildung, person, wohnsitz, wwa)\n",
    "    \n",
    "    image = ImageInfo(path=image_path, boxes=new_sub_boxes, values=new_values,classes=sub_classes_string, numbers=new_sub_box_number)\n",
    "    numbers_to_check = [\"31\", \"32\", \"33\", \"35\", \"36\"]\n",
    "    # Check if the string does not contain any of the specified numbers\n",
    "    does_not_contain_numbers = all(number not in image.path for number in numbers_to_check)\n",
    "    \n",
    "    if does_not_contain_numbers:\n",
    "        \n",
    "            image_list.append(image)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73327eb722f2ea",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "### Crop ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8995ce981686184e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(image_list[0].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbc953849a6b899",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Crop ROI\n",
    "save_path_crops = \"../data_zettel/cropped_images\"\n",
    "\n",
    "import cv2\n",
    "def delete_file(file_path):\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "        print(f\"File {file_path} deleted successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_path} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while deleting {file_path}: {e}\")\n",
    "# Crop ROI\n",
    "import cv2\n",
    "from bounding_box.ressize import resize_imaged_without_expand_dim\n",
    "from bounding_box.config import YOLO_WIDTH, YOLO_HEIGHT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb57744d7f7dfbbf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Crop ROI\n",
    "import cv2\n",
    "from bounding_box.ressize import resize_imaged_without_expand_dim\n",
    "from bounding_box.config import YOLO_WIDTH, YOLO_HEIGHT\n",
    "from bounding_box.model import load_weight_model,predict_image,get_image_as_array, show_image \n",
    "from bounding_box.config import NUM_CLASSES_ALL,BBOX_PATH,MAIN_BBOX_DETECTOR_MODEL,SUB_BBOX_DETECTOR_MODEL  \n",
    "from bounding_box.model import load_weight_model, predict_image,plot_image, get_templated_data, edit_sub_boxes_cut_links, edit_sub_boxes_cut_top\n",
    "from bounding_box.template import build_templating_data\n",
    "\n",
    "def crop(xmin, ymin, xmax, ymax, image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = resize_imaged_without_expand_dim(image, YOLO_WIDTH, YOLO_HEIGHT)\n",
    "    xmin = int(round(xmin))\n",
    "    ymin = int(round(ymin))\n",
    "    xmax = int(round(xmax))\n",
    "    ymax = int(round(ymax))\n",
    "    # width = int(round(width))\n",
    "    # height = int(round(height))\n",
    "    # rowBeg = y\n",
    "    # rowEnd = y + height\n",
    "    # columnBeg = x\n",
    "    # columnEnd = x + width\n",
    "    imgCropped = image[ymin:ymax, xmin:xmax]\n",
    "    return imgCropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5882766b025353",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_number(value):\n",
    "    if isinstance(value, (int, float)):\n",
    "        return True\n",
    "    elif isinstance(value, str):\n",
    "        if value.isdigit() or (value.replace('.', '', 1).isdigit()):\n",
    "            return True\n",
    "    return False\n",
    "        \n",
    "for index, image in enumerate(image_list):\n",
    "    boxes = image.boxes\n",
    "    for i, box in enumerate(boxes):\n",
    "        xmin, ymin, xmax, ymax = np.array(box)\n",
    "        imgCropped = crop(xmin, ymin, xmax, ymax, image.path)\n",
    "        if imgCropped is not None:\n",
    "            not_list = [\"0\", \"1\", \"\", None]\n",
    "            not_classes_list = [31]\n",
    "            if image.numbers[i] not in not_classes_list:\n",
    "                if image.values[i] not in not_list and image.values[i] is not None:\n",
    "                    if is_number(image.values[i]):       \n",
    "                        img_file_path = f\"{save_path_crops}/{index}_{i}.jpg\"\n",
    "                        txt_file_path = f\"{save_path_crops}/{index}_{i}.txt\"\n",
    "                        try:\n",
    "                            cv2.imwrite(img_file_path, imgCropped)\n",
    "                            with open(txt_file_path, 'w', encoding='utf-8') as file:\n",
    "                                image.values[i] = image.values[i].replace(\" \", \"|\")\n",
    "                                 \n",
    "                                file.write(image.values[i])\n",
    "                                print(f\"{image.numbers[i]}: {image.classes[i]}: {image.values[i]}\")\n",
    "                        except:\n",
    "                            delete_file(img_file_path)\n",
    "                            delete_file(txt_file_path)\n",
    "                            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
