{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fake Prediction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b83f47b37997236a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from builtins import print\n",
    "\n",
    "import tensorflow as tf\n",
    "# import keras_cv\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from tensorflow import keras\n",
    "#from keras_cv import bounding_box\n",
    "#from keras_cv import visualization\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.models import Sequential, model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "from keras.callbacks import EarlyStopping\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1cd42883ee81fb9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "he = 0\n",
    "print(bool(he))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0b42bc920771a3c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "path = \"../data_zettel/Annotations\"\n",
    "\n",
    "# Get all XML file paths in path_annot and sort them\n",
    "xml_files = sorted(\n",
    "    [\n",
    "        os.path.join(path, file_name)\n",
    "        for file_name in os.listdir(path)\n",
    "        if file_name.endswith(\".xml\")\n",
    "    ]\n",
    ")\n",
    " \n",
    "# Get all JPEG image file paths in path_images and sort them\n",
    "jpg_files = sorted(\n",
    "    [\n",
    "        os.path.join(path, file_name)\n",
    "        for file_name in os.listdir(path)\n",
    "        if file_name.endswith(\".jpg\")\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de25d596d2429a23",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_box(bbox):\n",
    "    xmin = float(bbox.find(\"xmin\").text)\n",
    "    ymin = float(bbox.find(\"ymin\").text)\n",
    "    xmax = float(bbox.find(\"xmax\").text)\n",
    "    ymax = float(bbox.find(\"ymax\").text)\n",
    "    return [xmin, ymin, xmax, ymax]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fec2c06c5208d6f5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2298a2e644551a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_annotation_fake(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    image_name = root.find(\"filename\").text\n",
    "    image_path = f'../data_zettel/filled_resized/{image_name}'\n",
    "\n",
    "    boxes = []\n",
    "    classes = []\n",
    "    main_classes = []\n",
    "    sub_classes = []\n",
    "    main_boxes = []\n",
    "    sub_boxes = []\n",
    "    values = []\n",
    "    \n",
    "    for obj in root.iter(\"object\"):\n",
    "        cls = obj.find(\"name\").text\n",
    "        classes.append(cls)\n",
    "        \n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        boxes.append(create_box(bbox))\n",
    "        \n",
    "        # main labels\n",
    "        if (cls == 'Wohnsitz_waehrend_Ausbildung') or (cls == 'Ausbildung') or (cls == 'Person') or (cls == 'Wohnsitz'):\n",
    "            main_classes.append(cls)\n",
    "            bbox = obj.find(\"bndbox\")\n",
    "            main_boxes.append(create_box(bbox))\n",
    "        else:\n",
    "            attributes = obj.findall(\"attributes/attribute\")\n",
    "            for attribute in attributes:\n",
    "                value_element = attribute.find(\"value\")\n",
    "                value = value_element.text\n",
    "                if value is None:\n",
    "                    continue\n",
    "                elif value is None or value.lower() in [\"true\", \"false\"]:\n",
    "                    continue\n",
    "                \n",
    "                # Versuche, den Wert in einen Float zu konvertieren\n",
    "                try:\n",
    "                    float_value = float(value)\n",
    "                    int_value = int(float_value)\n",
    "                    values.append(str(int_value))  # Hier wird der Integer in einen String umgewandelt\n",
    "                except ValueError:\n",
    "                    # Wenn die Konvertierung fehlschlägt, füge den originalen Wert zur Liste hinzu\n",
    "                    values.append(value)\n",
    "                break\n",
    "            \n",
    "            bbox = obj.find(\"bndbox\")\n",
    "            sub_boxes.append(create_box(bbox))\n",
    "            sub_classes.append(cls)\n",
    "    return image_path,main_boxes,main_classes,values, sub_classes"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from bounding_box.model import load_weight_model, predict_image,plot_image, get_templated_data, edit_sub_boxes_cut_links, edit_sub_boxes_cut_top\n",
    "from bounding_box.template import build_templating_data\n",
    "org_ms_boxes_person, org_ms_boxes_wohnsitz, org_ms_boxes_ausbildung, org_ms_boxes_wwa, person_class_ids, ausbildung_class_ids, wohnsitz_class_ids, wwa_class_ids, widthOrgImag, heightOrgImag = build_templating_data()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e44b0a934b7186a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from bounding_box.model import load_weight_model, predict_image,plot_image, get_templated_data, edit_sub_boxes_cut_links, edit_sub_boxes_cut_top\n",
    "from bounding_box.template import build_templating_data\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f66a646b3a4297da",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def sort_box_to_class(sub_boxes, sub_classes_numbers, sub_classes_string, values):\n",
    "    new_sub_boxes = []\n",
    "    new_values = []\n",
    "    new_sub_box_classes = []\n",
    "    new_sub_box_number = []\n",
    "    cls_values = [8, 5, 3, 4,\n",
    "                  14, 16, 17, 9, 11, 18, 19, 20,\n",
    "                  22, 25, 26, 23, 24, 27, 28, 29, 33, 30, 31,  34]\n",
    "    comment_strings = [\n",
    "        \"Ausbildung_Staette\",\n",
    "        \"Ausbilung_Abschluss\",\n",
    "        \"Ausbildung_Amt\",\n",
    "        \"Ausbildung_Foerderungsnummer\",\n",
    "        \n",
    "        \"Person_Name\",\n",
    "        \"Person_Vorname\",\n",
    "        \"Person_Geburtsname\",\n",
    "        \"Person_Geburtsort\",\n",
    "        \"Person_Geburtsdatum\",\n",
    "        \"Person_Familienstand_seit\",\n",
    "        \"Person_Stattsangehörigkeit_eigene\",\n",
    "        \"Person_Kinder\",\n",
    "        \n",
    "        \"Wohnsitz_Strasse\",\n",
    "        \"Wohnsitz_Hausnummer\",\n",
    "        \"Wohnsitz_Adresszusatz\",\n",
    "        \"Wohnsitz_Land\",\n",
    "        \"Wohnsitz_Postleitzahl\",\n",
    "        \"Wohnsitz_Ort\",\n",
    "        \n",
    "        \"Wohnsitz_waehrend_Ausbildung_Strasse\",\n",
    "        \"Wohnsitz_waehrend_Ausbildung_Hausnummer\",\n",
    "        \"Wohnsitz_waehrend_Ausbildung_Adresszusatz\",\n",
    "        \"Wohnsitz_waehrend_Ausbildung_Land\",\n",
    "        \"Wohnsitz_waehrend_Ausbildung_Postleitzahl\",\n",
    "        \"Wohnsitz_waehrend_Ausbildung_ort\"\n",
    "    ]\n",
    "    for j,class_string in enumerate(sub_classes_string):\n",
    "        for i, comment_string in enumerate(comment_strings):\n",
    "            if class_string == comment_string:\n",
    "                for x, sub_class_number in enumerate(sub_classes_numbers):\n",
    "                    if cls_values[i] == sub_class_number:\n",
    "                        new_sub_class_number = cls_values[i]\n",
    "                        new_sub_box = sub_boxes[x]\n",
    "                        \n",
    "                        value = values[j]\n",
    "                        new_sub_class_string = class_string\n",
    "                        \n",
    "                        new_sub_box_number.append(new_sub_class_number)\n",
    "                        new_sub_boxes.append(new_sub_box)\n",
    "                        new_values.append(value)\n",
    "                        new_sub_box_classes.append(new_sub_class_string)\n",
    "        \n",
    "    return new_sub_boxes, new_values, new_sub_box_classes, new_sub_box_number"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e876bac39505990b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4955cb22409e20f3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from bounding_box.template import get_for_main_bbox_sub_bboxes\n",
    "ImageInfo = namedtuple('ImageInfo', ['path', 'boxes', 'values', 'classes','numbers'])\n",
    "image_list = []\n",
    "for xml_file in tqdm(xml_files): \n",
    "    image_path, main_boxes, main_classes,values, sub_classes = parse_annotation_fake(xml_file)\n",
    "    # confidence = [[0.9, 0.9, 1, 1]]\n",
    "    # main_classes = [[0,1,2,3]]\n",
    "    # main_boxes = [main_boxes]\n",
    "    import os\n",
    "\n",
    "   \n",
    "    base_name = os.path.basename(xml_file)\n",
    "    file_name, file_extension = os.path.splitext(base_name)\n",
    "    desired_part = file_name.split('_')[-1]\n",
    "    bbox_model = load_weight_model(r\"../bounding_box\\workspace\\models\\main_bbox_detector_model.h5\",4)\n",
    "    image_path = f\"../data_zettel/filled_resized/image_{desired_part}.jpg\"\n",
    "    main_boxes, confidence, classes = predict_image(image_path, bbox_model)\n",
    "    \n",
    "    ausbildung, person, wohnsitz, wwa, best_predicted = get_templated_data(main_boxes, confidence, classes, org_ms_boxes_person,\n",
    "                                                                       org_ms_boxes_wohnsitz, org_ms_boxes_ausbildung,\n",
    "                                                                       org_ms_boxes_wwa, person_class_ids,\n",
    "                                                                       ausbildung_class_ids, wohnsitz_class_ids,\n",
    "                                                                       wwa_class_ids)\n",
    "    \n",
    "    ausbildung, person, wohnsitz, wwa = edit_sub_boxes_cut_top(ausbildung, person, wohnsitz, wwa)\n",
    "    \n",
    "    print(desired_part)\n",
    "    plot_image(image_path, ausbildung, person, wohnsitz, wwa, best_predicted)\n",
    "    \n",
    "    \n",
    "    sub_boxes = ausbildung[0] + person[0] + wohnsitz[0] + wwa[0]\n",
    "    sub_classes_number = ausbildung[1] + person[1] + wohnsitz[1] + wwa[1]\n",
    "    new_sub_boxes, new_values, sub_classes_string, new_sub_box_number = sort_box_to_class(sub_boxes,sub_classes_number,sub_classes,values)\n",
    "    \n",
    "    #sub_boxes = edit_sub_boxes_cut_top(ausbildung, person, wohnsitz, wwa)\n",
    "    #sub_boxes = edit_sub_boxes_cut_links(ausbildung, person, wohnsitz, wwa)\n",
    "    \n",
    "    image = ImageInfo(path=image_path, boxes=new_sub_boxes, values=new_values,classes=sub_classes_string, numbers=new_sub_box_number)\n",
    "    numbers_to_check = [\"31\", \"32\", \"33\", \"35\", \"36\"]\n",
    "    # Check if the string does not contain any of the specified numbers\n",
    "    does_not_contain_numbers = all(number not in image.path for number in numbers_to_check)\n",
    "    \n",
    "    if does_not_contain_numbers:\n",
    "        \n",
    "            image_list.append(image)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73327eb722f2ea",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "### Crop ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8995ce981686184e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(image_list[0].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbc953849a6b899",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Crop ROI\n",
    "save_path_crops = \"../data_zettel/cropped_images\"\n",
    "\n",
    "import cv2\n",
    "def delete_file(file_path):\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "        print(f\"File {file_path} deleted successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_path} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while deleting {file_path}: {e}\")\n",
    "# Crop ROI\n",
    "import cv2\n",
    "from bounding_box.ressize import resize_imaged_without_expand_dim\n",
    "from bounding_box.config import YOLO_WIDTH, YOLO_HEIGHT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Crop ROI\n",
    "import cv2\n",
    "from bounding_box.ressize import resize_imaged_without_expand_dim\n",
    "from bounding_box.config import YOLO_WIDTH, YOLO_HEIGHT\n",
    "from bounding_box.model import load_weight_model,predict_image,get_image_as_array, show_image \n",
    "from bounding_box.config import NUM_CLASSES_ALL,BBOX_PATH,MAIN_BBOX_DETECTOR_MODEL,SUB_BBOX_DETECTOR_MODEL  \n",
    "from bounding_box.model import load_weight_model, predict_image,plot_image, get_templated_data, edit_sub_boxes_cut_links, edit_sub_boxes_cut_top\n",
    "from bounding_box.template import build_templating_data\n",
    "\n",
    "def crop(xmin, ymin, xmax, ymax, image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = resize_imaged_without_expand_dim(image, YOLO_WIDTH, YOLO_HEIGHT)\n",
    "    xmin = int(round(xmin))\n",
    "    ymin = int(round(ymin))\n",
    "    xmax = int(round(xmax))\n",
    "    ymax = int(round(ymax))\n",
    "    # width = int(round(width))\n",
    "    # height = int(round(height))\n",
    "    # rowBeg = y\n",
    "    # rowEnd = y + height\n",
    "    # columnBeg = x\n",
    "    # columnEnd = x + width\n",
    "    imgCropped = image[ymin:ymax, xmin:xmax]\n",
    "    return imgCropped\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb57744d7f7dfbbf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "for index, image in enumerate(image_list):\n",
    "    boxes = image.boxes\n",
    "    for i, box in enumerate(boxes):\n",
    "        xmin, ymin, xmax, ymax = np.array(box)\n",
    "        imgCropped = crop(xmin, ymin, xmax, ymax, image.path)\n",
    "        if imgCropped is not None:\n",
    "            not_list = [\"0\", \"1\", \"\", None]\n",
    "            not_classes_list = [31]\n",
    "            if image.numbers[i] not in not_classes_list:\n",
    "                if image.values[i] not in not_list and image.values[i] is not None:\n",
    "                    img_file_path = f\"{save_path_crops}/{index}_{i}.jpg\"\n",
    "                    txt_file_path = f\"{save_path_crops}/{index}_{i}.txt\"\n",
    "                    try:\n",
    "                        cv2.imwrite(img_file_path, imgCropped)\n",
    "                        with open(txt_file_path, 'w', encoding='utf-8') as file:\n",
    "                            image.values[i] = image.values[i].replace(\" \", \"|\")\n",
    "                             \n",
    "                            file.write(image.values[i])\n",
    "                            print(f\"{image.numbers[i]}: {image.classes[i]}: {image.values[i]}\")\n",
    "                    except:\n",
    "                        delete_file(img_file_path)\n",
    "                        delete_file(txt_file_path)\n",
    "                        continue"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e5882766b025353",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fdc51121e5bd01e2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Handwriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617741a46be8f4e3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unsere Klassen\n",
    "#import handwriting.load_data as load_data\n",
    "import handwriting.load_transfer_data as load_transfer_data\n",
    "import handwriting.testing_models as testing_models # Use: build_model9v3(img_width, img_height, char) \n",
    "import utils.configs as cfg\n",
    "#Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d912de093664402a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cafc2f961d6b8d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config_path = \"../utils/configs.json\"\n",
    "\n",
    "config = cfg.Config(config_path)\n",
    "\n",
    "# Pipeline\n",
    "TRANSFER = bool(config.get_pipeline_parameter()[\"transfer\"])\n",
    "\n",
    "# Model Parameter\n",
    "MODEL_SAVE = bool(config.get_model_parameter()[\"save\"])\n",
    "MODEL_NAME = config.get_model_parameter()[\"name\"]\n",
    "IMAGE_WIDTH = config.get_model_parameter()[\"width\"] # default: 1024\n",
    "IMAGE_HEIGHT = config.get_model_parameter()[\"height\"] # default: 128\n",
    "\n",
    "# Directory Parameter\n",
    "MODEL_DIR_NAME = pathlib.Path(os.getcwd()).joinpath(config.get_directory_parameter()[\"model_dir\"])\n",
    "TEST_RESULT_DIR_NAME = pathlib.Path(os.getcwd()).joinpath(config.get_directory_parameter()[\"test_dir\"])\n",
    "DATA_BASE_PATH = config.get_directory_parameter()[\"data_base_path\"]\n",
    "\n",
    "# Training Parameter\n",
    "SAVE_HISTORY = bool(config.get_training_parameter()[\"save_history\"])\n",
    "EPOCHS = config.get_training_parameter()[\"epochs\"]\n",
    "BATCH_SIZE = config.get_training_parameter()[\"batch_size\"] # default: 32 - 48\n",
    "TF_SEED = config.get_training_parameter()[\"tf_seed\"] # default: 42\n",
    "LEARNING_RATE = config.get_training_parameter()[\"learning_rate\"]\n",
    "PATIENCE = config.get_training_parameter()[\"patience\"] # default: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50ebf19d620853",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be0da09e6b20c3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Default: seed = 42\n",
    "# np.random.seed(TF_SEED)\n",
    "# tf.random.set_seed(TF_SEED)\n",
    "\n",
    "# Random\n",
    "#seed = random.randint(1, 1000)\n",
    "#np.random.seed(seed)\n",
    "#tf.random.set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e96e3bacfefa84",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load_data.print_samples(DATA_BASE_PATH)\n",
    "if False: # IAM Dataset\n",
    "    x_train_img_paths, y_train_labels = load_data.get_train_data()\n",
    "    x_val_img_paths, y_val_labels = load_data.get_validation_data()\n",
    "    #x_test_img_paths, y_test_labels = load_data.get_test_data()\n",
    "else:\n",
    "    x_train_img_paths, y_train_labels = load_transfer_data.get_train_data()\n",
    "    x_val_img_paths, y_val_labels = load_transfer_data.get_validation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc94188289acd0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f\"Training path: {x_train_img_paths[0:2]}\", y_train_labels[0:2])\n",
    "print(f\"Validation path: {x_val_img_paths[0:2]}\", y_val_labels[0:2])\n",
    "#print(f\"Testing path: {x_test_img_paths[0:2]}\", y_test_labels[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d396ce20431c83",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c72e5da9634ba",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Has to be here because load data functions need to be called before\n",
    "import handwriting.tokenizer as tokenizer\n",
    "import handwriting.custom_image_generator as cgi\n",
    "\n",
    "# takes eternity\n",
    "#x_train, y_train = tokenizer.prepare_data(x_train_img_paths, y_train_labels) \n",
    "#x_test, y_test = tokenizer.prepare_data(x_test_img_paths, y_test_labels)\n",
    "\n",
    "#train_generator = cgi.CustomImageGenerator(x_train_img_paths, y_train_labels, BATCH_SIZE, IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "\n",
    "train_ds = tokenizer.prepare_dataset(x_train_img_paths, y_train_labels, (IMAGE_WIDTH,IMAGE_HEIGHT),BATCH_SIZE)\n",
    "val_ds = tokenizer.prepare_dataset(x_val_img_paths, y_val_labels,(IMAGE_WIDTH,IMAGE_HEIGHT),BATCH_SIZE)\n",
    "#test_ds = tokenizer.prepare_dataset(x_test_img_paths, y_test_labels,(IMAGE_WIDTH,IMAGE_HEIGHT),BATCH_SIZE)\n",
    "#aug_train_ds = tokenizer.prepare_augmented_dataset(x_train_img_paths, y_train_labels, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5267aa06119792c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Show Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1843d431baf541",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for data in train_ds.take(1):\n",
    "    images, labels = data[\"image\"], data[\"label\"]\n",
    "\n",
    "    ax = plt.subplots(4, 4, figsize=(32, 8))[1]\n",
    "\n",
    "    for i in range(16):\n",
    "        img = images[i]\n",
    "        img = tf.image.flip_left_right(img)\n",
    "        img = tf.transpose(img, perm=[1, 0, 2])\n",
    "        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n",
    "        img = img[:, :, 0]\n",
    "\n",
    "        # Gather indices where label!= padding_token.\n",
    "        label = labels[i]\n",
    "        indices = tf.gather(label, tf.where(tf.math.not_equal(label, tokenizer.padding_token)))\n",
    "        # Convert to string.\n",
    "        label = tf.strings.reduce_join(tokenizer.num_to_char(indices))\n",
    "        label = label.numpy().decode(\"utf-8\")\n",
    "\n",
    "        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
    "        ax[i // 4, i % 4].set_title(label)\n",
    "        ax[i // 4, i % 4].axis(\"off\")\n",
    "\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42bfaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load_transfer_data.max_len)\n",
    "print(load_transfer_data.characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a37a927a1a58b2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d0b142ed5b54cf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # To see the augmentations from CustomImageGenerator\n",
    "# train_generator = cgi.CustomImageGenerator(x_train_img_paths, y_train_labels, tokenizer.batch_size, IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "# \n",
    "# example_batch = train_generator[0]\n",
    "# augmented_images = example_batch[0]['image']\n",
    "# \n",
    "# num_to_plot = 4\n",
    "# fig, axes = plt.subplots(1, num_to_plot, figsize=(10, 10))\n",
    "# \n",
    "# for i, ax in enumerate(axes.flatten()):\n",
    "#     ax.imshow(np.squeeze(augmented_images[i]), cmap='gray')\n",
    "#     ax.axis('off')\n",
    "# \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322476a450778bc6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomBrightness(0.5,value_range=(0, 1), seed=TF_SEED),\n",
    "        tf.keras.layers.RandomContrast(0.5,seed=TF_SEED)\n",
    "    ]\n",
    ")\n",
    "\n",
    "for data in train_ds.take(1):\n",
    "    images, labels = data[\"image\"], data[\"label\"]\n",
    "\n",
    "# Display the original image\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(images[0].numpy(), cmap='gray', vmin=0, vmax=1)\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "# Apply data augmentation to the image\n",
    "augmented_images = data_augmentation(images, training=True)\n",
    "\n",
    "# Display the augmented images\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 4, i + 2)\n",
    "    plt.imshow(augmented_images[i].numpy(), cmap='gray', vmin=0, vmax=1)\n",
    "    plt.title(f\"Augmented Image {i+1}\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de342f6f643d2f8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9c9f0a326f83ce",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_keras_string =\"_weights.keras\"\n",
    "\n",
    "def model_load_weights_if_exists(model):\n",
    "    MODEL_MODEL_PATH = MODEL_NAME\n",
    "    MODEL_WEIGHT_PATH = MODEL_NAME + weights_keras_string\n",
    "    model_path = os.path.join(MODEL_DIR_NAME, MODEL_MODEL_PATH)\n",
    "    model_weight_path = os.path.join(model_path, MODEL_WEIGHT_PATH)\n",
    "    print(model_path)\n",
    "    if os.path.exists(model_path):\n",
    "        print(\"Resuming Training where we left off!\")\n",
    "        model.load_weights(model_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678df9fcdf15f347",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    #model_load_weights_if_exists(model)\n",
    "        \n",
    "    prediction_model = keras.models.Model(model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output)\n",
    "    # checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "    early_stopping = EarlyStopping(patience=PATIENCE, restore_best_weights=True)\n",
    "\n",
    "    # reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=20, min_lr=1e-9, verbose=10)\n",
    "    # history = model.fit(train_ds, validation_data=val_ds, epochs=500, callbacks=[reduce_lr, early_stopping])    \n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=500)   \n",
    "    return prediction_model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce72291f",
   "metadata": {},
   "source": [
    "# Transfer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccc731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "def load_model_and_weights():\n",
    "    weights_keras_string = \"_weights.keras\"\n",
    "    MODEL_MODEL_PATH = MODEL_NAME\n",
    "    MODEL_WEIGHT_PATH = MODEL_NAME + weights_keras_string\n",
    "    model_path = os.path.join(MODEL_DIR_NAME, MODEL_MODEL_PATH)\n",
    "    model_weight_path = os.path.join(model_path, MODEL_WEIGHT_PATH)\n",
    "    model_weight_path = \"models/model9v3_xl/model9v3_xl_weights.keras\"\n",
    "    model_path = \"models/model9v3_xl\"\n",
    "    print(model_path)\n",
    "    if os.path.exists(model_path):\n",
    "        print(\"Loading pre-trained model and weights...\")\n",
    "        model = load_model(model_path)\n",
    "        model.load_weights(model_weight_path)\n",
    "        print(\"Model and weights loaded successfully.\")\n",
    "\n",
    "        return model\n",
    "    else:\n",
    "        print(\"No pre-trained model or weights found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02884dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model_and_weights()\n",
    "char = len(tokenizer.char_to_num.get_vocabulary())\n",
    "model = testing_models.load_and_finetune_model_gru_and_dense(model, IMAGE_WIDTH, IMAGE_HEIGHT, char, LEARNING_RATE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdbe79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "prediction_model, history = train_model(model)\n",
    "\n",
    "total_duration = time.time() - start_time\n",
    "print(\"Gesamte Trainingsdauer: {time}s\".format(time=round(total_duration)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc27d01fe397042",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Plot helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e443bfc89b1a8fea",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_history(history, name, dir_path, save_fig):\n",
    "    \"\"\"\n",
    "    Plottet die Historie des Trainings eines Models und speichert die in einem Verzeichnis ab \n",
    "\n",
    "    :param history: Das trainierte Modell\n",
    "    :param name: Name, wie das Modell gespeicht werden soll\n",
    "    :param name: Verzeichniss, wo der Plot gespeichert weren soll\n",
    "    :return: void\n",
    "    \"\"\"\n",
    "    metrics = history.history\n",
    "    _, ax1 = plt.subplots()\n",
    "\n",
    "    # Plot für Trainings- und Validierungsverluste\n",
    "    ax1.plot(metrics['loss'], label='Training Loss', color='blue')\n",
    "    ax1.plot(metrics['val_loss'], label='Validation Loss', color='red')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss', color='black')\n",
    "    ax1.tick_params('y', colors='black')\n",
    "    ax1.legend(loc='upper left', bbox_to_anchor=(0.0, 0.95))  \n",
    "\n",
    "    # Zweite Y-Achse für die Lernrate\n",
    "    ax2 = ax1.twinx()\n",
    "    #ax2.plot(metrics['lr'], label='Learning Rate', color='green')\n",
    "    ax2.set_ylabel('Learning Rate', color='black')\n",
    "    \n",
    "    ax2.set_yscale('log')  # Verwende logarithmische Skala für die Lernrate\n",
    "    \n",
    "    ax2.tick_params('y', colors='black')\n",
    "    ax2.yaxis.set_major_formatter(StrMethodFormatter('{x:1.0e}'))\n",
    "    ax2.legend(loc='upper right', bbox_to_anchor=(1.0, 0.95))  \n",
    "    \n",
    "    if save_fig:\n",
    "        plt.title('Name: '+name)\n",
    "        path = os.path.join(dir_path, name + '_history.png')\n",
    "        plt.savefig(path)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2d89800205cdc0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_dir(path_to_dir):\n",
    "    isExist = os.path.exists(path_to_dir)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_to_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c285abdfcc81c8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A utility function to decode the output of the network.\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    # Use greedy search. For complex tasks, you can use beam search.\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][:, :load_transfer_data.max_len]\n",
    "    # Iterate over the results and get back the text.\n",
    "    output_text = []\n",
    "    for res in results:\n",
    "        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n",
    "        res = tf.strings.reduce_join(tokenizer.num_to_char(res)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(res)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e2678f21bfbbb9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_evaluation(name, dir_path, save_fig):\n",
    "    for batch in val_ds.take(1):\n",
    "        batch_images = batch[\"image\"]\n",
    "        _, ax = plt.subplots(4, 4, figsize=(32, 8))\n",
    "\n",
    "        preds = prediction_model.predict(batch_images)\n",
    "        pred_texts = decode_batch_predictions(preds)\n",
    "\n",
    "        for i in range(16):\n",
    "            img = batch_images[i]\n",
    "            img = tf.image.flip_left_right(img)\n",
    "            img = tf.transpose(img, perm=[1, 0, 2])\n",
    "            img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n",
    "            img = img[:, :, 0]\n",
    "\n",
    "            title = f\"Prediction: {pred_texts[i]}\"\n",
    "            ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
    "            ax[i // 4, i % 4].set_title(title)\n",
    "            ax[i // 4, i % 4].axis(\"off\")   \n",
    "    if save_fig:\n",
    "        path = os.path.join(dir_path, name + '_result.png')\n",
    "        plt.savefig(path)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46158f62a4aac633",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d958dca138b01f54",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_new_plot_name(model_name, names, format):\n",
    "    import re\n",
    "    pattern = r\"\\d+\"\n",
    "    max_number = 0\n",
    "    for name in names:\n",
    "        tmp_name = name.replace(model_name,\"\")\n",
    "        number = int(re.findall(pattern,tmp_name)[0])\n",
    "        if number > max_number:\n",
    "            max_number = number\n",
    "            \n",
    "    new_model_name = model_name + \"V_\" + str(max_number + 1)\n",
    "    return format.replace(model_name,new_model_name)\n",
    "        \n",
    "if not os.path.exists(TEST_RESULT_DIR_NAME):\n",
    "            create_dir(TEST_RESULT_DIR_NAME)\n",
    "files_with_model_name = [file for file in os.listdir(TEST_RESULT_DIR_NAME) if MODEL_NAME in file]\n",
    "metrics = history.history\n",
    "\n",
    "NAME = \"{name}_{epoch}E_{height}H_{width}W_{loss}L_{val_loss}VL_{time}s\".format(\n",
    "    name=MODEL_NAME, epoch=history.epoch[-1], height=IMAGE_HEIGHT, width=IMAGE_WIDTH,\n",
    "    loss=round(metrics['loss'][-1],2), val_loss=round(metrics['val_loss'][-1], 2), time=round(total_duration))\n",
    "\n",
    "if not files_with_model_name:\n",
    "    if SAVE_HISTORY:\n",
    "        plot_history(history, NAME, TEST_RESULT_DIR_NAME, True)\n",
    "        plot_evaluation(NAME, TEST_RESULT_DIR_NAME, True)\n",
    "else:\n",
    "    new_name = create_new_plot_name(MODEL_NAME,files_with_model_name, NAME)\n",
    "    plot_history(history, new_name, TEST_RESULT_DIR_NAME, True)\n",
    "    plot_evaluation(new_name, TEST_RESULT_DIR_NAME, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ca800c",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde914d352e2192",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODEL_SAVE:\n",
    "    if not os.path.exists(MODEL_DIR_NAME):\n",
    "        create_dir(MODEL_DIR_NAME)\n",
    "    model_path = os.path.join(MODEL_DIR_NAME, \"{model_name}\".format(model_name=MODEL_NAME))\n",
    "    model.save(model_path)\n",
    "    model.save_weights(os.path.join(model_path, f\"{MODEL_NAME}{weights_keras_string}\"), overwrite=True, save_format=None, options=None)\n",
    "    print(model_path)\n",
    "    json_string = model.to_json()\n",
    "\n",
    "    with open(os.path.join(model_path, f\"{MODEL_NAME}.json\"),'w') as f:\n",
    "        f.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a7692c3fc79cb0bc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
