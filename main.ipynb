{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1502b4cfa6e7903",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "136c81f63399a8a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:24.312729700Z",
     "start_time": "2023-11-27T18:53:24.251731200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\SoNotOkay\\GitHubReposVStudios\\SmartApp-Project\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import load_data\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import os\n",
    "import preprocess\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9fdecf7c2a8def",
   "metadata": {},
   "source": [
    "## Constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "216f1fc3e59cf475",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:24.382729400Z",
     "start_time": "2023-11-27T18:53:24.257733800Z"
    }
   },
   "outputs": [],
   "source": [
    "# SAVE_HISTORY = True: Es speichert die Plots im Ordner \"test_results\"\n",
    "SAVE_HISTORY = True\n",
    "\n",
    "# MODEL_SAVE = True: Es speichert das Modell im Ordner \"arch\" mit den Name von \"MODEL_NAME\"\n",
    "MODEL_SAVE = False\n",
    "MODEL_NAME = \"Default\" # Am besten mit der Aenderung im Modell bennen \n",
    "MODEL_DIR_NAME = pathlib.Path(os.getcwd()).joinpath('arch')\n",
    "TEST_RESULT_DIR_NAME = pathlib.Path(os.getcwd()).joinpath('test_results')\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "IMAGE_WIDTH = preprocess.image_width\n",
    "IMAGE_HEIGHT = preprocess.image_height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76747d5c3df28a1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86582a055970482",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:24.607730800Z",
     "start_time": "2023-11-27T18:53:24.272732600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train samples: 10209\n",
      "Total validation samples: 567\n",
      "Total test samples: 568\n",
      "Maximum length:  93\n",
      "Vocab size:  79\n"
     ]
    }
   ],
   "source": [
    "load_data.print_samples()\n",
    "x_train_img_paths, y_train_labels = load_data.get_train_data()\n",
    "x_test_img_paths, y_test_labels = load_data.get_test_data()\n",
    "x_val_img_paths, y_val_labels = load_data.get_validation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cb1f3ce3dc036ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:24.652243Z",
     "start_time": "2023-11-27T18:53:24.608729900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training path: ['data\\\\lines\\\\m06\\\\m06-106\\\\m06-106-03.png', 'data\\\\lines\\\\a01\\\\a01-132u\\\\a01-132u-03.png'] ['and|Haris|there|were|many|events|.|Chief|of|these|was', 'adjust|the|financing|-|which|Mr.|Powell']\n",
      "Validation path: ['data\\\\lines\\\\b04\\\\b04-034\\\\b04-034-04.png', 'data\\\\lines\\\\a05\\\\a05-004\\\\a05-004-05.png'] ['Newmarket|urban|council|,|says|:|\"|I|shall|always|feel|this|as|a', 'and|operations|.|This|would|apply|also|in|the']\n",
      "Testing path: ['data\\\\lines\\\\a02\\\\a02-093\\\\a02-093-01.png', 'data\\\\lines\\\\n02\\\\n02-049\\\\n02-049-03.png'] ['priority|to|the|clash|over|Northern|Rhodesia|on|his', 'look|as|though|it|was|only|what|you|expected|of|me|,']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training path: {x_train_img_paths[0:2]}\", y_train_labels[0:2])\n",
    "print(f\"Validation path: {x_val_img_paths[0:2]}\", y_val_labels[0:2])\n",
    "print(f\"Testing path: {x_test_img_paths[0:2]}\", y_test_labels[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ab75f6db361259",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a385c9dcb30be19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:25.639243500Z",
     "start_time": "2023-11-27T18:53:24.623732100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\SoNotOkay\\GitHubReposVStudios\\SmartApp-Project\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\SoNotOkay\\GitHubReposVStudios\\SmartApp-Project\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Has to be here because load data functions need to be called before\n",
    "import tokenizer\n",
    "\n",
    "# takes eternity\n",
    "#x_train, y_train = tokenizer.prepare_data(x_train_img_paths, y_train_labels) \n",
    "#x_test, y_test = tokenizer.prepare_data(x_test_img_paths, y_test_labels)\n",
    "train_ds = tokenizer.prepare_dataset(x_train_img_paths, y_train_labels)\n",
    "val_ds = tokenizer.prepare_dataset(x_val_img_paths, y_val_labels)\n",
    "test_ds = tokenizer.prepare_dataset(x_test_img_paths, y_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7320fbb2c02999f8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Show Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dcf82c6677caa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:26.261244600Z",
     "start_time": "2023-11-27T18:53:25.642245200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for data in test_ds.take(1):\n",
    "    images, labels = data[\"image\"], data[\"label\"]\n",
    "\n",
    "    ax = plt.subplots(4, 4, figsize=(32, 4))[1]\n",
    "\n",
    "    for i in range(16):\n",
    "        img = images[i]\n",
    "        img = tf.image.flip_left_right(img)\n",
    "        img = tf.transpose(img, perm=[1, 0, 2])\n",
    "        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n",
    "        img = img[:, :, 0]\n",
    "\n",
    "        # Gather indices where label!= padding_token.\n",
    "        label = labels[i]\n",
    "        indices = tf.gather(label, tf.where(tf.math.not_equal(label, tokenizer.padding_token)))\n",
    "        # Convert to string.\n",
    "        label = tf.strings.reduce_join(tokenizer.num_to_char(indices))\n",
    "        label = label.numpy().decode(\"utf-8\")\n",
    "\n",
    "        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
    "        ax[i // 4, i % 4].set_title(label)\n",
    "        ax[i // 4, i % 4].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fb84d1f182a3c2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\SoNotOkay\\GitHubReposVStudios\\SmartApp-Project\\main.ipynb Cell 13\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SoNotOkay/GitHubReposVStudios/SmartApp-Project/main.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SoNotOkay/GitHubReposVStudios/SmartApp-Project/main.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m sample_image \u001b[39m=\u001b[39m ia\u001b[39m.\u001b[39msample_image(train_ds)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/SoNotOkay/GitHubReposVStudios/SmartApp-Project/main.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m (sample_image\u001b[39m.\u001b[39;49msize) \u001b[39m# , sample_label.size)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SoNotOkay/GitHubReposVStudios/SmartApp-Project/main.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Initialize the image data generator\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SoNotOkay/GitHubReposVStudios/SmartApp-Project/main.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m datagen \u001b[39m=\u001b[39m ia\u001b[39m.\u001b[39minit_image_generator(sample_image)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "import image_augmentation as ia\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_image = ia.sample_image(train_ds)\n",
    "print (sample_image.size) # , sample_label.size)\n",
    "\n",
    "# Initialize the image data generator\n",
    "datagen = ia.init_image_generator(sample_image)\n",
    "\n",
    "# Generate augmented images\n",
    "augmented_images = []\n",
    "for i in range(4):  # Generate and collect 4 augmented images\n",
    "    batch = next(datagen)\n",
    "    augmented_images.append(image.array_to_img(batch[0]))\n",
    "\n",
    "# Plot the original and augmented images\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, img in enumerate([image.array_to_img(sample_image)] + augmented_images):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.set_cmap('gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff86774f0f94fd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:27.186245500Z",
     "start_time": "2023-11-27T18:53:26.264243600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomBrightness(0.5,value_range=(0, 1), seed=42)\n",
    "    ]\n",
    ")\n",
    "\n",
    "for data in train_ds.take(1):\n",
    "    images, labels = data[\"image\"], data[\"label\"]\n",
    "\n",
    "# Display the original image\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(images[0].numpy(), cmap='gray', vmin=0, vmax=1)\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "# Apply data augmentation to the image\n",
    "augmented_images = data_augmentation(images, training=True)\n",
    "\n",
    "# Display the augmented images\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 4, i + 2)\n",
    "    plt.imshow(augmented_images[i].numpy(), cmap='gray', vmin=0, vmax=1)\n",
    "    plt.title(f\"Augmented Image {i+1}\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a8f3c1739275a9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## CTC Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa5b993cc46bdf07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:27.223242700Z",
     "start_time": "2023-11-27T18:53:27.187242700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "class CTCLayer(keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # At test time, just return the computed predictions.\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b04141fedb9fc1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c88a18f9b04af9aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:27.224242900Z",
     "start_time": "2023-11-27T18:53:27.207242700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model9v3():\n",
    "    input_img = keras.Input(shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 1), name=\"image\")\n",
    "    labels = keras.layers.Input(name=\"label\", shape=(None,))\n",
    "    \n",
    "    x = keras.layers.Conv2D(48, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\", name=\"Conv1\")(input_img)\n",
    "    x = keras.layers.Conv2D(96, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\", name=\"Conv2\")(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
    "    x = keras.layers.Conv2D(48, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\", name=\"Conv3\")(x)\n",
    "    x = keras.layers.Conv2D(96, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\", name=\"Conv4\")(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "    new_shape = ((IMAGE_WIDTH // 4), (IMAGE_HEIGHT // 4) * 96)\n",
    "    x = keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
    "    x = keras.layers.Dense(128, activation=\"relu\", name=\"dense1\")(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "                                \n",
    "    x = keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True, dropout=0.25))(x)\n",
    "    x = keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n",
    "\n",
    "    x = keras.layers.Dense(len(tokenizer.char_to_num.get_vocabulary()) + 2, activation=\"softmax\", name=\"dense2\")(x)\n",
    "\n",
    "    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n",
    "\n",
    "    model = keras.models.Model(inputs=[input_img, labels], outputs=output, name=\"handwriting_recognizer\")\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed55c7a76356f3f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa2ff82295403fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:27.235244Z",
     "start_time": "2023-11-27T18:53:27.221246700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', mode='min', restore_best_weights=True,patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e3dd1605013373",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:27.266271800Z",
     "start_time": "2023-11-27T18:53:27.235244Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9f6c5d2af16e7e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:27.266271800Z",
     "start_time": "2023-11-27T18:53:27.252273200Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    prediction_model = keras.models.Model(model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output)\n",
    "\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS,callbacks=monitor)\n",
    "    return prediction_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "489839570631767b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:28.002427700Z",
     "start_time": "2023-11-27T18:53:27.270271700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\SoNotOkay\\GitHubReposVStudios\\SmartApp-Project\\venv\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\SoNotOkay\\GitHubReposVStudios\\SmartApp-Project\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Model: \"handwriting_recognizer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image (InputLayer)          [(None, 512, 32, 1)]         0         []                            \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)              (None, 512, 32, 48)          480       ['image[0][0]']               \n",
      "                                                                                                  \n",
      " Conv2 (Conv2D)              (None, 512, 32, 96)          41568     ['Conv1[0][0]']               \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)        (None, 256, 16, 96)          0         ['Conv2[0][0]']               \n",
      "                                                                                                  \n",
      " Conv3 (Conv2D)              (None, 256, 16, 48)          41520     ['pool1[0][0]']               \n",
      "                                                                                                  \n",
      " Conv4 (Conv2D)              (None, 256, 16, 96)          41568     ['Conv3[0][0]']               \n",
      "                                                                                                  \n",
      " pool2 (MaxPooling2D)        (None, 128, 8, 96)           0         ['Conv4[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 128, 8, 96)           0         ['pool2[0][0]']               \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 128, 768)             0         ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dense1 (Dense)              (None, 128, 128)             98432     ['reshape[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 128, 128)             0         ['dense1[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 128, 512)             788480    ['dropout_1[0][0]']           \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirecti  (None, 128, 256)             656384    ['bidirectional[0][0]']       \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " label (InputLayer)          [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " dense2 (Dense)              (None, 128, 82)              21074     ['bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      " ctc_loss (CTCLayer)         (None, 128, 82)              0         ['label[0][0]',               \n",
      "                                                                     'dense2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1689506 (6.44 MB)\n",
      "Trainable params: 1689506 (6.44 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the model.\n",
    "model = build_model9v3()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20c2bdc5647c8fa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-27T18:53:28.001426900Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "prediction_model, history = train_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 13/320 [>.............................] - ETA: 9:03 - loss: 244.2905"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\SoNotOkay\\GitHubReposVStudios\\SmartApp-Project\\main.ipynb Cell 26\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/SoNotOkay/GitHubReposVStudios/SmartApp-Project/main.ipynb#X60sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     plt\u001b[39m.\u001b[39maxis(\u001b[39m'\u001b[39m\u001b[39moff\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/SoNotOkay/GitHubReposVStudios/SmartApp-Project/main.ipynb#X60sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/SoNotOkay/GitHubReposVStudios/SmartApp-Project/main.ipynb#X60sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_generator, steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_generator), validation_data\u001b[39m=\u001b[39;49mval_ds, epochs\u001b[39m=\u001b[39;49mEPOCHS, callbacks\u001b[39m=\u001b[39;49mmonitor)\n",
      "File \u001b[1;32mc:\\Users\\SoNotOkay\\GitHubReposVStudios\\SmartApp-Project\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\SoNotOkay\\GitHubReposVStudios\\SmartApp-Project\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1808\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\SoNotOkay\\GitHubReposVStudios\\SmartApp-Project\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\SoNotOkay\\GitHubReposVStudios\\SmartApp-Project\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\SoNotOkay\\GitHubReposVStudios\\SmartApp-Project\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    869\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[0;32m    870\u001b[0m   )\n\u001b[0;32m    871\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\SoNotOkay\\GitHubReposVStudios\\SmartApp-Project\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\SoNotOkay\\GitHubReposVStudios\\SmartApp-Project\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall_preflattened(args)\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\SoNotOkay\\GitHubReposVStudios\\SmartApp-Project\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_preflattened\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_flat(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    217\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\SoNotOkay\\GitHubReposVStudios\\SmartApp-Project\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    253\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\SoNotOkay\\GitHubReposVStudios\\SmartApp-Project\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1487\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1488\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1489\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1490\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1491\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1492\u001b[0m   )\n\u001b[0;32m   1493\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\SoNotOkay\\GitHubReposVStudios\\SmartApp-Project\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import custom_image_generator as cgi\n",
    "\n",
    "BATCH_SIZE=32\n",
    "\n",
    "train_generator = cgi.CustomImageGenerator(x_train_img_paths, y_train_labels, BATCH_SIZE, IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "\n",
    "\n",
    "\n",
    "example_batch = train_generator[0]\n",
    "augmented_images = example_batch[0]['image']\n",
    "\n",
    "num_to_plot = 10\n",
    "fig = plt.figure(figsize=(12, 6))  # Adjust the figsize as needed\n",
    "\n",
    "for i in range(num_to_plot):\n",
    "    plt.subplot(2, num_to_plot // 2, i+1)\n",
    "    plt.imshow(np.squeeze(augmented_images[i]), cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "history = model.fit(train_generator, steps_per_epoch=len(train_generator), validation_data=val_ds, epochs=EPOCHS, callbacks=monitor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import image_augmentation as ia\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=0.2,\n",
    "        shear_range=0.5,\n",
    "        zoom_range=0.05,\n",
    "        rescale=1./255\n",
    "    )\n",
    "\n",
    "images, labels = zip(*train_ds)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "unique_labels = list(set(labels))  # Get unique labels\n",
    "label_to_index = {label: i for i, label in enumerate(unique_labels)}  # Create a mapping from label to index\n",
    "index_to_label = {i: label for i, label in enumerate(unique_labels)}  # Create a mapping from index to label\n",
    "num_classes = len(unique_labels)\n",
    "\n",
    "# Convert labels to indices and then to one-hot encoding\n",
    "labels_indices = [label_to_index[label] for label in labels]\n",
    "one_hot_labels = to_categorical(labels_indices, num_classes=93)\n",
    "\n",
    "# Assuming images is a list of file paths to images\n",
    "images = [load_img(image_path, target_size=(IMAGE_WIDTH, IMAGE_HEIGHT)) for image_path in x_train_img_paths]\n",
    "images = [img_to_array(img) for img in images]\n",
    "images = np.array(images)\n",
    "one_hot_labels = np.array(list(one_hot_labels))\n",
    "\n",
    "datagen = datagen.flow(images, one_hot_labels)\n",
    "\n",
    "'''\n",
    "sample_image, sample_label = ia.sample_image(train_ds)\n",
    "#sample_image = ia.sample_image(train_ds)\n",
    "#datagen = ia.init_image_generator(sample_image, sample_label)\n",
    "sample_image = np.expand_dims(sample_image, axis=0)\n",
    "datagen = datagen.flow(sample_image)\n",
    "'''\n",
    "history = model.fit((datagen), validation_data=val_ds, epochs=EPOCHS,callbacks=monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d09077ade6432b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f5fa9591872bc8",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def plot_history_simple(history):\n",
    "    \"\"\"\n",
    "    Plottet die Historie des Trainings eines Models\n",
    "\n",
    "    :param history: Das trainierte Modell\n",
    "    :return: void\n",
    "    \"\"\"\n",
    "    metrics = history.history\n",
    "    plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "    plt.legend(['loss', 'val_loss'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7cb27a66ec7812",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def plot_history(history, name, dir_path):\n",
    "    \"\"\"\n",
    "    Plottet die Historie des Trainings eines Models und speichert die in einem Verzeichnis ab \n",
    "\n",
    "    :param history: Das trainierte Modell\n",
    "    :param name: Name, wie das Modell gespeicht werden soll\n",
    "    :param name: Verzeichniss, wo der Plot gespeichert weren soll\n",
    "    :return: void\n",
    "    \"\"\"\n",
    "    metrics = history.history\n",
    "    plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "    plt.legend(['loss', 'val_loss'])\n",
    "    plt.title('Name: '+name)\n",
    "    path = os.path.join(dir_path, name + '_history.png')\n",
    "    plt.savefig(path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab38e2a8619ce38",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def create_dir(path_to_dir):\n",
    "    isExist = os.path.exists(path_to_dir)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_to_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b6ad48840858cc",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# A utility function to decode the output of the network.\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    # Use greedy search. For complex tasks, you can use beam search.\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][:, :load_data.max_len]\n",
    "    # Iterate over the results and get back the text.\n",
    "    output_text = []\n",
    "    for res in results:\n",
    "        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n",
    "        res = tf.strings.reduce_join(tokenizer.num_to_char(res)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(res)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc5e3e4084e1873",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def plot_evaluation(name, dir_path, save):\n",
    "    if save:\n",
    "        path = os.path.join(dir_path, name + '_result.png')\n",
    "        plt.savefig(path)\n",
    "\n",
    "    for batch in val_ds.take(1):\n",
    "        batch_images = batch[\"image\"]\n",
    "        _, ax = plt.subplots(4, 4, figsize=(32, 4))\n",
    "\n",
    "        preds = prediction_model.predict(batch_images)\n",
    "        pred_texts = decode_batch_predictions(preds)\n",
    "\n",
    "        for i in range(16):\n",
    "            img = batch_images[i]\n",
    "            img = tf.image.flip_left_right(img)\n",
    "            img = tf.transpose(img, perm=[1, 0, 2])\n",
    "            img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n",
    "            img = img[:, :, 0]\n",
    "\n",
    "            title = f\"Prediction: {pred_texts[i]}\"\n",
    "            ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
    "            ax[i // 4, i % 4].set_title(title)\n",
    "            ax[i // 4, i % 4].axis(\"off\")   \n",
    "            \n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb24791bb38053e2",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#test_loss, test_accuracy = model.evaluate(test_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55a273c2329919a",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ca5fd49c11770",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "files_with_model_name = [file for file in os.listdir(TEST_RESULT_DIR_NAME) if MODEL_NAME in file]\n",
    "metrics = history.history\n",
    "\n",
    "NAME = \"{name}_{epoch}E_{height}H_{width}W_{loss}L_{val_loss}VL\".format(\n",
    "    name=MODEL_NAME, epoch=EPOCHS, height=IMAGE_HEIGHT, width=IMAGE_WIDTH,\n",
    "    loss=round(metrics['loss'][-1]), val_loss=round(metrics['val_loss'][-1]))\n",
    "\n",
    "if not files_with_model_name:\n",
    "    if SAVE_HISTORY:\n",
    "        if not os.path.exists(TEST_RESULT_DIR_NAME):\n",
    "            create_dir(TEST_RESULT_DIR_NAME)\n",
    "        plot_history(history, NAME, TEST_RESULT_DIR_NAME)\n",
    "        plot_evaluation(NAME, TEST_RESULT_DIR_NAME, True)\n",
    "else:\n",
    "    plot_history_simple(history)\n",
    "    plot_evaluation(NAME, TEST_RESULT_DIR_NAME, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f26ab3b04550af2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3721ecbe52011",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "if MODEL_SAVE:\n",
    "    if not os.path.exists(MODEL_DIR_NAME):\n",
    "        create_dir(MODEL_DIR_NAME)\n",
    "    model.save(os.path.join(MODEL_DIR_NAME, \"{model_name}\".format(model_name=MODEL_NAME)))\n",
    "    #model.save_weights(os.path.join(MODEL_DIR_NAME, \"weights.keras\"), overwrite=True, save_format=None, options=None)\n",
    "    json_string = model.to_json()\n",
    "\n",
    "    with open(os.path.join(MODEL_DIR_NAME, \"model\"),'w') as f:\n",
    "        f.write(json_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
