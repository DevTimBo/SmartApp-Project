{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1502b4cfa6e7903",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c81f63399a8a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:24.312729700Z",
     "start_time": "2023-11-27T18:53:24.251731200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import load_data\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import os\n",
    "import preprocess\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9fdecf7c2a8def",
   "metadata": {},
   "source": [
    "## Constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f1fc3e59cf475",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:24.382729400Z",
     "start_time": "2023-11-27T18:53:24.257733800Z"
    }
   },
   "outputs": [],
   "source": [
    "# SAVE_HISTORY = True: Es speichert die Plots im Ordner \"test_results\"\n",
    "SAVE_HISTORY = True\n",
    "\n",
    "# MODEL_SAVE = True: Es speichert das Modell im Ordner \"arch\" mit den Name von \"MODEL_NAME\"\n",
    "MODEL_SAVE = False\n",
    "MODEL_NAME = \"Default\" # Am besten mit der Aenderung im Modell bennen \n",
    "MODEL_DIR_NAME = pathlib.Path(os.getcwd()).joinpath('arch')\n",
    "TEST_RESULT_DIR_NAME = pathlib.Path(os.getcwd()).joinpath('test_results')\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "IMAGE_WIDTH = preprocess.image_width\n",
    "IMAGE_HEIGHT = preprocess.image_height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76747d5c3df28a1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86582a055970482",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:24.607730800Z",
     "start_time": "2023-11-27T18:53:24.272732600Z"
    }
   },
   "outputs": [],
   "source": [
    "load_data.print_samples()\n",
    "x_train_img_paths, y_train_labels = load_data.get_train_data()\n",
    "x_test_img_paths, y_test_labels = load_data.get_test_data()\n",
    "x_val_img_paths, y_val_labels = load_data.get_validation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb1f3ce3dc036ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:24.652243Z",
     "start_time": "2023-11-27T18:53:24.608729900Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Training path: {x_train_img_paths[0:2]}\", y_train_labels[0:2])\n",
    "print(f\"Validation path: {x_val_img_paths[0:2]}\", y_val_labels[0:2])\n",
    "print(f\"Testing path: {x_test_img_paths[0:2]}\", y_test_labels[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ab75f6db361259",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a385c9dcb30be19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:25.639243500Z",
     "start_time": "2023-11-27T18:53:24.623732100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Has to be here because load data functions need to be called before\n",
    "import tokenizer\n",
    "import custom_image_generator as cgi\n",
    "\n",
    "# takes eternity\n",
    "#x_train, y_train = tokenizer.prepare_data(x_train_img_paths, y_train_labels) \n",
    "#x_test, y_test = tokenizer.prepare_data(x_test_img_paths, y_test_labels)\n",
    "train_ds = tokenizer.prepare_dataset(x_train_img_paths, y_train_labels)\n",
    "val_ds = tokenizer.prepare_dataset(x_val_img_paths, y_val_labels)\n",
    "test_ds = tokenizer.prepare_dataset(x_test_img_paths, y_test_labels)\n",
    "dataset = tokenizer.prepare_augmented_dataset(x_train_img_paths, y_train_labels) # basically augmented train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7320fbb2c02999f8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Show Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dcf82c6677caa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:26.261244600Z",
     "start_time": "2023-11-27T18:53:25.642245200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To see augmentations in the augmented dataset, just change the dataset used here\n",
    "for data in dataset.take(1):\n",
    "    images, labels = data[\"image\"], data[\"label\"]\n",
    "\n",
    "    ax = plt.subplots(4, 4, figsize=(32, 4))[1]\n",
    "\n",
    "    for i in range(16):\n",
    "        img = images[i]\n",
    "        img = tf.image.flip_left_right(img)\n",
    "        img = tf.transpose(img, perm=[1, 0, 2])\n",
    "        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n",
    "        img = img[:, :, 0]\n",
    "\n",
    "        # Gather indices where label!= padding_token.\n",
    "        label = labels[i]\n",
    "        indices = tf.gather(label, tf.where(tf.math.not_equal(label, tokenizer.padding_token)))\n",
    "        # Convert to string.\n",
    "        label = tf.strings.reduce_join(tokenizer.num_to_char(indices))\n",
    "        label = label.numpy().decode(\"utf-8\")\n",
    "\n",
    "        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
    "        ax[i // 4, i % 4].set_title(label)\n",
    "        ax[i // 4, i % 4].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fb84d1f182a3c2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the augmentations from CustomImageGenerator\n",
    "train_generator = cgi.CustomImageGenerator(x_train_img_paths, y_train_labels, tokenizer.batch_size, IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "\n",
    "example_batch = train_generator[0]\n",
    "augmented_images = example_batch[0]['image']\n",
    "\n",
    "num_to_plot = 4\n",
    "fig, axes = plt.subplots(1, num_to_plot, figsize=(10, 10))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(np.squeeze(augmented_images[i]), cmap='gray')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff86774f0f94fd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:27.186245500Z",
     "start_time": "2023-11-27T18:53:26.264243600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomBrightness(0.5,value_range=(0, 1), seed=42)\n",
    "    ]\n",
    ")\n",
    "\n",
    "for data in train_ds.take(1):\n",
    "    images, labels = data[\"image\"], data[\"label\"]\n",
    "\n",
    "# Display the original image\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(images[0].numpy(), cmap='gray', vmin=0, vmax=1)\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "# Apply data augmentation to the image\n",
    "augmented_images = data_augmentation(images, training=True)\n",
    "\n",
    "# Display the augmented images\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 4, i + 2)\n",
    "    plt.imshow(augmented_images[i].numpy(), cmap='gray', vmin=0, vmax=1)\n",
    "    plt.title(f\"Augmented Image {i+1}\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a8f3c1739275a9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## CTC Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b993cc46bdf07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:27.223242700Z",
     "start_time": "2023-11-27T18:53:27.187242700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "class CTCLayer(keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # At test time, just return the computed predictions.\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b04141fedb9fc1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a18f9b04af9aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:27.224242900Z",
     "start_time": "2023-11-27T18:53:27.207242700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model9v3():\n",
    "    input_img = keras.Input(shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 1), name=\"image\")\n",
    "    labels = keras.layers.Input(name=\"label\", shape=(None,))\n",
    "    \n",
    "    x = keras.layers.Conv2D(48, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\", name=\"Conv1\")(input_img)\n",
    "    x = keras.layers.Conv2D(96, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\", name=\"Conv2\")(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
    "    x = keras.layers.Conv2D(48, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\", name=\"Conv3\")(x)\n",
    "    x = keras.layers.Conv2D(96, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\", name=\"Conv4\")(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "    new_shape = ((IMAGE_WIDTH // 4), (IMAGE_HEIGHT // 4) * 96)\n",
    "    x = keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
    "    x = keras.layers.Dense(128, activation=\"relu\", name=\"dense1\")(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "                                \n",
    "    x = keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True, dropout=0.25))(x)\n",
    "    x = keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n",
    "\n",
    "    x = keras.layers.Dense(len(tokenizer.char_to_num.get_vocabulary()) + 2, activation=\"softmax\", name=\"dense2\")(x)\n",
    "\n",
    "    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n",
    "\n",
    "    model = keras.models.Model(inputs=[input_img, labels], outputs=output, name=\"handwriting_recognizer\")\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed55c7a76356f3f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2ff82295403fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:27.235244Z",
     "start_time": "2023-11-27T18:53:27.221246700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', mode='min', restore_best_weights=True,patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e3dd1605013373",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:27.266271800Z",
     "start_time": "2023-11-27T18:53:27.235244Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f6c5d2af16e7e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:27.266271800Z",
     "start_time": "2023-11-27T18:53:27.252273200Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    prediction_model = keras.models.Model(model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output)\n",
    "\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS,callbacks=monitor)\n",
    "    return prediction_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489839570631767b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T18:53:28.002427700Z",
     "start_time": "2023-11-27T18:53:27.270271700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the model.\n",
    "model = build_model9v3()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20c2bdc5647c8fa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-27T18:53:28.001426900Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "prediction_model, history = train_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = cgi.CustomImageGenerator(x_train_img_paths, y_train_labels, tokenizer.batch_size, IMAGE_WIDTH, IMAGE_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on what to try, change the input to dataset/train_generator\n",
    "history = model.fit(dataset, batch_size=tokenizer.batch_size, validation_data=val_ds, epochs=EPOCHS, callbacks=monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d09077ade6432b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f5fa9591872bc8",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def plot_history_simple(history):\n",
    "    \"\"\"\n",
    "    Plottet die Historie des Trainings eines Models\n",
    "\n",
    "    :param history: Das trainierte Modell\n",
    "    :return: void\n",
    "    \"\"\"\n",
    "    metrics = history.history\n",
    "    plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "    plt.legend(['loss', 'val_loss'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7cb27a66ec7812",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def plot_history(history, name, dir_path):\n",
    "    \"\"\"\n",
    "    Plottet die Historie des Trainings eines Models und speichert die in einem Verzeichnis ab \n",
    "\n",
    "    :param history: Das trainierte Modell\n",
    "    :param name: Name, wie das Modell gespeicht werden soll\n",
    "    :param name: Verzeichniss, wo der Plot gespeichert weren soll\n",
    "    :return: void\n",
    "    \"\"\"\n",
    "    metrics = history.history\n",
    "    plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "    plt.legend(['loss', 'val_loss'])\n",
    "    plt.title('Name: '+name)\n",
    "    path = os.path.join(dir_path, name + '_history.png')\n",
    "    plt.savefig(path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab38e2a8619ce38",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def create_dir(path_to_dir):\n",
    "    isExist = os.path.exists(path_to_dir)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_to_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b6ad48840858cc",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# A utility function to decode the output of the network.\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    # Use greedy search. For complex tasks, you can use beam search.\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][:, :load_data.max_len]\n",
    "    # Iterate over the results and get back the text.\n",
    "    output_text = []\n",
    "    for res in results:\n",
    "        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n",
    "        res = tf.strings.reduce_join(tokenizer.num_to_char(res)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(res)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc5e3e4084e1873",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def plot_evaluation(name, dir_path, save):\n",
    "    if save:\n",
    "        path = os.path.join(dir_path, name + '_result.png')\n",
    "        plt.savefig(path)\n",
    "\n",
    "    for batch in val_ds.take(1):\n",
    "        batch_images = batch[\"image\"]\n",
    "        _, ax = plt.subplots(4, 4, figsize=(32, 4))\n",
    "\n",
    "        preds = prediction_model.predict(batch_images)\n",
    "        pred_texts = decode_batch_predictions(preds)\n",
    "\n",
    "        for i in range(16):\n",
    "            img = batch_images[i]\n",
    "            img = tf.image.flip_left_right(img)\n",
    "            img = tf.transpose(img, perm=[1, 0, 2])\n",
    "            img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n",
    "            img = img[:, :, 0]\n",
    "\n",
    "            title = f\"Prediction: {pred_texts[i]}\"\n",
    "            ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
    "            ax[i // 4, i % 4].set_title(title)\n",
    "            ax[i // 4, i % 4].axis(\"off\")   \n",
    "            \n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb24791bb38053e2",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#test_loss, test_accuracy = model.evaluate(test_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55a273c2329919a",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ca5fd49c11770",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "files_with_model_name = [file for file in os.listdir(TEST_RESULT_DIR_NAME) if MODEL_NAME in file]\n",
    "metrics = history.history\n",
    "\n",
    "NAME = \"{name}_{epoch}E_{height}H_{width}W_{loss}L_{val_loss}VL\".format(\n",
    "    name=MODEL_NAME, epoch=EPOCHS, height=IMAGE_HEIGHT, width=IMAGE_WIDTH,\n",
    "    loss=round(metrics['loss'][-1]), val_loss=round(metrics['val_loss'][-1]))\n",
    "\n",
    "if not files_with_model_name:\n",
    "    if SAVE_HISTORY:\n",
    "        if not os.path.exists(TEST_RESULT_DIR_NAME):\n",
    "            create_dir(TEST_RESULT_DIR_NAME)\n",
    "        plot_history(history, NAME, TEST_RESULT_DIR_NAME)\n",
    "        plot_evaluation(NAME, TEST_RESULT_DIR_NAME, True)\n",
    "else:\n",
    "    plot_history_simple(history)\n",
    "    plot_evaluation(NAME, TEST_RESULT_DIR_NAME, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f26ab3b04550af2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3721ecbe52011",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "if MODEL_SAVE:\n",
    "    if not os.path.exists(MODEL_DIR_NAME):\n",
    "        create_dir(MODEL_DIR_NAME)\n",
    "    model.save(os.path.join(MODEL_DIR_NAME, \"{model_name}\".format(model_name=MODEL_NAME)))\n",
    "    #model.save_weights(os.path.join(MODEL_DIR_NAME, \"weights.keras\"), overwrite=True, save_format=None, options=None)\n",
    "    json_string = model.to_json()\n",
    "\n",
    "    with open(os.path.join(MODEL_DIR_NAME, \"model\"),'w') as f:\n",
    "        f.write(json_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
