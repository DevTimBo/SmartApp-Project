{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1502b4cfa6e7903",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c81f63399a8a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T08:53:21.163418900Z",
     "start_time": "2023-11-26T08:53:17.114100800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unsere Klassen\n",
    "import load_data\n",
    "import preprocess\n",
    "import testing_models # Use: build_model9v3(img_width, img_height, char) \n",
    "#Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE_HISTORY = True: Es speichert die Plots im Ordner \"test_results\"\n",
    "SAVE_HISTORY = True\n",
    "\n",
    "# MODEL_SAVE = True: Es speichert das Modell im Ordner \"arch\" mit den Name von \"MODEL_NAME\"\n",
    "MODEL_SAVE = False\n",
    "MODEL_NAME = \"alexejV1\" # Der Name wird am Ende im Plot mit angezeigt \n",
    "MODEL_DIR_NAME = pathlib.Path(os.getcwd()).joinpath('arch')\n",
    "TEST_RESULT_DIR_NAME = pathlib.Path(os.getcwd()).joinpath('test_results')\n",
    "\n",
    "#Anzahl an Epochen die maximal durchlaufen werden\n",
    "EPOCHS = 100\n",
    "\n",
    "# IMAGE_WIDTH   : Default 512\n",
    "# IMAGE_HEIGHT  : Default 32\n",
    "IMAGE_WIDTH = preprocess.image_width\n",
    "IMAGE_HEIGHT = preprocess.image_height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76747d5c3df28a1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data.print_samples()\n",
    "x_train_img_paths, y_train_labels = load_data.get_train_data()\n",
    "x_test_img_paths, y_test_labels = load_data.get_test_data()\n",
    "x_val_img_paths, y_val_labels = load_data.get_validation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training path: {x_train_img_paths[0:2]}\", y_train_labels[0:2])\n",
    "print(f\"Validation path: {x_val_img_paths[0:2]}\", y_val_labels[0:2])\n",
    "print(f\"Testing path: {x_test_img_paths[0:2]}\", y_test_labels[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ab75f6db361259",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a385c9dcb30be19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T08:53:22.092326600Z",
     "start_time": "2023-11-26T08:53:21.496154300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Has to be here because load data functions need to be called before\n",
    "import tokenizer\n",
    "\n",
    "# takes eternity\n",
    "#x_train, y_train = tokenizer.prepare_data(x_train_img_paths, y_train_labels) \n",
    "#x_test, y_test = tokenizer.prepare_data(x_test_img_paths, y_test_labels)\n",
    "train_ds = tokenizer.prepare_dataset(x_train_img_paths, y_train_labels)\n",
    "val_ds = tokenizer.prepare_dataset(x_val_img_paths, y_val_labels)\n",
    "test_ds = tokenizer.prepare_dataset(x_test_img_paths, y_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7320fbb2c02999f8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Show Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dcf82c6677caa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T08:53:22.332368700Z",
     "start_time": "2023-11-26T08:53:22.095327Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for data in test_ds.take(1):\n",
    "    images, labels = data[\"image\"], data[\"label\"]\n",
    "\n",
    "    ax = plt.subplots(4, 4, figsize=(32, 4))[1]\n",
    "\n",
    "    for i in range(16):\n",
    "        img = images[i]\n",
    "        img = tf.image.flip_left_right(img)\n",
    "        img = tf.transpose(img, perm=[1, 0, 2])\n",
    "        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n",
    "        img = img[:, :, 0]\n",
    "\n",
    "        # Gather indices where label!= padding_token.\n",
    "        label = labels[i]\n",
    "        indices = tf.gather(label, tf.where(tf.math.not_equal(label, tokenizer.padding_token)))\n",
    "        # Convert to string.\n",
    "        label = tf.strings.reduce_join(tokenizer.num_to_char(indices))\n",
    "        label = label.numpy().decode(\"utf-8\")\n",
    "\n",
    "        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
    "        ax[i // 4, i % 4].set_title(label)\n",
    "        ax[i // 4, i % 4].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b04141fedb9fc1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Train Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    prediction_model = keras.models.Model(model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output)\n",
    "\n",
    "    checkpoint = ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n",
    "    early_stopping = EarlyStopping(patience=3, restore_best_weights=True)\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=[checkpoint, early_stopping])    \n",
    "    return prediction_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default\n",
    "# model = testing_models.build_model_default(IMAGE_WIDTH, IMAGE_HEIGHT, char, MODEL_NAME)\n",
    "\n",
    "char = len(tokenizer.char_to_num.get_vocabulary())\n",
    "model = testing_models.build_model9v3(IMAGE_WIDTH, IMAGE_HEIGHT, char)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "prediction_model, history = train_model(model)\n",
    "\n",
    "total_duration = time.time() - start_time\n",
    "print(\"Gesamte Trainingsdauer: {time}s\".format(time=round(total_duration)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d09077ade6432b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, name, dir_path, save_fig):\n",
    "    \"\"\"\n",
    "    Plottet die Historie des Trainings eines Models und speichert die in einem Verzeichnis ab \n",
    "\n",
    "    :param history: Das trainierte Modell\n",
    "    :param name: Name, wie das Modell gespeicht werden soll\n",
    "    :param name: Verzeichniss, wo der Plot gespeichert weren soll\n",
    "    :return: void\n",
    "    \"\"\"\n",
    "    metrics = history.history\n",
    "    plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "    plt.legend(['loss', 'val_loss'])\n",
    "    \n",
    "    if save_fig:\n",
    "        plt.title('Name: '+name)\n",
    "        path = os.path.join(dir_path, name + '_history.png')\n",
    "        plt.savefig(path)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path_to_dir):\n",
    "    isExist = os.path.exists(path_to_dir)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_to_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b6ad48840858cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T09:01:46.809774700Z",
     "start_time": "2023-11-26T09:01:45.484417400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A utility function to decode the output of the network.\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    # Use greedy search. For complex tasks, you can use beam search.\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][:, :load_data.max_len]\n",
    "    # Iterate over the results and get back the text.\n",
    "    output_text = []\n",
    "    for res in results:\n",
    "        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n",
    "        res = tf.strings.reduce_join(tokenizer.num_to_char(res)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(res)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evaluation(name, dir_path, save_fig):\n",
    "    for batch in val_ds.take(1):\n",
    "        batch_images = batch[\"image\"]\n",
    "        _, ax = plt.subplots(4, 4, figsize=(32, 4))\n",
    "\n",
    "        preds = prediction_model.predict(batch_images)\n",
    "        pred_texts = decode_batch_predictions(preds)\n",
    "\n",
    "        for i in range(16):\n",
    "            img = batch_images[i]\n",
    "            img = tf.image.flip_left_right(img)\n",
    "            img = tf.transpose(img, perm=[1, 0, 2])\n",
    "            img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n",
    "            img = img[:, :, 0]\n",
    "\n",
    "            title = f\"Prediction: {pred_texts[i]}\"\n",
    "            ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
    "            ax[i // 4, i % 4].set_title(title)\n",
    "            ax[i // 4, i % 4].axis(\"off\")   \n",
    "    if save_fig:\n",
    "        path = os.path.join(dir_path, name + '_result.png')\n",
    "        plt.savefig(path)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_with_model_name = [file for file in os.listdir(TEST_RESULT_DIR_NAME) if MODEL_NAME in file]\n",
    "metrics = history.history\n",
    "\n",
    "NAME = \"{name}_{epoch}E_{height}H_{width}W_{loss}L_{val_loss}VL_{time}s\".format(\n",
    "    name=MODEL_NAME, epoch=history.epoch[-1], height=IMAGE_HEIGHT, width=IMAGE_WIDTH,\n",
    "    loss=round(metrics['loss'][-1],2), val_loss=round(metrics['val_loss'][-1], 2), time=round(total_duration))\n",
    "\n",
    "if not files_with_model_name:\n",
    "    if SAVE_HISTORY:\n",
    "        if not os.path.exists(TEST_RESULT_DIR_NAME):\n",
    "            create_dir(TEST_RESULT_DIR_NAME)\n",
    "        plot_history(history, NAME, TEST_RESULT_DIR_NAME, True)\n",
    "        plot_evaluation(NAME, TEST_RESULT_DIR_NAME, True)\n",
    "else:\n",
    "    plot_history(history, name=None, dir_path=None, save_fig=False)\n",
    "    plot_evaluation(name=None, dir_path=None, save_fig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f26ab3b04550af2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3721ecbe52011",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T09:08:38.722886300Z",
     "start_time": "2023-11-26T09:08:38.635372800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODEL_SAVE:\n",
    "    if not os.path.exists(MODEL_DIR_NAME):\n",
    "        create_dir(MODEL_DIR_NAME)\n",
    "    model.save(os.path.join(MODEL_DIR_NAME, \"{model_name}\".format(model_name=MODEL_NAME)))\n",
    "    model.save_weights(os.path.join(MODEL_DIR_NAME, \"weights.keras\"), overwrite=True, save_format=None, options=None)\n",
    "    json_string = model.to_json()\n",
    "\n",
    "    with open(os.path.join(MODEL_DIR_NAME, \"model\"),'w') as f:\n",
    "        f.write(json_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
