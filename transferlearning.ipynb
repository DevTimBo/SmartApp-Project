{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = set()\n",
    "max_len = 0\n",
    "base_path = \"data_zettel/cropped_images/\"  # gets overwritten by config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    data_list = []\n",
    "    image_files = [f for f in os.listdir(base_path) if f.endswith('.jpg')]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_name = os.path.splitext(image_file)[0]\n",
    "\n",
    "        img_path = os.path.join(base_path, image_file)\n",
    "        label_file = os.path.join(base_path, f\"{image_name}.txt\")\n",
    "\n",
    "        if os.path.exists(label_file):\n",
    "            with open(label_file, \"r\", encoding=\"utf-8\") as file:\n",
    "                line = file.readline().strip()\n",
    "                data_list.append((img_path, line))\n",
    "\n",
    "    #np.random.shuffle(data_list) # Rausgenommen zum testen\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary_length(data):\n",
    "    characters = set()\n",
    "    max_len = 0\n",
    "\n",
    "    for _, label in data:\n",
    "        for char in label:\n",
    "            characters.add(char)\n",
    "\n",
    "        max_len = max(max_len, len(label))\n",
    "\n",
    "    characters = sorted(list(characters))\n",
    "\n",
    "    print(\"Maximum length: \", max_len)\n",
    "    print(\"Vocab size: \", len(characters))\n",
    "    return characters, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_paths_and_labels(samples):\n",
    "    x_img_paths = []\n",
    "    y_labels = []\n",
    "\n",
    "    for img_path, label in samples:\n",
    "        if os.path.exists(img_path):\n",
    "            x_img_paths.append(img_path)\n",
    "            y_labels.append(label)\n",
    "\n",
    "    return x_img_paths, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(lines_list):\n",
    "    split_idx = int(0.9 * len(lines_list))\n",
    "    train_samples = lines_list[:split_idx]\n",
    "    test_samples = lines_list[split_idx:]\n",
    "\n",
    "    val_split_idx = int(0.5 * len(test_samples))\n",
    "    validation_samples = test_samples[:val_split_idx]\n",
    "    test_samples = test_samples[val_split_idx:]\n",
    "\n",
    "    return train_samples, test_samples, validation_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length:  47\n",
      "Vocab size:  72\n"
     ]
    }
   ],
   "source": [
    "data = read_data()\n",
    "all_data = read_data()\n",
    "characters, max_len = get_vocabulary_length(all_data)\n",
    "train_samples, test_samples, validation_samples = split_data(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train samples: 2114\n",
      "Total validation samples: 117\n",
      "Total test samples: 118\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total train samples: {len(train_samples)}\")\n",
    "print(f\"Total validation samples: {len(validation_samples)}\")\n",
    "print(f\"Total test samples: {len(test_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_img_paths, y_train_labels = get_image_paths_and_labels(train_samples)\n",
    "\n",
    "x_val_img_paths, y_val_labels = get_image_paths_and_labels(validation_samples)\n",
    "\n",
    "test_path, test_label = get_image_paths_and_labels(test_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length:  47\n",
      "Vocab size:  69\n"
     ]
    }
   ],
   "source": [
    "# Has to be here because load data functions need to be called before\n",
    "import handwriting.tokenizer as tokenizer\n",
    "import handwriting.custom_image_generator as cgi\n",
    "\n",
    "# takes eternity\n",
    "#x_train, y_train = tokenizer.prepare_data(x_train_img_paths, y_train_labels) \n",
    "#x_test, y_test = tokenizer.prepare_data(x_test_img_paths, y_test_labels)\n",
    "\n",
    "#train_generator = cgi.CustomImageGenerator(x_train_img_paths, y_train_labels, BATCH_SIZE, IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "\n",
    "train_ds = tokenizer.prepare_dataset(x_train_img_paths, y_train_labels, (512,64), 32)\n",
    "val_ds = tokenizer.prepare_dataset(x_val_img_paths, y_val_labels,(512,64), 32)\n",
    "#test_ds = tokenizer.prepare_dataset(x_test_img_paths, y_test_labels,(IMAGE_WIDTH,IMAGE_HEIGHT),BATCH_SIZE)\n",
    "#aug_train_ds = tokenizer.prepare_augmented_dataset(x_train_img_paths, y_train_labels, BATCH_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple-htr-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
