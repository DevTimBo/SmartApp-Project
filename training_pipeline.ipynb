{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95664aeebf3aaa3f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c2e25903326405",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T13:34:01.885153300Z",
     "start_time": "2024-01-09T13:34:01.861292800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils.configs as Config\n",
    "config_path = \"utils/configs.json\"\n",
    "config = Config.Config(config_path)\n",
    "\n",
    "\n",
    "SHOULD_TRAIN = bool(config.get_pipeline_parameter()[\"training\"])\n",
    "SHOULD_PLOT = bool(config.get_pipeline_parameter()[\"plotting\"])\n",
    "BB_MODEL_NO = config.get_pipeline_parameter()[\"bb_model\"]\n",
    "HW_MODEL_NO = config.get_pipeline_parameter()[\"handwriting_model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eaf4da49f14168",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "importing the required packages and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T13:34:06.873841600Z",
     "start_time": "2024-01-09T13:34:02.759731100Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "import keras_cv\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from tensorflow import keras\n",
    "from keras_cv import bounding_box\n",
    "from keras_cv import visualization\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ddde87861bb7c4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Globale Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c64569232484acbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T13:34:08.353084900Z",
     "start_time": "2024-01-09T13:34:08.337523400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = 'bounding_box/workspace'\n",
    "ANNOTATION_PATH = WORKSPACE_PATH+'/annotations'\n",
    "ORIGINAL_ANNOTATION_PATH = ANNOTATION_PATH+'/original'\n",
    "IMAGE_PATH = WORKSPACE_PATH+'/images'\n",
    "ORIGINAL_IMAGE_PATH = IMAGE_PATH+'/original'\n",
    "MODEL_PATH = WORKSPACE_PATH+'/models'\n",
    "TEST_IMAGE_PATH = IMAGE_PATH +'/Bilder'\n",
    " \n",
    "SPLIT_RATIO = 0.2\n",
    "BATCH_SIZE = 2\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCH = 5\n",
    "GLOBAL_CLIPNORM = 10.0\n",
    "NEW_HEIGHT = 640\n",
    "NEW_WIDTH = 640  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a6913913a7c628",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f0ef724d142aa2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_ids = [\n",
    "\"Ausbildung\",\n",
    "\"Ausbildung_Klasse\" ,\n",
    "\"Ausbildung_Antrag_gestellt_ja\" ,\n",
    "\"Ausbildung_Antrag_gestellt_nein\" ,\n",
    "\"Ausbildung_Amt\" ,\n",
    "\"Ausbildung_Foerderungsnummer\" ,\n",
    "\"Ausbilung_Abschluss\" ,\n",
    "\"Ausbildung_Vollzeit\" ,\n",
    "\"Ausbildung\" ,\n",
    "\"Ausbildung_Teilzeit\" ,\n",
    "\"Ausbildung_Staette\" ,\n",
    "\"Person\" ,\n",
    "\"Person_Geburtsort\" ,\n",
    "\"Person_maennlich\" ,\n",
    "\"Person_Geburtsdatum\" ,\n",
    "\"Person_weiblich\",\n",
    "\"Person_divers\",\n",
    "\"Person_Name\",\n",
    "\"Person_Familienstand\" ,\n",
    "\"Person_Vorname\" ,\n",
    "\"Person_Geburtsname\" ,\n",
    "\"Person_Familienstand_seit\",\n",
    "\"Person_Stattsangehörigkeit_eigene\" ,\n",
    "\"Person_Stattsangehörigkeit_Ehegatte\" ,\n",
    "\"Person_Kinder\",\n",
    "\"Wohnsitz_Strasse\",\n",
    "\"Wohnsitz_Land\",\n",
    "\"Wohnsitz_Postleitzahl\",\n",
    "\"Wohnsitz\",\n",
    "\"Wohnsitz_Hausnummer\",\n",
    "\"Wohnsitz_Adresszusatz\",\n",
    "\"Wohnsitz_Ort\",\n",
    "\"Wohnsitz_waehrend_Ausbildung\" ,\n",
    "\"Wohnsitz_waehrend_Ausbildung_Strasse\",\n",
    "\"Wohnsitz_waehrend_Ausbildung_Hausnummer\",\n",
    "\"Wohnsitz_waehrend_Ausbildung_Land\",\n",
    "\"Wohnsitz_waehrend_Ausbildung_Ort\",\n",
    "\"Wohnsitz_waehrend_Ausbildung_elternwohnung_nein\",\n",
    "\"Wohnsitz_waehrend_Ausbildung_Adresszusatz\",\n",
    "\"Wohnsitz_waehrend_Ausbildung_Postleitzahl\",\n",
    "\"Wohnsitz_waehrend_Ausbildung_elternmiete\",\n",
    "\"Wohnsitz_waehrend_Ausbildung_elternwohnung_ja\",\n",
    "\"Wohnsitz_waehrend_Ausbildung_elternmiete_nein\"\n",
    "]\n",
    "sub_class_ids = [\n",
    "\"Ausbildung_Staette\" ,\n",
    "\"Ausbildung_Klasse\" ,\n",
    "\"Ausbildung_Antrag_gestellt_ja\" ,\n",
    "\"Ausbildung_Antrag_gestellt_nein\" ,\n",
    "\"Ausbildung_Amt\" ,\n",
    "\"Ausbildung_Foerderungsnummer\" ,\n",
    "\"Ausbilung_Abschluss\" ,\n",
    "\"Ausbildung_Vollzeit\" ,\n",
    "\"Ausbildung\" ,\n",
    "\"Ausbildung_Teilzeit\" ,\n",
    "\"Person_Geburtsort\" ,\n",
    "\"Person_maennlich\" ,\n",
    "\"Person_Geburtsdatum\" ,\n",
    "\"Person_weiblich\",\n",
    "\"Person_divers\",\n",
    "\"Person_Name\",\n",
    "\"Person_Familienstand\" ,\n",
    "\"Person_Vorname\" ,\n",
    "\"Person_Geburtsname\" ,\n",
    "\"Person_Familienstand_seit\",\n",
    "\"Person_Stattsangehörigkeit_eigene\" ,\n",
    "\"Person_Stattsangehörigkeit_Ehegatte\" ,\n",
    "\"Person_Kinder\",\n",
    "\"Wohnsitz_Strasse\",\n",
    "\"Wohnsitz_Land\",\n",
    "\"Wohnsitz_Postleitzahl\",\n",
    "\"Wohnsitz_Hausnummer\",\n",
    "\"Wohnsitz_Adresszusatz\",\n",
    "\"Wohnsitz_Ort\",\n",
    "\"Wohnsitz_waehrend_Ausbildung_Strasse\",\n",
    "\"Wohnsitz_waehrend_Ausbildung_Hausnummer\",\n",
    "\"Wohnsitz_waehrend_Ausbildung_Land\",\n",
    "\"Wohnsitz_waehrend_Ausbildung_Ort\",\n",
    "\"Wohnsitz_waehrend_Ausbildung_elternwohnung_nein\",\n",
    "\"Wohnsitz_waehrend_Ausbildung_Adresszusatz\",\n",
    "\"Wohnsitz_waehrend_Ausbildung_Postleitzahl\",\n",
    "\"Wohnsitz_waehrend_Ausbildung_elternmiete\",\n",
    "\"Wohnsitz_waehrend_Ausbildung_elternwohnung_ja\",\n",
    "\"Wohnsitz_waehrend_Ausbildung_elternmiete_nein\"\n",
    "]\n",
    "main_class_ids=[\n",
    "    \"Wohnsitz_waehrend_Ausbildung\" ,\n",
    "    \"Ausbildung\",\n",
    "    \"Person\" ,\n",
    "    \"Wohnsitz\",\n",
    "]\n",
    "\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))\n",
    "main_class_mapping = dict(zip(range(len(main_class_ids)), main_class_ids))\n",
    "sub_class_mapping = dict(zip(range(len(sub_class_ids)), sub_class_ids))\n",
    "print(class_mapping)\n",
    "print(main_class_mapping)\n",
    "print(sub_class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6758ef1fa42299",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get all XML file paths in path_annot and sort them\n",
    "xml_files = sorted(\n",
    "    [\n",
    "        os.path.join(ORIGINAL_ANNOTATION_PATH, file_name)\n",
    "        for file_name in os.listdir(ORIGINAL_ANNOTATION_PATH)\n",
    "        if file_name.endswith(\".xml\")\n",
    "    ]\n",
    ")\n",
    " \n",
    "# Get all JPEG image file paths in path_images and sort them\n",
    "jpg_files = sorted(\n",
    "    [\n",
    "        os.path.join(ORIGINAL_IMAGE_PATH, file_name)\n",
    "        for file_name in os.listdir(ORIGINAL_IMAGE_PATH)\n",
    "        if file_name.endswith(\".jpg\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b54ce7ddf2f5ab",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "parsing the XML annotation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66119d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_class_id(classes, cls):    \n",
    "    class_ids = [\n",
    "        list(class_mapping.keys())[list(class_mapping.values()).index(cls)]\n",
    "        for cls in classes\n",
    "    ]\n",
    "    return class_ids\n",
    "\n",
    "def create_box(bbox):\n",
    "    xmin = float(bbox.find(\"xmin\").text)\n",
    "    ymin = float(bbox.find(\"ymin\").text)\n",
    "    xmax = float(bbox.find(\"xmax\").text)\n",
    "    ymax = float(bbox.find(\"ymax\").text)\n",
    "    return [xmin, ymin, xmax, ymax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0b0dfa61d8a842",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_annotation(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    " \n",
    "    image_name = root.find(\"filename\").text\n",
    "    image_path = os.path.join(ORIGINAL_IMAGE_PATH, image_name)\n",
    "    \n",
    "    boxes = []\n",
    "    classes = []\n",
    "    main_classes = []\n",
    "    sub_classes = []\n",
    "    main_boxes = []\n",
    "    sub_boxes = []\n",
    "    for obj in root.iter(\"object\"):\n",
    "        cls = obj.find(\"name\").text\n",
    "        classes.append(cls)\n",
    " \n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        boxes.append( create_box(bbox))\n",
    "        #main labels\n",
    "        if (cls=='Wohnsitz_waehrend_Ausbildung')or(cls=='Ausbildung') or (cls =='Person') or (cls == 'Wohnsitz'):\n",
    "            main_classes.append(cls)\n",
    "            bbox = obj.find(\"bndbox\")\n",
    "            main_boxes.append( create_box(bbox))\n",
    "        else:\n",
    "            bbox = obj.find(\"bndbox\")\n",
    "            sub_boxes.append( create_box(bbox))\n",
    "            sub_classes.append(cls)\n",
    "            print(cls)\n",
    "    class_ids = map_class_id(classes, cls)\n",
    "    main_class_ids = map_class_id(main_classes, cls)            \n",
    "    sub_class_ids = map_class_id(sub_classes, cls)\n",
    "\n",
    "    return image_path, boxes, class_ids, main_class_ids, sub_class_ids, main_boxes, sub_boxes, image_name\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dd7af4378f4935",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "image_names = []\n",
    "bbox = []\n",
    "classes = []\n",
    "main_classes = []\n",
    "sub_classes= []\n",
    "main_bbox= []\n",
    "sub_bbox= []\n",
    "for xml_file in tqdm(xml_files):\n",
    "    image_path, boxes, class_ids, main_class_ids,sub_class_ids, main_boxes, sub_boxes, image_name = parse_annotation(xml_file)\n",
    "    image_paths.append(image_path)\n",
    "    bbox.append(boxes)\n",
    "    classes.append(class_ids)\n",
    "    image_names.append(image_name)\n",
    "\n",
    "    main_classes.append(main_class_ids)\n",
    "    sub_classes.append(sub_class_ids)\n",
    "    main_bbox.append(main_boxes)\n",
    "    sub_bbox.append(sub_boxes)\n",
    "\n",
    "arr=np.array(sub_bbox)\n",
    "print(arr.shape)\n",
    "subset_image_paths_all=image_paths\n",
    "subset_class_ids_all=sub_classes\n",
    "subset_boxes_all=sub_bbox\n",
    "print(subset_class_ids_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155d91e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_imgaes(input_path, output_path, height, width):\n",
    "    image =  cv2.imread(input_path)\n",
    "    resized_image = cv2.resize(image, (width, height))\n",
    "    cv2.imwrite(output_path, resized_image)    \n",
    "    \n",
    "def scale_bounding_boxes(input_path,bounding_boxes, height, width):\n",
    "    image =  cv2.imread(input_path)\n",
    "\n",
    "    height_ratio = height / image.shape[0]\n",
    "    width_ratio = width / image.shape[1]\n",
    "    resized_boxes_for_one_image=[]\n",
    "    #for box in bounding_boxes:\n",
    "    resized_boxes = []\n",
    "    x_min = (bounding_boxes[0]*width_ratio)\n",
    "    y_min = (bounding_boxes[1]*height_ratio)\n",
    "    x_max = (bounding_boxes[2]*width_ratio)\n",
    "    y_max = (bounding_boxes[3]*height_ratio)\n",
    "    #resized_boxes.append([x_min,y_min,x_max,y_max])\n",
    "    #resized_boxes_for_one_image.append(resized_boxes)\n",
    "    return [x_min,y_min,x_max,y_max]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dc7bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Images from main_classes\n",
    "IMAGES_MAIN_CLASSES_PATH = IMAGE_PATH +'/640x640_main_classes'\n",
    "\n",
    "def create_main_images(input_path, output_path, box):\n",
    "    startY, endY, startX, endX = int(np.round(box[1])), int(np.round(box[3])), int(np.round(box[0])), int(np.round(box[2]))\n",
    "    image =  cv2.imread(input_path)\n",
    "    cropped_image = image[startY:endY, startX:endX]\n",
    "    cv2.imwrite(output_path, cropped_image)  \n",
    "\n",
    "box_ratio_factors = []\n",
    "sub_box_calculated = []\n",
    "main_images_paths = []\n",
    "main_image_names = []\n",
    "\n",
    "def calculate_box_ratio_factor(image_path,box):\n",
    "    image = cv2.imread(image_path)\n",
    "    width = image.shape[0]\n",
    "    height = image.shape[1]\n",
    "    box[2], box[2], box[2], box[2]\n",
    "    relative_xbl = box[0] #/ width\n",
    "    relative_ybl = box[1] #/ height\n",
    "    relative_xtr = box[2] #/ width\n",
    "    relative_ytr = box[3] #/ height\n",
    "    return [relative_xbl,relative_ybl,relative_xtr,relative_ytr]\n",
    "\n",
    "def array_calculation(sub_box, main_box):\n",
    "    return [sub_box[0]-main_box[0],sub_box[1]-main_box[1],sub_box[2]-main_box[0],sub_box[3]-main_box[1]]\n",
    "\n",
    "#Bilder ausschneiden und speichern\n",
    "for i in range(len(main_class_ids)):\n",
    "    for j in range(len(image_paths)):\n",
    "        box_ratio_factors.append(calculate_box_ratio_factor(image_paths[j], main_bbox[j][i]))\n",
    "        create_main_images(image_paths[j],IMAGES_MAIN_CLASSES_PATH+'/'+str(i)+'_'+str(j)+'.jpg', main_bbox[j][i])\n",
    "        main_images_paths.append(IMAGES_MAIN_CLASSES_PATH+'/'+str(i)+'_'+str(j)+'.jpg')\n",
    "        main_image_names.append(str(i)+'_'+str(j)+'.jpg')\n",
    "\n",
    "#Resize Images auf 640x640\n",
    "subsset_scaled_image_paths = []\n",
    "for img in range(len(main_images_paths)):\n",
    "    resize_imgaes(main_images_paths[img], IMAGE_PATH+ '/640x640_main_classes_scaled/' +main_image_names[img], 640, 640)\n",
    "    subsset_scaled_image_paths.append(IMAGE_PATH+ '/640x640_main_classes_scaled/' +main_image_names[img])\n",
    "#print(subsset_scaled_image_paths)\n",
    "\n",
    "#Anpassen der Bounding Box Koordinaten zu dem jeweiligen Bildausschnitt\n",
    "for i in range(len(main_class_ids)):\n",
    "    for j in range(len(image_paths)):\n",
    "        for k in range(len(sub_class_ids)):\n",
    "            sub_box_calculated.append(array_calculation(sub_bbox[j][k], main_bbox[j][i]))\n",
    "\n",
    "\n",
    "\n",
    "sub_boxes_main_class_1=[]  \n",
    "sub_boxes_main_class_2=[] \n",
    "sub_boxes_main_class_3=[] \n",
    "sub_boxes_main_class_4=[] \n",
    "sub_boxes_all_main_classes=[]\n",
    "\n",
    "scaled_sub_boxes_main_class_1=[]  \n",
    "scaled_sub_boxes_main_class_2=[] \n",
    "scaled_sub_boxes_main_class_3=[] \n",
    "scaled_sub_boxes_main_class_4=[] \n",
    "\n",
    "#Boxen im Verhältnis der main_box zu 640x640 scalen\n",
    "for i in range(len(image_names)): #18 Bilder\n",
    "    for j in range(len(sub_class_ids)): #38 Klassen\n",
    "        arr=[]\n",
    "        if j < 10: #Ausbildung\n",
    "            sub_boxes_main_class_1.append(array_calculation(sub_bbox[i][j], main_bbox[i][0]))\n",
    "            scaled_sub_boxes_main_class_1.append(scale_bounding_boxes(main_images_paths[i],sub_boxes_main_class_1[i],640,640))\n",
    "\n",
    "        elif (j >= 10) and (j <= 21) :#Person\n",
    "            sub_boxes_main_class_2.append(array_calculation(sub_bbox[i][j], main_bbox[i][1]))\n",
    "            scaled_sub_boxes_main_class_2.append(scale_bounding_boxes(main_images_paths[i+18],sub_boxes_main_class_2[i],640,640))\n",
    "        elif (j >= 22) and (j <= 27) :#Wohnsitz\n",
    "            #sub_boxes_main_class_3.append(sub_bbox[i][j])\n",
    "            sub_boxes_main_class_3.append(array_calculation(sub_bbox[i][j], main_bbox[i][2]))\n",
    "            scaled_sub_boxes_main_class_3.append(scale_bounding_boxes(main_images_paths[i+36],sub_boxes_main_class_3[i],640,640))\n",
    "        elif (j >= 28) and (j <= 37) :#Wohnsitz_während_Ausildung\n",
    "            sub_boxes_main_class_4.append(array_calculation(sub_bbox[i][j], main_bbox[i][3]))\n",
    "            scaled_sub_boxes_main_class_4.append(scale_bounding_boxes(main_images_paths[i+54],sub_boxes_main_class_4[i],640,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33321ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, boxes):\n",
    "    image = cv2.imread(image)\n",
    "\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)) \n",
    "\n",
    "    # Bounding Boxes zeichnen\n",
    "    for box in boxes:\n",
    "        xmin, ymin, xmax, ymax = map(int, box)\n",
    "        rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8380d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(main_images_paths[0],sub_boxes_main_class_1)\n",
    "show_image(main_images_paths[18],sub_boxes_main_class_2)\n",
    "show_image(main_images_paths[36],sub_boxes_main_class_3)\n",
    "show_image(main_images_paths[54],sub_boxes_main_class_4)\n",
    "\n",
    "show_image(subsset_scaled_image_paths[0],scaled_sub_boxes_main_class_1)\n",
    "show_image(subsset_scaled_image_paths[18],scaled_sub_boxes_main_class_2)\n",
    "show_image(subsset_scaled_image_paths[36],scaled_sub_boxes_main_class_3)\n",
    "show_image(subsset_scaled_image_paths[54],scaled_sub_boxes_main_class_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5a3312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 4 datasets\n",
    "#image_paths\n",
    "#shape(18,x)\n",
    "subset_images_paths_1 = []\n",
    "subset_images_paths_2 = []\n",
    "subset_images_paths_3 = []\n",
    "subset_images_paths_4 = []\n",
    "for i in range(len(subsset_scaled_image_paths)):\n",
    "        if i < 18: #Ausbildung\n",
    "            subset_images_paths_1.append(subsset_scaled_image_paths[i])\n",
    "        elif (i >= 18) and (i <= 35) :#Person\n",
    "            subset_images_paths_2.append(subsset_scaled_image_paths[i])\n",
    "        elif (i >= 36) and (i <= 53) :#Wohnsitz\n",
    "            subset_images_paths_3.append(subsset_scaled_image_paths[i])\n",
    "        elif (i >= 54) and (i <= 73) :#Wohnsitz_während_Ausildung\n",
    "            subset_images_paths_4.append(subsset_scaled_image_paths[i])\n",
    "#classes\n",
    "subset_class_ids_1_1 = []\n",
    "subset_class_ids_2_2 = []\n",
    "subset_class_ids_3_3 = []\n",
    "subset_class_ids_4_4 = []\n",
    "subset_class_ids_1 = []\n",
    "subset_class_ids_2 = []\n",
    "subset_class_ids_3 = []\n",
    "subset_class_ids_4 = []\n",
    "classes=[]\n",
    "#shape(18,x)\n",
    "for i in range(len(subset_class_ids_all[0])):\n",
    "        if i < 10: #Ausbildung\n",
    "                subset_class_ids_1_1.append(subset_class_ids_all[0][i])\n",
    "        elif (i >= 10) and (i <= 21) :#Person\n",
    "                subset_class_ids_2_2.append(subset_class_ids_all[0][i])\n",
    "        elif (i >= 22) and (i <= 27) :#Wohnsitz\n",
    "                subset_class_ids_3_3.append(subset_class_ids_all[0][i])\n",
    "        elif (i >= 28) and (i <= 37) :#Wohnsitz_während_Ausildung\n",
    "                subset_class_ids_4_4.append(subset_class_ids_all[0][i])\n",
    "\n",
    "for i in range (0,18):\n",
    "    subset_class_ids_1.append(subset_class_ids_1_1)\n",
    "    subset_class_ids_2.append(subset_class_ids_2_2)\n",
    "    subset_class_ids_3.append(subset_class_ids_3_3)\n",
    "    subset_class_ids_4.append(subset_class_ids_4_4)\n",
    "\n",
    "#boxen\n",
    "subset_boxes_1 = []\n",
    "subset_boxes_2 = []\n",
    "subset_boxes_3 = []\n",
    "subset_boxes_4 = []\n",
    "#shape(18,x,4)\n",
    "\n",
    "\n",
    "arr= np.array(scaled_sub_boxes_main_class_1)\n",
    "arr_1=arr.reshape(18,10,4)\n",
    "for j in range(0,18):\n",
    "    arr_1_1=[]\n",
    "    for i in range(0,10):\n",
    "        arr_1_1.append(arr_1[i][0])\n",
    "    subset_boxes_1.append(arr_1_1)\n",
    "\n",
    "arr= np.array(scaled_sub_boxes_main_class_2)\n",
    "arr_2=arr.reshape(18,12,4)\n",
    "for j in range(0,18):\n",
    "    arr_1_1=[]\n",
    "    for i in range(0,12):\n",
    "        arr_1_1.append(arr_2[i][0])\n",
    "    subset_boxes_2.append(arr_1_1)\n",
    "\n",
    "arr= np.array(scaled_sub_boxes_main_class_3)\n",
    "arr_3=arr.reshape(18,6,4)\n",
    "for j in range(0,18):\n",
    "    arr_1_1=[]\n",
    "    for i in range(0,6):\n",
    "        arr_1_1.append(arr_3[i][0])\n",
    "    subset_boxes_3.append(arr_1_1)\n",
    "\n",
    "arr= np.array(scaled_sub_boxes_main_class_4)\n",
    "arr_4=arr.reshape(18,10,4)\n",
    "for j in range(0,18):\n",
    "    arr_1_1=[]\n",
    "    for i in range(0,10):\n",
    "        arr_1_1.append(arr_4[i][0])\n",
    "    subset_boxes_4.append(arr_1_1)\n",
    "\n",
    "print(subset_class_ids_1)\n",
    "arr=np.array(subset_class_ids_4)\n",
    "print(arr.shape)\n",
    "arrs=np.array(subset_class_ids_1)\n",
    "print(arrs.shape)\n",
    "arrf=np.array(subset_boxes_1)\n",
    "print(arrf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae1f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conc_paths = np.concatenate((subset_images_paths_1, subset_images_paths_2, subset_images_paths_3, subset_images_paths_4), axis=0)\n",
    "#print(conc_paths.shape)\n",
    "#conc_boxes = np.concatenate((subset_boxes_1, subset_boxes_2, subset_boxes_3, subset_boxes_4), axis=1)\n",
    "#print(conc_boxes.shape)\n",
    "#conc_classes = np.concatenate(( subset_class_ids_1, subset_class_ids_2, subset_class_ids_3, subset_class_ids_4), axis=1)\n",
    "#print(conc_classes.shape)\n",
    "\n",
    "classes=[]\n",
    "images=[]\n",
    "box=[]\n",
    "#shape (72,) subset aus 4 main_boxen\n",
    "for i in range(len(subset_boxes_1)):\n",
    "    box.append(subset_boxes_1[i])\n",
    "    images.append(subset_images_paths_1[i])\n",
    "    classes.append(subset_class_ids_1[i])\n",
    "for i in range(len(subset_boxes_2)):\n",
    "    box.append(subset_boxes_2[i])\n",
    "    images.append(subset_images_paths_2[i])\n",
    "    classes.append(subset_class_ids_2[i])\n",
    "for i in range(len(subset_boxes_3)):\n",
    "    box.append(subset_boxes_3[i])\n",
    "    images.append(subset_images_paths_3[i])\n",
    "    classes.append(subset_class_ids_3[i])\n",
    "for i in range(len(subset_boxes_4)):\n",
    "    box.append(subset_boxes_4[i])\n",
    "    images.append(subset_images_paths_4[i])\n",
    "    classes.append(subset_class_ids_4[i])\n",
    "\n",
    "#hinzugügen des sets der ganzen Seite\n",
    "for i in range(len(subset_boxes_all)):\n",
    "    box.append(subset_boxes_all[i])\n",
    "    images.append(subset_image_paths_all[i])\n",
    "    classes.append(subset_class_ids_all[i])\n",
    "\n",
    "arr=np.array(subset_boxes_1)\n",
    "print(arr.shape)\n",
    "print(len(classes))\n",
    "print(classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a6c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_tensor(image_paths,classes,bbox):\n",
    "    bbox = tf.ragged.constant(bbox, dtype=tf.float32)\n",
    "    classes = tf.ragged.constant(classes, dtype=tf.int64)\n",
    "    image_paths = tf.ragged.constant(image_paths, dtype=tf.string)\n",
    "    data = tf.data.Dataset.from_tensor_slices((image_paths, classes, bbox))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ed64ac0efe7e20",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merged_sub_data = create_data_tensor(merged_paths, merged_classes, merged_boxes)\n",
    "\n",
    "new_sub_data_all = create_data_tensor(images,classes, box )\n",
    "\n",
    "#new_sub_data_all = create_data_tensor(subset_image_paths_all, subset_class_ids_all, subset_boxes_all)\n",
    "\n",
    "new_sub_data_1 = create_data_tensor(subset_images_paths_1, subset_class_ids_1, subset_boxes_1)\n",
    "new_sub_data_2 = create_data_tensor(subset_images_paths_2, subset_class_ids_2, subset_boxes_2)\n",
    "new_sub_data_3 = create_data_tensor(subset_images_paths_3, subset_class_ids_3, subset_boxes_3)\n",
    "new_sub_data_4 = create_data_tensor(subset_images_paths_4, subset_class_ids_4, subset_boxes_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a780ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_data(split, data_tensor):\n",
    "    num_val = int(split * SPLIT_RATIO)#int(len(image_path_list)\n",
    "    val_data = data_tensor.take(num_val)\n",
    "    train_data = data_tensor.skip(num_val)\n",
    "    return val_data, train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e100a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bilder durchmischen\n",
    "new_sub_data_all = new_sub_data_all.shuffle(90, reshuffle_each_iteration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a0ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub_val_data_all,sub_train_data_all  = create_train_test_data(18 , zipped_ds)\n",
    "\n",
    "\n",
    "sub_val_data_all, sub_train_data_all  = create_train_test_data(90 , new_sub_data_all)\n",
    "\n",
    "sub_val_data_1, sub_train_data_1  = create_train_test_data(18 , new_sub_data_1)\n",
    "sub_val_data_2, sub_train_data_2  = create_train_test_data(18 , new_sub_data_2)\n",
    "sub_val_data_3, sub_train_data_3  = create_train_test_data(18 , new_sub_data_3)\n",
    "sub_val_data_4, sub_train_data_4  = create_train_test_data(18 , new_sub_data_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59876dac6b8109d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    return image\n",
    " \n",
    "\n",
    "def load_dataset(image_path, classes, bbox):\n",
    "    # Read Image\n",
    "    image = load_image(image_path)\n",
    "    bounding_boxes = {\n",
    "        \"classes\": tf.cast(classes, dtype=tf.float32),\n",
    "        \"boxes\": bbox,\n",
    "    }\n",
    "    return {\"images\": tf.cast(image, tf.float32), \"bounding_boxes\": bounding_boxes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fbff8fae67f4f5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "augmenter = keras.Sequential(\n",
    "    layers=[\n",
    "        #keras_cv.layers.RandomFlip(mode=\"horizontal\", bounding_box_format=\"xyxy\"),\n",
    "        #keras_cv.layers.RandomRotation(factor=0.2, bounding_box_format=\"xyxy\"),\n",
    "        keras_cv.layers.JitteredResize(\n",
    "            target_size=(640, 640),\n",
    "            scale_factor=(1, 1),\n",
    "            bounding_box_format=\"xyxy\",\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d8b76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_ds(train_data):\n",
    "    train_ds = train_data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_ds = train_ds.shuffle(BATCH_SIZE * 8)\n",
    "    train_ds = train_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
    "    train_ds = train_ds.map(augmenter, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bee2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sub_train_data_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b552c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_ds_all = create_train_ds(sub_train_data_all)\n",
    "\n",
    "sub_train_ds_1 = create_train_ds(sub_train_data_1)\n",
    "sub_train_ds_2 = create_train_ds(sub_train_data_2)\n",
    "sub_train_ds_3 = create_train_ds(sub_train_data_3)\n",
    "sub_train_ds_4 = create_train_ds(sub_train_data_4)\n",
    "\n",
    "#sub_trains_ds_zipped = tf.data.Dataset.zip(sub_train_ds_all, sub_train_ds_1, sub_train_ds_2, sub_train_ds_3, sub_train_ds_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715c4d13d07a9021",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resizing = keras_cv.layers.JitteredResize(\n",
    "    target_size=(640, 640),\n",
    "    scale_factor=(1, 1),\n",
    "    bounding_box_format=\"xyxy\",\n",
    ")\n",
    "\n",
    "def create_val_ds(val_data):\n",
    "    val_ds = val_data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.shuffle(BATCH_SIZE * 8)\n",
    "    val_ds = val_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
    "    val_ds = val_ds.map(resizing, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9dfa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_val_ds_all= create_train_ds(sub_val_data_all)\n",
    "\n",
    "sub_val_ds_1 = create_train_ds(sub_val_data_1)\n",
    "sub_val_ds_2 = create_train_ds(sub_val_data_2)\n",
    "sub_val_ds_3 = create_train_ds(sub_val_data_3)\n",
    "sub_val_ds_4 = create_train_ds(sub_val_data_4)\n",
    "\n",
    "#sub_val_ds_zipped = tf.data.Dataset.zip(sub_val_ds_all, sub_val_ds_1, sub_val_ds_2, sub_val_ds_3, sub_val_ds_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7dfd9ee0435599",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualize_dataset(inputs, value_range, rows, cols, bounding_box_format):\n",
    "    inputs = next(iter(inputs.take(1)))\n",
    "    images, bounding_boxes = inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
    "    visualization.plot_bounding_box_gallery(\n",
    "        images,\n",
    "        value_range=value_range,\n",
    "        rows=rows,\n",
    "        cols=cols,\n",
    "        y_true=bounding_boxes,\n",
    "        scale=5,\n",
    "        font_scale=0.2,\n",
    "        bounding_box_format=bounding_box_format,\n",
    "        class_mapping=class_mapping,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a4d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset(sub_train_ds_all, bounding_box_format=\"xyxy\", value_range=(0, 255), rows=1, cols=2)\n",
    "visualize_dataset(sub_val_ds_all, bounding_box_format=\"xyxy\", value_range=(0, 255), rows=1, cols=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ed721cc85379c1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dict_to_tuple(inputs):\n",
    "    return inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
    "\n",
    "def create_train_val_tuple(train_ds,val_ds):\n",
    "    train_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return train_ds, val_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d4805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_ds_all,sub_val_ds_all=create_train_val_tuple(sub_train_ds_all,sub_val_ds_all)\n",
    "sub_train_ds_1,sub_val_ds_1=create_train_val_tuple(sub_train_ds_1,sub_val_ds_1)\n",
    "sub_train_ds_2,sub_val_ds_2=create_train_val_tuple(sub_train_ds_2,sub_val_ds_2)\n",
    "sub_train_ds_3,sub_val_ds_3=create_train_val_tuple(sub_train_ds_3,sub_val_ds_3)\n",
    "sub_train_ds_4,sub_val_ds_4=create_train_val_tuple(sub_train_ds_4,sub_val_ds_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e170d82fe24bd7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "define backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9aa6f584e4c14f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def define_backbone(backbone):\n",
    "    backbone = keras_cv.models.YOLOV8Backbone.from_preset(\n",
    "        \"yolo_v8_xs_backbone_coco\",\n",
    "         load_weights=True \n",
    "    )\n",
    "    return backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c96ab8f16010f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9df5fe5c59a00aa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def define_optimizer():\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        global_clipnorm=GLOBAL_CLIPNORM, #This ensures that gradients, which influence the model’s parameter updates, \n",
    "                                        # don’t become exceedingly large and destabilize training.\n",
    "    )\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcd6e9a7ee37a17",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "define YOLO8Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e5f43561951061",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def define_model(num_classes):\n",
    "    model = keras_cv.models.YOLOV8Detector(\n",
    "    num_classes=num_classes, #the number of object classes\n",
    "    bounding_box_format=\"xyxy\",\n",
    "    backbone=define_backbone(\"yolo_v8_xs_backbone_coco\"),\n",
    "    fpn_depth=1,\n",
    ")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75549b0bd6aa448",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc71693c31705379",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    model.compile(\n",
    "    optimizer=define_optimizer(), \n",
    "    classification_loss=\"binary_crossentropy\", #calculates the discrepancy between anticipated class probabilities and actual class probabilities\n",
    "    box_loss=\"ciou\" # box_loss -> measure the difference between the predicted bounding boxes and the ground truth\n",
    "                    # he Complete IoU (CIoU) metric is used, which not only measures the overlap between predicted and ground truth bounding \n",
    "                    # boxes but also considers the difference in aspect ratio, center distance, and box size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd02b3a86101acca",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc14bcd28e72b7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss',  \n",
    "                               patience=3,          \n",
    "                               restore_best_weights=True)  \n",
    "\n",
    "callbacks = [early_stopping]\n",
    "\n",
    "def fit_model(model, train_data, validation_data):\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        validation_data=validation_data,\n",
    "        epochs=EPOCH,\n",
    "        callbacks=early_stopping,\n",
    "        #callbacks=[EvaluateCOCOMetricsCallback(val_ds, \"workspace/models/yolo_coco_model.h5\")],\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7d3178697d79ba",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "define NonMaxSuppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41d60b0d51b9293",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def define_NonMaxSuppression(model):\n",
    "    model.prediction_decoder = keras_cv.layers.NonMaxSuppression(\n",
    "        bounding_box_format=\"xyxy\",\n",
    "        from_logits=True,\n",
    "        iou_threshold=0.9,\n",
    "        confidence_threshold=0.5\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab3681e4f8e05b4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "define a base model, compile the base model and then loads the weights from a path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f882e067f7329069",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_weight_model(model_path):\n",
    "    base_model = define_model(len(class_mapping))\n",
    "    compile_model(base_model)\n",
    "    loaded_model = base_model.load_weights(model_path)\n",
    "    return  loaded_model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6d40400ff2d63b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "save weights of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47feba0eebb6d985",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_weights(model, name):\n",
    "    save_model_path = MODEL_PATH + name\n",
    "    model.save_weights(save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c0c1e8d8d2b27",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "define visualization methode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2516f2d228dcce8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualize_detections(model, dataset, bounding_box_format, class_mapping):\n",
    "    images, y_true = next(iter(dataset.take(1)))\n",
    "    y_pred = model.predict(images)\n",
    "    y_pred = bounding_box.to_ragged(y_pred)\n",
    "    visualization.plot_bounding_box_gallery(\n",
    "        images,\n",
    "        value_range=(0, 255),\n",
    "        bounding_box_format=bounding_box_format,\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        scale=5,\n",
    "        rows=1,\n",
    "        cols=1,\n",
    "        show=True,\n",
    "        font_scale=0.4,\n",
    "        class_mapping= class_mapping ,#class_mapping,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3796fc7867b4fe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "define and compile model for sub_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d04f885e2c1b782",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yolo_coco_sub = define_model(43)\n",
    "compile_model(yolo_coco_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6218a7e8c569fabd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "define and compile model for main_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d66bf3db6b01bc7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yolo_coco_main = define_model(len(main_class_mapping))\n",
    "compile_model(yolo_coco_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb8e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_MODEL_PATH = MODEL_PATH+'/main_bbox_detector_model.h5'\n",
    "\n",
    "#yolo_coco_main.load_weights(MAIN_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa1769fff44ecc0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "fit main_bbox_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9851752000ef9c7a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#main_bbox_history = fit_model(yolo_coco_main, main_train_ds, main_val_ds )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e0665310e4b897",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "fit sub_bbox_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9d130532e0fbb9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#yolo_coco_sub.fit(sub_trains_ds_zipped, epochs=5, validation_data=sub_val_ds_zipped)\n",
    "\n",
    "sub_bbox_history_all= fit_model(yolo_coco_sub,sub_train_ds_all,sub_val_ds_all )\n",
    "\n",
    "NEWSUB_5_SETS_MODEL_PATH = MODEL_PATH+'/new_sub_bbox_detector_model_5_datasets.h5'\n",
    "#yolo_coco_sub.save_weights(NEWSUB_5_SETS_MODEL_PATH)\n",
    "#yolo_coco_sub.load_weights(NEWSUB_5_SETS_MODEL_PATH)\n",
    "#sub_bbox_history_1 = fit_model(yolo_coco_sub, sub_train_ds_1, sub_val_ds_1 )\n",
    "\"\"\"\n",
    "yolo_coco_sub.save_weights(NEWSUB_5_SETS_MODEL_PATH)\n",
    "yolo_coco_sub.load_weights(NEWSUB_5_SETS_MODEL_PATH)\n",
    "sub_bbox_history_2 = fit_model(yolo_coco_sub, sub_train_ds_2, sub_val_ds_2 )\n",
    "yolo_coco_sub.save_weights(NEWSUB_5_SETS_MODEL_PATH)\n",
    "yolo_coco_sub.load_weights(NEWSUB_5_SETS_MODEL_PATH)\n",
    "sub_bbox_history_3 = fit_model(yolo_coco_sub, sub_train_ds_3, sub_val_ds_3 )\n",
    "yolo_coco_sub.save_weights(NEWSUB_5_SETS_MODEL_PATH)\n",
    "yolo_coco_sub.load_weights(NEWSUB_5_SETS_MODEL_PATH)\n",
    "sub_bbox_history_4 = fit_model(yolo_coco_sub, sub_train_ds_4, sub_val_ds_4 )\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4529b5fb",
   "metadata": {},
   "source": [
    "Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d999d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Box Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['box_loss'], label='Training Box Loss')\n",
    "    plt.plot(history.history['val_box_loss'], label='Validation Box Loss')\n",
    "    plt.title('Training and Validation Box Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Box Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Klassen Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['class_loss'], label='Training Class Loss')\n",
    "    plt.plot(history.history['val_class_loss'], label='Validation Class Loss')\n",
    "    plt.title('Training and Validation Class Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Class Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6406faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(sub_bbox_history_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cb0a670477657e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "visualization main bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39a74fd92642989",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#visualize_detections(yolo_coco_main, dataset=main_val_ds, bounding_box_format=\"xyxy\", class_mapping= main_class_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc464b76f7c4b71",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "visualization sub bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d209caeefc4f547",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_detections(yolo_coco_sub, dataset=sub_val_ds_all, bounding_box_format=\"xyxy\", class_mapping= class_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd044daa5edc01b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0b9e1271bfded2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAIN_MODEL_PATH = MODEL_PATH+'/main_bbox_detector_model.h5'\n",
    "\n",
    "#yolo_coco_main.save_weights(MAIN_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297ad9bcda410868",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "load model for sub_bbox and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa88f862ef2d6244",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#yolo_coco_sub.load_weights(MAIN_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a8f31b3f9f3c9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "visualize a prediction with loaded_sub_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb72e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_image(image_path, model):\n",
    "    image =  cv2.imread(image_path)\n",
    "    resized_image = cv2.resize(image, (640, 640))\n",
    "    resized_image = np.expand_dims(resized_image, axis=0)  \n",
    "\n",
    "    #predict\n",
    "    predictions = model.predict(resized_image)\n",
    "    boxes = predictions['boxes']\n",
    "    confidence = predictions['confidence']\n",
    "    classes = predictions['classes']\n",
    "    iou_threshold = 0.5\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "    for box, conf, cls in zip(boxes[0], confidence[0], classes[0]):\n",
    "        if conf > 0.1:\n",
    "            xmin, ymin, xmax, ymax = box\n",
    "            #label = f\"Class {cls} ({conf:.2f})\"\n",
    "            rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=1, edgecolor='r', facecolor='none')#, label=label)\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaac925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_image(image_path, model):\n",
    "    image = cv2.imread(image_path)\n",
    "    resized_image = cv2.resize(image, (640, 640))\n",
    "    resized_image = np.expand_dims(resized_image, axis=0)  \n",
    "\n",
    "    # Predict\n",
    "    predictions = model.predict(resized_image)\n",
    "    boxes = predictions['boxes']\n",
    "    confidence = predictions['confidence']\n",
    "    classes = predictions['classes']\n",
    "\n",
    "    sorted_indices = np.argsort(-confidence[0])  \n",
    "    boxes = boxes[0][sorted_indices]\n",
    "    confidence = confidence[0][sorted_indices]\n",
    "    classes = classes[0][sorted_indices]\n",
    "\n",
    "    unique_classes = np.unique(classes)\n",
    "    selected_indices = []\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        cls_indices = np.where(classes == cls)[0]\n",
    "        if len(cls_indices) > 0:\n",
    "            best_idx = cls_indices[0]  \n",
    "            selected_indices.append(best_idx)\n",
    "\n",
    "    selected_boxes = boxes[selected_indices]\n",
    "    selected_confidence = confidence[selected_indices]\n",
    "    selected_classes = classes[selected_indices]\n",
    "\n",
    "    iou_threshold = 0.5\n",
    "\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "    for box, conf, cls in zip(selected_boxes, selected_confidence, selected_classes):\n",
    "        if conf > 0.1:\n",
    "            xmin, ymin, xmax, ymax = box\n",
    "            label = f\"Class {cls} ({conf:.2f})\"\n",
    "            rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=1, edgecolor='r', facecolor='none' ,label=label)\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dced394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#lade bild\n",
    "image_path1 = (IMAGE_PATH+ '/640x640_main_classes_scaled/0_4.jpg') \n",
    "image_path2 = (ORIGINAL_IMAGE_PATH+'/image_0004.jpg') \n",
    "predict_on_image(image_path1, yolo_coco_sub)\n",
    "predict_on_image(image_path2, yolo_coco_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d43ee844c1840",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EvaluateCOCOMetricsCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, data, save_path):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.metrics = keras_cv.metrics.BoxCOCOMetrics(\n",
    "            bounding_box_format=\"xyxy\",\n",
    "            evaluate_freq=1e9,\n",
    "        )\n",
    "\n",
    "        self.save_path = save_path\n",
    "        self.best_map = -1.0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.metrics.reset_state()\n",
    "        for batch in self.data:\n",
    "            images, y_true = batch[0], batch[1]\n",
    "            y_pred = self.model.predict(images, verbose=0)\n",
    "            self.metrics.update_state(y_true, y_pred)\n",
    "\n",
    "        metrics = self.metrics.result(force=True)\n",
    "        logs.update(metrics)\n",
    "\n",
    "        current_map = metrics[\"MaP\"]\n",
    "        if current_map > self.best_map:\n",
    "            self.best_map = current_map\n",
    "            self.model.save(self.save_path)  # Save the model when mAP improves\n",
    "\n",
    "        return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83f47b37997236a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Fake Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1cd42883ee81fb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T13:34:31.996115700Z",
     "start_time": "2024-01-09T13:34:31.924042600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "# import keras_cv\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from tensorflow import keras\n",
    "#from keras_cv import bounding_box\n",
    "#from keras_cv import visualization\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.models import Sequential, model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "from keras.callbacks import EarlyStopping\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de25d596d2429a23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T13:36:31.489332400Z",
     "start_time": "2024-01-09T13:36:31.390Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get all XML file paths in path_annot and sort them\n",
    "xml_files = sorted(\n",
    "    [\n",
    "        os.path.join(\"data_zettel/Annotations\", file_name)\n",
    "        for file_name in os.listdir(\"data_zettel/Annotations\")\n",
    "        if file_name.endswith(\".xml\")\n",
    "    ]\n",
    ")\n",
    " \n",
    "# Get all JPEG image file paths in path_images and sort them\n",
    "jpg_files = sorted(\n",
    "    [\n",
    "        os.path.join(\"data_zettel/Annotations\", file_name)\n",
    "        for file_name in os.listdir(\"data_zettel/Annotations\")\n",
    "        if file_name.endswith(\".jpg\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec2c06c5208d6f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T13:36:31.894495600Z",
     "start_time": "2024-01-09T13:36:31.854394800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def map_class_id(classes, cls):    \n",
    "    class_ids = [\n",
    "        list(class_mapping.keys())[list(class_mapping.values()).index(cls)]\n",
    "        for cls in classes\n",
    "    ]\n",
    "    return class_ids\n",
    "\n",
    "def create_box(bbox):\n",
    "    xmin = float(bbox.find(\"xmin\").text)\n",
    "    ymin = float(bbox.find(\"ymin\").text)\n",
    "    xmax = float(bbox.find(\"xmax\").text)\n",
    "    ymax = float(bbox.find(\"ymax\").text)\n",
    "    return [xmin, ymin, xmax, ymax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7f2298a2e644551a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T14:16:37.513681500Z",
     "start_time": "2024-01-09T14:16:37.459396500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_annotation_fake(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    " \n",
    "    image_name = root.find(\"filename\").text\n",
    "    image_path = f'data_zettel/filled_resized/{image_name}'\n",
    "    \n",
    "    boxes = []\n",
    "    classes = []\n",
    "    main_classes = []\n",
    "    sub_classes = []\n",
    "    main_boxes = []\n",
    "    sub_boxes = []\n",
    "    values = []\n",
    "    for obj in root.iter(\"object\"):\n",
    "        cls = obj.find(\"name\").text\n",
    "        classes.append(cls)\n",
    "        \n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        boxes.append( create_box(bbox))\n",
    "        #main labels\n",
    "        if (cls=='Wohnsitz_waehrend_Ausbildung')or(cls=='Ausbildung') or (cls =='Person') or (cls == 'Wohnsitz'):\n",
    "            main_classes.append(cls)\n",
    "            bbox = obj.find(\"bndbox\")\n",
    "            main_boxes.append( create_box(bbox))\n",
    "        else:\n",
    "            attributes = obj.findall(\"attributes/attribute\")\n",
    "            for attribute in attributes:\n",
    "                value_element = attribute.find(\"value\")\n",
    "                if value_element is not None:\n",
    "                    value = value_element.text\n",
    "                    if value is None:\n",
    "                        value = \"\"\n",
    "                    if value.lower() == \"true\":\n",
    "                        values.append(\"X\")\n",
    "                    elif value.lower() == \"false\":\n",
    "                        values.append(\"\")\n",
    "                    else:\n",
    "                        # Versuche, den Wert in einen Float zu konvertieren\n",
    "                        try:\n",
    "                            float_value = float(value)\n",
    "                            int_value = int(float_value)\n",
    "                            values.append(str(int_value)) # Zurück wandeln in String für später\n",
    "                        except ValueError:\n",
    "                            values.append(value)\n",
    "                    break \n",
    "            \n",
    "            bbox = obj.find(\"bndbox\")\n",
    "            \n",
    "            sub_boxes.append(create_box(bbox))\n",
    "            sub_classes.append(cls)\n",
    "\n",
    "    return image_path, sub_boxes, values\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4955cb22409e20f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T14:16:39.218790200Z",
     "start_time": "2024-01-09T14:16:39.140629200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [00:00<00:00, 892.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['42', '21012001', '4', 'NR', 'X', 'Puffer Straße', '21', 'NR', '49928', 'Arts', 'Lüpfer Weg', 'Master', '11112004', '21998', 'Span', '', '', '0', '', '', 'Worskpace Hochschule', 'X', 'X', 'NR', '217778210341982', 'Patron', 'Linda', 'tronan', 'Pindra']\n",
      "['Washin', '1', '', '', '', '22219', '201', 'Freedom house', 'Ar', '5', '0', 'DE', '321', 'Berlin', '92187', 'Sandrin Universität', '1212001', 'Chimie', 'Bachelor', 'X', 'X', 'BE', '201022467349110', 'Zama', 'Zura', 'Bana', 'Weißerweg', 'X', 'Lindor']\n",
      "['Babau', '234902399876543', 'BA', 'X', '1', 'X', 'Master', 'Biologie', 'Bilden Bibau', '', '', '0', 'Lize', 'Betz', 'Noran', 'Lotze', '21122003', '', '2', 'X', 'Antag Weg', '41', 'DE', '19227', 'Münich', '221', '78219', '', 'Nierdan']\n",
      "['', '1', '', 'Bibaa Hochschule', 'Mathe', 'Master', 'X', 'X', 'Zo', '202193424982109', 'Luzan', 'Birzan', 'Luzan', 'Purshan', '11010192', '2', '5', 'NR', 'X', 'Lianpina', '42', 'LP', 'Brobon', 'Bremerstraße', '49', 'Kl', '21983', 'Brebau', '0']\n",
      "['Stadau', 'Lor Weg', '', '', '0', 'Hagen', 'Busslin Weg', '21210', '241', '', '1', 'Spand Bredau', 'Informatik', 'Master', 'X', 'BR', '124908723410234', 'Liza', 'Bitz', 'Noron', 'Lotz', '11111999', '102101', 'DE', 'X', '221', 'Br', 'DE', '22222']\n",
      "['21112101', '1', 'Bremen Hochschule', 'Median theory', 'Master', 'X', '123456789120321', 'Namener', 'Bubaran', 'Lizadan', 'Bidan', '11212000', 'Kr', 'Br', 'X', '0', 'Lützen Weg', '221', 'Hamburg', 'Hamburger Weg', '421', 'Kr', '21102', 'Hamburg', '', '', '1', '', '']\n",
      "['Master', '11211010', '3', 'NR', 'Br', 'X', 'Bayerner Universität', 'Physik', 'Hamburg', 'X', 'X', 'Br', '20101', '210101111000111', 'Meiners', 'Liparan', 'Lupun', 'London', '21111092', 'Blauer Weg', '122', '', 'Ai', '1', 'Spandau', '210', 'BR', 'Hauluwer Straße', '0']\n",
      "['', 'Bayernerman', 'Bayern', '27720', 'Birland', 'Nonarin', 'Orinano', 'BN', 'Bacherlor', 'Andrea', 'Farbe Forschung', 'NB', '', '', '7210', 'Ki', '24', '222101263493100', '', 'DR', '21028', 'Hand Straße', '', 'Flavour Schule', '11022003', '21012009', '0', 'X', '2']\n",
      "['14728', 'Dardon', '21982', '2B', '123', 'Straßendan Weg', 'Weideman', '21', 'Linderhof', 'X', 'BR', '21111908', '11111111', 'pdardon', 'Runger', 'Linpada', 'Linpan', '123498760124578', 'Li', 'X', 'Bacherlor', 'Wirtschaft', 'Pandau Hochschule', '', '1', '', '', '', '0']\n",
      "['X', 'X', '1', 'Master', '1', 'Produkte', 'Mandau Universität', '', '', '0', '', 'Bremen', '21010', '21', 'Gironau Straße', 'Baron', '21010', '210', 'Gröpelingen', 'X', 'Br', 'BL', '11282112', '1112008', 'Bidazon', 'Minoros', 'Biaron', 'Adminor', 'Bo']\n",
      "['30403', '', 'Oslo', '', '', '', '3101985', '2', 'swedisch', '1', 'Obdachlosstr', '6', '', 'Pokemon Trainer', '1', 'Master', 'X', 'Ketchup', 'Arschin', 'Pikachu', '', 'GER', '', 'Karlsruhe Training Centre', '', '', '', 'Karlsruhe', '0']\n",
      "['Bremen', '28208', 'GER', 'Im Keller', '420', '', '', '', '', '1', '0', '', '1', 'Auberginestr', 'X', 'russisch', '', '', '', '7121995', 'Nottingham', 'X', 'Doktor', 'Philosophie', '1', 'Freud', 'Sigmund', 'Universität Bremen', 'Bob']\n",
      "['Maria', '23208', 'Polen', 'DE', 'Kleinberg', 'X', 'Toujo', '', '1', '1', '100', 'Kleinbergerstraße', 'Deutscher', 'Polin', 'Bachelor', 'Informatik', 'Kleinberger Hochschule', '', '', '1', '1', '', '', '', '', '', '', '0', '']\n",
      "['', '', '0', '', '3031998', '', '', '1', 'Deutscher', 'Bachelor', 'X', '', '', 'Tanjo', '', 'Maria', 'Polen', '', '', '1', 'Polin', '2', 'Kleinbergerstraße', '23208', 'Weinberger Hochschule', 'Informatik', '144', 'DE', 'Weinberg']\n",
      "['X', 'London', 'Sherlock', 'Master', 'X', 'X', 'Moriarty', 'Holmes', '3', '', '', '1', '', '1', '', '', '0', '', '49328', 'GER', '301', 'Longjohnstr', 'englisch', 'englisch', '11111987', 'London', 'Detective', 'London Universität', '']\n",
      "['', '', 'Polin', 'Deutscher', 'Informatik', 'Tanjo', 'X', 'Weinberg', '23208', 'DE', '100', '', '', '', '1', '', '', '', '', 'Weinbergerstraße', 'Maria', '0', '', '1', 'Weinberger Hochschule', 'Bachelor', 'Polen', '3031998', '2']\n",
      "['Peter', 'Hochschule Dresden', 'Master', 'Demonology', 'GER', '204', 'Dämonstr', 'Parker', '1', '0', '', '', '42066', '', '1', 'deutsch', 'Dresden', '', '', '', '1', '', 'X', '', 'Spiderman', 'Dresden', '', '31052002', '']\n",
      "['DE', '', '1', '1', '0', '100', '3031998', '', '', 'Polen', '', '', '', '', '', '', '', 'Bachelor', 'Weinberg', '23208', 'Weinbergstrasse', 'Deutscher', 'Polin', '2', 'Maria', 'Taujo', 'X', 'Informatik', 'Weinberger Hochschule']\n",
      "['BREMEN', 'ELIZABETH', 'UNIVERSITÄT BREMEN', 'JOJO', 'AMSTERDAM', '10011990', '28150', '', 'deutsch', 'X', 'X', '1', '', '2', '', '', '', 'STARK', '', '', '355', '', 'deutsch', 'BACHELOR', '1', 'NEUSTADTERSTR', '50', 'GER', 'BIOLOGIE']\n",
      "['Polen', '', '3031998', '', '', '', '0', '2', '', 'Maria', '', 'Weinberg', '1', 'Informatik', 'Bachelor', 'X', '', 'Toujo', '1', '', '', '', 'DE', '100', 'Weinbergstrasse', 'Deutscher', '23208', 'Weinberger Hochschule', 'Polin']\n",
      "['2', 'Naruto', 'Uzumaki', 'Konoha Academy', 'Ninjutsu', 'Master', 'X', 'Konoha', '89320', 'GER', 'Ninjastr', 'japanisch', 'japanisch', '', '', '1', '', '', '25031999', '2', 'Kyuubi', 'X', '4', '', '', 'Konoha', '', '1', '']\n",
      "['Polen', '1', '3031998', '2', 'DE', '23208', '', '', '', '', '', '', '', '', '', '', '0', '1', 'Weinberger Hochschule', 'Informatik', 'Weinber', '100', 'Weinbergerstraße', 'Deutscher', 'Polin', 'Maria', 'Toujo', 'X', 'Bachelor']\n",
      "['Bremen', 'Hochschule Bremen', 'Mark', 'Robert', 'Potsdam', '5092001', '', '', 'X', 'deutsch', '', '1', '', 'X', 'Henry', '0', '', '', '1', 'Medien Informatik', '', '28320', 'GER', '150', 'Parkstraße', '1', '', '', 'Bachelor']\n",
      "['', '', '', 'Polen', '3031998', '', '1', 'Toujo', 'maria', '2', 'Weinbergstraße', '1', '', '', '', '', '0', '', '', 'Deutscher', '100', 'DE', '23208', 'Weinberg', 'Weinberger Hochschule', 'Informatik', 'Bachelor', 'X', 'Polin']\n",
      "['X', 'X', 'Bachelor', 'Fly Catcher', 'Hochschule Ribbit', 'Ponderberg', '48957', 'GER', '39', 'FROG', '', '', '5061996', 'Amazon', 'The', 'Kermit', '', '', '', '', '1', '', '', '', '0', '1', 'polisch', '1', 'Pondstraße']\n",
      "['1', '', '', '', '0', '', '', '', '', 'Polin', '2', '3031998', '1', '', 'Polen', 'Maria', 'Toujo', '', 'Deutscher', 'Weinbergerstraße', '100', 'DE', '', 'Informatik', 'Weinberger Hochschule', 'Bachelor', 'X', '23208', 'Weinberg']\n",
      "['Bros', 'Osnabrück', '13452', 'GER', '12', 'Mario', '', 'Master', '', 'X', 'itanlianisch', '4', '', '', '', '1', 'Japan', 'Super', '', '', '', 'Trampoline Universität', 'Springen', '1081987', '', '1', 'Pipestr', '0', '']\n",
      "['', '', '', '3031998', '1', '', '2', '0', 'Polin', '', '23208', '', '', '1', 'Weinberg', '', '', '', 'Polen', 'DE', 'Bachelor', 'Informatik', 'kleinberger Hochschule', 'Maria', 'Deutscher', '100', 'WeinbergerStr.', 'X', 'Toujo']\n",
      "['120', '23032000', 'Denver', 'kcao', 'Bachelor', 'Racing', 'Universität Berlin', '1', '', '1', '', '', '', '', '', '', '0', '', 'Berlin', '53250', 'GER', 'Ferraristr', 'amerikanisch', '3', '', 'Lightning', 'McKing', 'X', 'X']\n",
      "['', 'Weinberger Hochschule', 'Informatik', 'Bachelor', 'Toujo', 'Weinbergerstrasse', '100', '0', '', '', '', '', '1', '', '23208', 'DE', '', '1', '', '', '', '', '', 'Maria', 'Polen', '3031998', '2', 'Polin', 'Deutscher']\n",
      "['Bob', '13778', 'Bachelor', 'Informatik', 'Leuchtenburg', '28779', 'DE', 'Tj', 'Sponge', '', 'Fachhochschule Bielefeld', '', '0', '', '', '', '88', 'Bikini Bottom', '', '', 'Deutsch', '', '', '1', '', '1', '8072000', 'Bremen', '']\n",
      "['', '', '1', '', '', '', '', '1', '1', '', '', '', '', '', '0', '1', 'X', 'Fritz', 'Deutsche', 'Auf der Koppel', '23', 'Steuern, Digitale Wirtschaft', 'Oldenburg', '26121', '3031999', 'Oldenburg', 'Marina', '10.05.2025', 'Jade Hochschule Oldenburg']\n",
      "['1041970', 'Sponge', 'Patrick', 'Star', '787', 'X', 'Master', 'Chemie', 'Touro College Berlin', 'USA', '77777', 'Bikini Bottom', '778', 'Bikini', 'X', 'Amerikanisch', '4', 'Bottom', '0', '', '', '', '1', '', '', '', '', '', '']\n",
      "['', 'Deutsch', 'Kölner', 'Bachelor', '28888', 'Köln', '', '', '1', '1', 'DE', '', '', '', '', '', '0', '', '3031977', '1', '', '', 'Köln', 'Freie Universität Berlin', 'Informatik', 'Igor', 'Martin', '778', 'Kölner']\n",
      "['Bayern', 'Biologie', 'X', 'Platz', '1', 'DE', '28998', 'Sascha', 'Jens', '1', '1', '', '', '1061999', '', '0', '', '', '', '', '1', '', 'Moskau', 'Asimov', 'Hertie School', 'Bachelor', 'X', '', '']\n",
      "['', 'DE', '28970', 'Berlin', '', '', '1', '', '', '', '', '1', '', '', '0', '', 'Steinbeis Hochschule', 'Sport', 'Master', 'X', 'Lev', 'Markus', 'Leon', '', '1', 'Bayern', '2081997', 'Wakanda', '999']\n",
      "['Quadriga Hochschule Berlin', 'Bachelor', '1', 'Elektrotechnik', 'X', 'X', '7778765', 'Markus', '', 'Berlin', '', '', '', '', '', 'Malte', 'Gustaf', 'Bemen', 'Guten', '120', '', '', '0', '', 'DE', '28779', 'X', '1651960', '3']\n",
      "['3.08.2023', 'Hotelfachmann', 'Schulzentrum 28219 Bremen', 'Weng', '13408967853210', 'X', 'Schwering', 'Emily', 'X', '', '', 'Schwanewede', '28790', '9', 'Puschkinstraße', 'Deutsch', '24121999', '', '', '0', '1', '', '', '', '1', '', '', '', '1']\n",
      "['1', '0', '', '', '', '10051996', '', 'Deutsche', 'Hakenwehrstraße', '7', '28779', 'Bremen', '1', '', '', '', '1', '', '', '', '', '', '1', 'Berlin', 'Marcus', 'Kraft', 'X', 'Architektur', 'Jade Hochschule Wihland']\n",
      "['Beckedorfstraße', 'Elektrotechnik und Informatik', 'Kevin', 'Bremen', '22031998', 'Deutsche', '17', '28790', 'Beckedorf', '', '0', 'X', '', '1', '1', '', '', '', '1', 'Hochschule Bremen', 'Krause', '', '', '1', '', '', '10.09.2024', '', '']\n",
      "['', '14051984', '', '', 'Amy', 'Amy', '1', 'USA', '', '1', '', '', 'Potsdam', 'Koch', 'Zuckerberg', '', '', '1', 'Mark', '', '0', '', 'New York', '', '', '1', 'Kalifornien', 'Hacker Way', '94025']\n",
      "['Funker', 'X', 'X', 'Kassel', '121314752741397', '7', 'Kassel', 'X', '', '0', '', '', '', '1', '', 'Nebraska', 'Senator str', '', '', 'USA', '', 'Warren', 'Buffet', 'Ohama', '', 'Amy', '1', '30081930', '50735']\n",
      "['94043', '', '', '', '0', '', '', '', '', '', '', '1', '', '', '1', '', '', 'California', 'USA', '2', 'Berlin', 'Model', 'Brin', 'Sergej', '21081973', '5', 'Ruski', 'X', 'Amphitheatre Parkway']\n",
      "['X', '2', '28101995', 'Seatle', 'Bill', 'Gates', '123456789001001', 'Stuttgart', 'Amy', '', 'Amy', '', 'X', 'Kellner', '', '', 'Redmond Woods', '', 'Stuttgart', '', '1', '0', '148th Ave NE', '98052', 'USA', '', '', '14', 'X']\n",
      "['', '1', '', '', '', '', '', '', '', '', '0', '1', '', 'Manager', 'Amy', 'Amy', 'X', '148th Ave NE', '14', 'USA', '98052', 'Redmond Woods', '2', '24031956', 'Detroid', 'Steve', 'Ballmer', 'X', 'Köln']\n",
      "['Michigan', '0', '', '1', 'Wismar', 'X', 'Page', 'Larry', '', '26031973', 'Amy', 'Amy', 'X', 'Amphitheatre Parkway', '7', 'Junker', '', '1', '', '', '', '', '', '1', 'USA', '24043', 'California', '', '']\n",
      "['28271', '', '5', 'Austin', '', '', '', '', '', '', '1', '', '17071944', 'Larry', 'Cloud Way', '1', '2300', '', '', '0', 'USA', '', 'New York', '', '', 'Berlin', 'Ellison', 'X', 'Gas, Wasser,...']\n",
      "['Schwabingen', 'Karlsruhe', 'informatiker', 'X', '80538', '', '', 'New Mexiko', '2', '12011964', 'Albuqerque', 'Jeff', 'Bezos', '', '', '', '', 'Amy', 'X', '', '', 'Parkstraße', '0', '1', '1', '37', '7', 'DE', '']\n",
      "['', 'Raubix', '', 'X', 'X', 'Automatisierer', 'Rernard', '', '5031949', 'Jeff', '0', 'München', '', '', '', '', '', '', '1', '1', 'Köln', '1', 'Arnault', '8', 'München', 'Ger', 'Franzose', 'Leopold str', '80802']\n",
      "['Berlin', 'Düsseldorf', '', 'König', '', 'X', 'Musk', 'Elon', 'Pretoria', '28061971', '2', 'Afrika', 'X', 'Ludwig-Prundte', '27', 'Ger', '12526', '', '1', '', '0', '', '1', '', '', '', '', '', '']\n",
      "['1', '', '', '', '', '', 'Musterstadt', '', '1', '', '1', '0', '', '', 'Fakeort', 'Bachelor', 'Technische Universität', 'Maschinenbau', 'X', '12345678910', 'Mülle', 'Max', '1011995', 'Deutsch', 'Deutsch', 'X', 'Hauptstraße', '42', 'Deutschland']\n",
      "['X', 'Doktor', 'Deutsch', '', 'X', '1', '', '', '', 'Laura', 'Fischer', '', '789123', 'Behörde', 'BetriebswirtschaftslehrBetriebswirtschaftslehre', 'IW Globalstadt', '', '', '', '1', '0', '', '1', '', '', '10101990', 'Handelsburg', 'Becker', '']\n",
      "['', '', 'Deutsch', '1041990', 'Phantasia', 'Clara', 'Schmidt', '', '', '', '0', '', '', '', '', '1', '', '1', '', '', '456874678910112', '', '', '1', 'X', 'X', 'Fotografie', 'Art Akademie Hamburg', 'Master']\n",
      "['Jonas', 'Fantasiewelt', '15051995', 'Deutsch', 'Abenteuerweg', 'DE', '33', '67890', 'Fantasiewelt', 'Maschinenbau', 'Bachelor', 'X', 'X', 'Weber', '', '1', '', 'Hochschule Berlin', '', '', '1', '', '', '', '', '0', '', '', '1']\n",
      "['Fischer', '', '0', '', '', '', 'Studio 2', '10', 'Kreativallee', '45678', 'HE', '5', 'Blumenweg', 'Deutsch', '2031992', 'Musterstadt', 'Lena', 'Bauer', '12345', 'Farbenstadt büro', 'X', 'X', '1', 'Bachelor', '1', 'Universität Farbenstadt', 'Farbenstadt', '98765', 'Grafikdesign']\n",
      "['David', 'Institut Forschungsstadt', 'Umweltwissenschaften', 'X', 'Behörde', '65432', 'Neumann', 'Klein', 'Grüntal', '', '20', 'Doktor', '8081988', 'Deutsch', 'X', 'Waldpfad', '', '', 'Forscherweg', '0', '12', 'ID', '12321', 'Grüntal', '1', 'Forschungsstadt', '32123', '', '1']\n",
      "['', '', '1', '', '', '1', '', '0', 'Hochschule Bau', 'Architektur', 'Diplom', 'X', 'Amt', '87654', 'Zimmermann', 'Sarah', 'Weber', 'Himmelsdorf', '16071994', 'Deutsch', 'Blütenstraße', '22', 'VI', '55678', 'Himmelsdorf', '87655', 'Konstruktionsstadt', '5', 'Planerallee']\n",
      "['Richter', 'Behörde', '32198', 'Felix', 'Lehmann', 'Bergdorf', '9091989', 'Deutsch', 'Österreichisch', 'X', 'Med Fakultät', 'Allgemeinmedizin', 'Doktor', 'X', 'X', '1', '', '', '', '', '', '', '1', '', '1', '', '0', '', '']\n",
      "['0', '1', '', '', '', 'Schmidt', 'Buchhausen', '14021991', '', '1', '1', '', '', '', '', '', '', '', '', '', 'Wagner', 'Emily', '56789', 'Literaturwissenschaft', 'Uni Kulturstadt', 'Deutsch', 'Behörde', 'Doktor', 'X']\n",
      "['Master of Science', 'TU Berlin', 'Deutsch', '21061993', 'Oliver', 'Digitalien', 'Neumann', 'Informatik', '', '', '654321', '', '', 'X', '', 'Schwarz', '', '1', '', '', '1', 'X', '0', '', '', '', '1', '', 'Amt']\n",
      "['0', '1', '', '', '1', 'Bremen', '28219', '', '', '282', 'Stader Str.', 'Deutsch', '5082004', 'Delmenhorst', 'Peter', 'Peterson', 'X', 'Kaufmann', 'Biemen', '', '', '', '', '', '', '', '1', '', '']\n",
      "['1', '', '1', '', '', '0', '1', '', '', '', '', '', '', '', 'GER', 'Hohentor Universität', 'Informatik', 'Master', 'X', 'Max', 'Max', 'Max', 'Maxstadt', '1012000', 'DE', 'Maxstraße', '5', '57312', 'München']\n",
      "['Harvard', 'deutsch', 'Main Street', '7', 'USA', '31057', 'Boston', '', '', 'Boston', '31061983', 'Computer', 'Bachelor', '', '', '', '', '1', '', '', '1', 'X', '356', '', '', '', '1', 'Zuckerberg', 'Mark']\n",
      "['555333678955000', 'Bremeramt', 'Deutsch', 'Master of language', 'X', '', '', '', 'Hannover', '0', '', '', '53210', 'POL', '1032004', 'Bremen', 'Meyer', 'Müller', 'Denis', '', '', '12', 'Karl-Marx-Weg', 'TH Hannover', '1052018', '2', 'deutsch', 'polnisch', 'X']\n",
      "['25319', 'Wizard Master', 'X', 'Harry', 'X', 'Der Weg', '33', 'NL', 'Amsterdam', 'kroatisch', '', '', '', '', '', '0', '', '1', '1', '', '1', '', 'Wizard School Hogwarts', 'Magic Potions', 'Potter', 'Lars', 'Berlin', '12122003', '']\n",
      "['', '0', '', 'Wolfgang', 'Johann', 'Goethe', '', '', '', '', 'Hochschule Hamburg', 'Mathe', 'Bachelor', '', 'Berlin', '', '', '1', '1', '', '1', '', '29531', '10101955', 'deutsch', 'Hamburger Weg', '5', 'GER', 'Hamburg']\n",
      "['Stege', '', '356', '', '', '', '', 'Universität Leipzig', 'Chemie', 'Master', 'X', 'Max', 'Leipzig', '1012001', 'polnisch', 'Leipzig Straße', '3', 'GER', '29317', 'Leipzig', '1', '', '', '', '1', '', '1', '', '']\n",
      "['Chicago', 'Master of Science', '', '', '', 'Computer Engineering', 'State University Chicago', 'deutsch', 'Street 2nd', 'X', '57310', 'Bremen', '1', 'Bo', '', 'Tim', 'USA', '5', '', '1', '12122003', '', '1', '', '354', 'Bo', '', '', '']\n",
      "['', '', '1', '', '', '', '', 'Monobachelor', 'Lehramt', 'Universität Heidelberg', '', '0', '', '1', '1', '', '', 'Heidelberg', 'X', 'Blumen', 'Julia', 'Blumen', '3032005', 'deutsch', 'Friedrich Straße', '3', 'GER', '10135', 'Heidelberg']\n",
      "['Freiburg', 'Hochschule Albert', 'Soziale Arbeit', 'Bachelor', 'X', 'Smith', 'Luisa', 'Smith', 'New York', '29052000', 'deutsch', 'Friedensweg', '5', 'GER', '79085', '1', '', '', '', '', '', '1', '', '', '0', '', '1', '', '']\n",
      "['0', '1', '', '', '', '', '', '', '', '1', '', '', '1', '', '', 'GER', 'FH Berlin', 'Informatik', 'Bachelor', 'Mark', 'Max', 'Berlin', 'Berlin', '30111999', 'deutsch', 'X', 'Karl Straße', '5', '51350']\n",
      "['Bremen', 'X', 'deutsch', '2', '14022001', 'Joachim', 'Jochen', '123456789101112', 'kleines Amt', 'X', 'Bachelor of Science', 'Informatik', 'Hochschule Bremen', '12', 'DE', '28757', 'Bremen', '', '', '', '', '0', '', '', '', '', '1', '', 'Kuhdamm']\n",
      "['', '1', '', 'Universität Lübeck', 'Data Science', 'Bachelor of Science', 'X', '', '', '', '0', '', '1', '', '', 'Kiel', 'Birne', 'Svenja', 'Apfel', '123456789012345', '5061999', 'deutsch', 'Hamurg', 'Schnelle Staße', '67', 'a', 'DE', '12', 'Verden']\n",
      "['12345', '1', '', '', '', '0', '', '', '', '', 'Universität Bremen', 'Medieninformatik', 'Bachelor of Arts', 'X', 'Beil', 'Helga', 'Axt', 'Lübeck', '2021980', 'deutsch', 'Baumallee', '1', 'DE', '1', 'Bremer Str.', '1', '28203', 'Bremen', '1']\n",
      "['', 'Hochschule Hannover', 'Technische Informatik', 'Bachelor of Science', 'X', 'X', 'Dezernat 1', '1123411925300', 'Thorsten', 'Thomas', 'Lübeck', '5121980', '5', 'französisch', 'italientisch', 'X', 'Lange Str.', '50', 'a', 'DE', '12333', 'Wels', '3560', '52', 'Bremen', '1', '0', '', 'Kurze Str.']\n",
      "['Hochschule Hamburg', 'Elektrotechnik', 'Bachelor of Engineering', 'Haus', 'Anne', 'München', '30101999', 'deutsch', 'Mittelstraße', '1', 'b', 'DE', 'Verden', '22305', '', '', '', '', '', '', '0', '', '', '1', '1', '', '1', '', '']\n",
      "['', '', '1', '', '', '', '', '', '0', '', '1', '1', '', 'Bachelor of Engineering', 'Halle', '33650', 'DE', '5', 'Spitze Staße', 'polnisch', '11112011', 'Kiel', 'Zack', 'Elke', 'Zarrath', 'X', 'X', 'Mathematik', 'Universität Hamburg']\n",
      "['Bermerhaven', 'X', '12032005', 'z', '5', 'deutsch', 'DE', '51234', 'Bremen', '', '', '', '', 'RTW Aachen', 'Maschinenbau', 'Bachelor of Engineering', 'X', 'Tisch', 'Jasmin', 'Stuhl', 'Enge Staße', '54', '1', '1', '', '0', '', '', '']\n",
      "['Berlin', '77', 'Hohe Staße', '', '1', '', 'X', 'Jens', 'Teller', '1', '0', '', '198760234102365', 'Amt Sachsen', '', 'X', '', 'X', 'Bachelor of Arts', '', 'Universität Berlin', 'BetriebswirtschaftslehrBetriebswirtschaftslehre', 'Berlin', '521917', 'deutsch', 'deutsch', 'b', 'DE', '15209']\n",
      "['Bremen', 'X', 'Knopf', 'Hannes', '111991', '16705', '', '0', '1', 'DE', '1', 'Flache Staße', 'deutsch', 'Master of Science', '', '', 'Mechatronik', 'Hochschule Bremerhaven', '', '1', '', '', '', '', '', '1', '', '', '']\n",
      "['1', '1', '', '', 'Karsten', 'Kupfer', 'Hamburg', '', '', '10101990', '0', '', 'deutsch', '', '', '', '', '', '1', '55212', 'Hamburg', 'Universität Kiel', 'Tiefe Staße', '3001', 'DE', 'Stahl', 'X', 'Master of Science', 'Energietechnik']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "ImageInfo = namedtuple('ImageInfo', ['path', 'boxes', 'values'])\n",
    "\n",
    "image_list = []\n",
    "for xml_file in tqdm(xml_files): \n",
    "    image_path, sub_boxes, values= parse_annotation_fake(xml_file)\n",
    "    image = ImageInfo(path=image_path, boxes=sub_boxes, values=values)\n",
    "    image_list.append(image)\n",
    "    print(values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73327eb722f2ea",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Crop ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8995ce981686184e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T14:16:41.482843900Z",
     "start_time": "2024-01-09T14:16:41.468218100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(image_list[5].boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3dbc953849a6b899",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T14:17:04.605779400Z",
     "start_time": "2024-01-09T14:16:42.004155500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "21012001\n",
      "4\n",
      "NR\n",
      "True\n",
      "Puffer Straße\n",
      "21\n",
      "NR\n",
      "49928\n",
      "Arts\n",
      "Lüpfer Weg\n",
      "Master\n",
      "11112004\n",
      "21998\n",
      "Span\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "Worskpace Hochschule\n",
      "True\n",
      "True\n",
      "NR\n",
      "217778210341982\n",
      "Patron\n",
      "Linda\n",
      "tronan\n",
      "Pindra\n",
      "Washin\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "22219\n",
      "201\n",
      "Freedom house\n",
      "Ar\n",
      "5\n",
      "0\n",
      "DE\n",
      "321\n",
      "Berlin\n",
      "92187\n",
      "Sandrin Universität\n",
      "1212001\n",
      "Chimie\n",
      "Bachelor\n",
      "True\n",
      "True\n",
      "BE\n",
      "201022467349110\n",
      "Zama\n",
      "Zura\n",
      "Bana\n",
      "Weißerweg\n",
      "True\n",
      "Lindor\n",
      "Babau\n",
      "234902399876543\n",
      "BA\n",
      "True\n",
      "1\n",
      "True\n",
      "Master\n",
      "Biologie\n",
      "Bilden Bibau\n",
      "\n",
      "\n",
      "0\n",
      "Lize\n",
      "Betz\n",
      "Noran\n",
      "Lotze\n",
      "21122003\n",
      "\n",
      "2\n",
      "True\n",
      "Antag Weg\n",
      "41\n",
      "DE\n",
      "19227\n",
      "Münich\n",
      "221\n",
      "78219\n",
      "\n",
      "Nierdan\n",
      "\n",
      "1\n",
      "\n",
      "Bibaa Hochschule\n",
      "Mathe\n",
      "Master\n",
      "True\n",
      "True\n",
      "Zo\n",
      "202193424982109\n",
      "Luzan\n",
      "Birzan\n",
      "Luzan\n",
      "Purshan\n",
      "11010192\n",
      "2\n",
      "5\n",
      "NR\n",
      "True\n",
      "Lianpina\n",
      "42\n",
      "LP\n",
      "Brobon\n",
      "Bremerstraße\n",
      "49\n",
      "Kl\n",
      "21983\n",
      "Brebau\n",
      "0\n",
      "Stadau\n",
      "Lor Weg\n",
      "\n",
      "\n",
      "0\n",
      "Hagen\n",
      "Busslin Weg\n",
      "21210\n",
      "241\n",
      "False\n",
      "1\n",
      "Spand Bredau\n",
      "Informatik\n",
      "Master\n",
      "True\n",
      "BR\n",
      "124908723410234\n",
      "Liza\n",
      "Bitz\n",
      "Noron\n",
      "Lotz\n",
      "11111999\n",
      "102101\n",
      "DE\n",
      "True\n",
      "221\n",
      "Br\n",
      "DE\n",
      "22222\n",
      "21112101\n",
      "1\n",
      "Bremen Hochschule\n",
      "Median theory\n",
      "Master\n",
      "True\n",
      "123456789120321\n",
      "Namener\n",
      "Bubaran\n",
      "Lizadan\n",
      "Bidan\n",
      "11212000\n",
      "Kr\n",
      "Br\n",
      "True\n",
      "0\n",
      "Lützen Weg\n",
      "221\n",
      "Hamburg\n",
      "Hamburger Weg\n",
      "421\n",
      "Kr\n",
      "21102\n",
      "Hamburg\n",
      "\n",
      "\n",
      "1\n",
      "False\n",
      "\n",
      "Master\n",
      "11211010\n",
      "3\n",
      "NR\n",
      "Br\n",
      "True\n",
      "Bayerner Universität\n",
      "Physik\n",
      "Hamburg\n",
      "True\n",
      "True\n",
      "Br\n",
      "20101\n",
      "210101111000111\n",
      "Meiners\n",
      "Liparan\n",
      "Lupun\n",
      "London\n",
      "21111092\n",
      "Blauer Weg\n",
      "122\n",
      "\n",
      "Ai\n",
      "1\n",
      "Spandau\n",
      "210\n",
      "BR\n",
      "Hauluwer Straße\n",
      "0\n",
      "\n",
      "Bayernerman\n",
      "Bayern\n",
      "27720\n",
      "Birland\n",
      "Nonarin\n",
      "Orinano\n",
      "BN\n",
      "Bacherlor\n",
      "Andrea\n",
      "Farbe Forschung\n",
      "NB\n",
      "\n",
      "\n",
      "7210\n",
      "Ki\n",
      "24\n",
      "222101263493100\n",
      "False\n",
      "DR\n",
      "21028\n",
      "Hand Straße\n",
      "False\n",
      "Flavour Schule\n",
      "11022003\n",
      "21012009\n",
      "0\n",
      "True\n",
      "2\n",
      "14728\n",
      "Dardon\n",
      "21982\n",
      "2B\n",
      "123\n",
      "Straßendan Weg\n",
      "Weideman\n",
      "21\n",
      "Linderhof\n",
      "True\n",
      "BR\n",
      "21111908\n",
      "11111111\n",
      "pdardon\n",
      "Runger\n",
      "Linpada\n",
      "Linpan\n",
      "123498760124578\n",
      "Li\n",
      "True\n",
      "Bacherlor\n",
      "Wirtschaft\n",
      "Pandau Hochschule\n",
      "\n",
      "1\n",
      "False\n",
      "\n",
      "\n",
      "0\n",
      "True\n",
      "True\n",
      "1\n",
      "Master\n",
      "1\n",
      "Produkte\n",
      "Mandau Universität\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "Bremen\n",
      "21010\n",
      "21\n",
      "Gironau Straße\n",
      "Baron\n",
      "21010\n",
      "210\n",
      "Gröpelingen\n",
      "True\n",
      "Br\n",
      "BL\n",
      "11282112\n",
      "1112008\n",
      "Bidazon\n",
      "Minoros\n",
      "Biaron\n",
      "Adminor\n",
      "Bo\n",
      "30403\n",
      "\n",
      "Oslo\n",
      "False\n",
      "\n",
      "\n",
      "3101985\n",
      "2\n",
      "swedisch\n",
      "1\n",
      "Obdachlosstr\n",
      "6\n",
      "\n",
      "Pokemon Trainer\n",
      "1\n",
      "Master\n",
      "True\n",
      "Ketchup\n",
      "Arschin\n",
      "Pikachu\n",
      "\n",
      "GER\n",
      "\n",
      "Karlsruhe Training Centre\n",
      "False\n",
      "\n",
      "\n",
      "Karlsruhe\n",
      "0\n",
      "Bremen\n",
      "28208\n",
      "GER\n",
      "Im Keller\n",
      "420\n",
      "\n",
      "\n",
      "False\n",
      "\n",
      "1\n",
      "0\n",
      "\n",
      "1\n",
      "Auberginestr\n",
      "True\n",
      "russisch\n",
      "\n",
      "\n",
      "\n",
      "7121995\n",
      "Nottingham\n",
      "True\n",
      "Doktor\n",
      "Philosophie\n",
      "1\n",
      "Freud\n",
      "Sigmund\n",
      "Universität Bremen\n",
      "Bob\n",
      "Maria\n",
      "23208\n",
      "Polen\n",
      "DE\n",
      "Kleinberg\n",
      "True\n",
      "Toujo\n",
      "\n",
      "1\n",
      "1\n",
      "100\n",
      "Kleinbergerstraße\n",
      "Deutscher\n",
      "Polin\n",
      "Bachelor\n",
      "Informatik\n",
      "Kleinberger Hochschule\n",
      "False\n",
      "\n",
      "1\n",
      "1\n",
      "\n",
      "False\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "False\n",
      "3031998\n",
      "\n",
      "\n",
      "1\n",
      "Deutscher\n",
      "Bachelor\n",
      "True\n",
      "False\n",
      "\n",
      "Tanjo\n",
      "\n",
      "Maria\n",
      "Polen\n",
      "\n",
      "\n",
      "1\n",
      "Polin\n",
      "2\n",
      "Kleinbergerstraße\n",
      "23208\n",
      "Weinberger Hochschule\n",
      "Informatik\n",
      "144\n",
      "DE\n",
      "Weinberg\n",
      "True\n",
      "London\n",
      "Sherlock\n",
      "Master\n",
      "True\n",
      "True\n",
      "Moriarty\n",
      "Holmes\n",
      "3\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "49328\n",
      "GER\n",
      "301\n",
      "Longjohnstr\n",
      "englisch\n",
      "englisch\n",
      "11111987\n",
      "London\n",
      "Detective\n",
      "London Universität\n",
      "\n",
      "\n",
      "\n",
      "Polin\n",
      "Deutscher\n",
      "Informatik\n",
      "Tanjo\n",
      "True\n",
      "Weinberg\n",
      "23208\n",
      "DE\n",
      "100\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "False\n",
      "False\n",
      "Weinbergerstraße\n",
      "Maria\n",
      "0\n",
      "\n",
      "1\n",
      "Weinberger Hochschule\n",
      "Bachelor\n",
      "Polen\n",
      "3031998\n",
      "2\n",
      "Peter\n",
      "Hochschule Dresden\n",
      "Master\n",
      "Demonology\n",
      "GER\n",
      "204\n",
      "Dämonstr\n",
      "Parker\n",
      "1\n",
      "0\n",
      "\n",
      "\n",
      "42066\n",
      "\n",
      "1\n",
      "deutsch\n",
      "Dresden\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "True\n",
      "False\n",
      "Spiderman\n",
      "Dresden\n",
      "False\n",
      "31052002\n",
      "\n",
      "DE\n",
      "\n",
      "1\n",
      "1\n",
      "0\n",
      "100\n",
      "3031998\n",
      "\n",
      "\n",
      "Polen\n",
      "\n",
      "\n",
      "\n",
      "False\n",
      "False\n",
      "\n",
      "\n",
      "Bachelor\n",
      "Weinberg\n",
      "23208\n",
      "Weinbergstrasse\n",
      "Deutscher\n",
      "Polin\n",
      "2\n",
      "Maria\n",
      "Taujo\n",
      "True\n",
      "Informatik\n",
      "Weinberger Hochschule\n",
      "BREMEN\n",
      "ELIZABETH\n",
      "UNIVERSITÄT BREMEN\n",
      "JOJO\n",
      "AMSTERDAM\n",
      "10011990\n",
      "28150\n",
      "\n",
      "deutsch\n",
      "True\n",
      "True\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "False\n",
      "\n",
      "STARK\n",
      "\n",
      "\n",
      "355\n",
      "\n",
      "deutsch\n",
      "BACHELOR\n",
      "1\n",
      "NEUSTADTERSTR\n",
      "50\n",
      "GER\n",
      "BIOLOGIE\n",
      "Polen\n",
      "\n",
      "3031998\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "Maria\n",
      "False\n",
      "Weinberg\n",
      "1\n",
      "Informatik\n",
      "Bachelor\n",
      "True\n",
      "\n",
      "Toujo\n",
      "1\n",
      "\n",
      "\n",
      "False\n",
      "DE\n",
      "100\n",
      "Weinbergstrasse\n",
      "Deutscher\n",
      "23208\n",
      "Weinberger Hochschule\n",
      "Polin\n",
      "2\n",
      "Naruto\n",
      "Uzumaki\n",
      "Konoha Academy\n",
      "Ninjutsu\n",
      "Master\n",
      "True\n",
      "Konoha\n",
      "89320\n",
      "GER\n",
      "Ninjastr\n",
      "japanisch\n",
      "japanisch\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "False\n",
      "25031999\n",
      "2\n",
      "Kyuubi\n",
      "True\n",
      "4\n",
      "\n",
      "\n",
      "Konoha\n",
      "\n",
      "1\n",
      "\n",
      "Polen\n",
      "1\n",
      "3031998\n",
      "2\n",
      "DE\n",
      "23208\n",
      "\n",
      "\n",
      "\n",
      "False\n",
      "False\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "1\n",
      "Weinberger Hochschule\n",
      "Informatik\n",
      "Weinber\n",
      "100\n",
      "Weinbergerstraße\n",
      "Deutscher\n",
      "Polin\n",
      "Maria\n",
      "Toujo\n",
      "True\n",
      "Bachelor\n",
      "Bremen\n",
      "Hochschule Bremen\n",
      "Mark\n",
      "Robert\n",
      "Potsdam\n",
      "5092001\n",
      "\n",
      "\n",
      "True\n",
      "deutsch\n",
      "\n",
      "1\n",
      "\n",
      "True\n",
      "Henry\n",
      "0\n",
      "\n",
      "\n",
      "1\n",
      "Medien Informatik\n",
      "False\n",
      "28320\n",
      "GER\n",
      "150\n",
      "Parkstraße\n",
      "1\n",
      "\n",
      "\n",
      "Bachelor\n",
      "\n",
      "\n",
      "False\n",
      "Polen\n",
      "3031998\n",
      "\n",
      "1\n",
      "Toujo\n",
      "maria\n",
      "2\n",
      "Weinbergstraße\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "False\n",
      "0\n",
      "\n",
      "\n",
      "Deutscher\n",
      "100\n",
      "DE\n",
      "23208\n",
      "Weinberg\n",
      "Weinberger Hochschule\n",
      "Informatik\n",
      "Bachelor\n",
      "True\n",
      "Polin\n",
      "True\n",
      "True\n",
      "Bachelor\n",
      "Fly Catcher\n",
      "Hochschule Ribbit\n",
      "Ponderberg\n",
      "48957\n",
      "GER\n",
      "39\n",
      "FROG\n",
      "\n",
      "\n",
      "5061996\n",
      "Amazon\n",
      "The\n",
      "Kermit\n",
      "\n",
      "False\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "1\n",
      "polisch\n",
      "1\n",
      "Pondstraße\n",
      "1\n",
      "\n",
      "\n",
      "False\n",
      "0\n",
      "False\n",
      "\n",
      "\n",
      "\n",
      "Polin\n",
      "2\n",
      "3031998\n",
      "1\n",
      "\n",
      "Polen\n",
      "Maria\n",
      "Toujo\n",
      "\n",
      "Deutscher\n",
      "Weinbergerstraße\n",
      "100\n",
      "DE\n",
      "\n",
      "Informatik\n",
      "Weinberger Hochschule\n",
      "Bachelor\n",
      "True\n",
      "23208\n",
      "Weinberg\n",
      "Bros\n",
      "Osnabrück\n",
      "13452\n",
      "GER\n",
      "12\n",
      "Mario\n",
      "False\n",
      "Master\n",
      "\n",
      "True\n",
      "itanlianisch\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Japan\n",
      "Super\n",
      "\n",
      "\n",
      "\n",
      "Trampoline Universität\n",
      "Springen\n",
      "1081987\n",
      "False\n",
      "1\n",
      "Pipestr\n",
      "0\n",
      "\n",
      "False\n",
      "\n",
      "\n",
      "3031998\n",
      "1\n",
      "\n",
      "2\n",
      "0\n",
      "Polin\n",
      "\n",
      "23208\n",
      "False\n",
      "\n",
      "1\n",
      "Weinberg\n",
      "\n",
      "\n",
      "\n",
      "Polen\n",
      "DE\n",
      "Bachelor\n",
      "Informatik\n",
      "kleinberger Hochschule\n",
      "Maria\n",
      "Deutscher\n",
      "100\n",
      "WeinbergerStr.\n",
      "True\n",
      "Toujo\n",
      "120\n",
      "23032000\n",
      "Denver\n",
      "kcao\n",
      "Bachelor\n",
      "Racing\n",
      "Universität Berlin\n",
      "1\n",
      "\n",
      "1\n",
      "False\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "Berlin\n",
      "53250\n",
      "GER\n",
      "Ferraristr\n",
      "amerikanisch\n",
      "3\n",
      "\n",
      "Lightning\n",
      "McKing\n",
      "True\n",
      "True\n",
      "\n",
      "Weinberger Hochschule\n",
      "Informatik\n",
      "Bachelor\n",
      "Toujo\n",
      "Weinbergerstrasse\n",
      "100\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "False\n",
      "1\n",
      "False\n",
      "23208\n",
      "DE\n",
      "False\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Maria\n",
      "Polen\n",
      "3031998\n",
      "2\n",
      "Polin\n",
      "Deutscher\n",
      "Bob\n",
      "13778\n",
      "Bachelor\n",
      "Informatik\n",
      "Leuchtenburg\n",
      "28779\n",
      "DE\n",
      "Tj\n",
      "Sponge\n",
      "\n",
      "Fachhochschule Bielefeld\n",
      "\n",
      "0\n",
      "False\n",
      "\n",
      "\n",
      "88\n",
      "Bikini Bottom\n",
      "False\n",
      "False\n",
      "Deutsch\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "8072000\n",
      "Bremen\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "False\n",
      "\n",
      "1\n",
      "1\n",
      "\n",
      "False\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "1\n",
      "True\n",
      "Fritz\n",
      "Deutsche\n",
      "Auf der Koppel\n",
      "23\n",
      "Steuern, Digitale Wirtschaft\n",
      "Oldenburg\n",
      "26121\n",
      "3031999\n",
      "Oldenburg\n",
      "Marina\n",
      "10.05.2025\n",
      "Jade Hochschule Oldenburg\n",
      "1041970\n",
      "Sponge\n",
      "Patrick\n",
      "Star\n",
      "787\n",
      "True\n",
      "Master\n",
      "Chemie\n",
      "Touro College Berlin\n",
      "USA\n",
      "77777\n",
      "Bikini Bottom\n",
      "778\n",
      "Bikini\n",
      "True\n",
      "Amerikanisch\n",
      "4\n",
      "Bottom\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "False\n",
      "\n",
      "\n",
      "\n",
      "Deutsch\n",
      "Kölner\n",
      "Bachelor\n",
      "28888\n",
      "Köln\n",
      "\n",
      "False\n",
      "1\n",
      "1\n",
      "DE\n",
      "False\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "3031977\n",
      "1\n",
      "False\n",
      "\n",
      "Köln\n",
      "Freie Universität Berlin\n",
      "Informatik\n",
      "Igor\n",
      "Martin\n",
      "778\n",
      "Kölner\n",
      "Bayern\n",
      "Biologie\n",
      "True\n",
      "Platz\n",
      "1\n",
      "DE\n",
      "28998\n",
      "Sascha\n",
      "Jens\n",
      "1\n",
      "1\n",
      "False\n",
      "\n",
      "1061999\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "Moskau\n",
      "Asimov\n",
      "Hertie School\n",
      "Bachelor\n",
      "True\n",
      "\n",
      "\n",
      "False\n",
      "DE\n",
      "28970\n",
      "Berlin\n",
      "\n",
      "False\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "Steinbeis Hochschule\n",
      "Sport\n",
      "Master\n",
      "True\n",
      "Lev\n",
      "Markus\n",
      "Leon\n",
      "\n",
      "1\n",
      "Bayern\n",
      "2081997\n",
      "Wakanda\n",
      "999\n",
      "Quadriga Hochschule Berlin\n",
      "Bachelor\n",
      "1\n",
      "Elektrotechnik\n",
      "True\n",
      "True\n",
      "7778765\n",
      "Markus\n",
      "\n",
      "Berlin\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Malte\n",
      "Gustaf\n",
      "Bemen\n",
      "Guten\n",
      "120\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "DE\n",
      "28779\n",
      "True\n",
      "1651960\n",
      "3\n",
      "3.08.2023\n",
      "Hotelfachmann\n",
      "Schulzentrum 28219 Bremen\n",
      "Weng\n",
      "13408967853210\n",
      "True\n",
      "Schwering\n",
      "Emily\n",
      "True\n",
      "\n",
      "\n",
      "Schwanewede\n",
      "28790\n",
      "9\n",
      "Puschkinstraße\n",
      "Deutsch\n",
      "24121999\n",
      "\n",
      "\n",
      "0\n",
      "1\n",
      "False\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "1\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "10051996\n",
      "\n",
      "Deutsche\n",
      "Hakenwehrstraße\n",
      "7\n",
      "28779\n",
      "Bremen\n",
      "1\n",
      "\n",
      "\n",
      "False\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "False\n",
      "1\n",
      "Berlin\n",
      "Marcus\n",
      "Kraft\n",
      "True\n",
      "Architektur\n",
      "Jade Hochschule Wihland\n",
      "Beckedorfstraße\n",
      "Elektrotechnik und Informatik\n",
      "Kevin\n",
      "Bremen\n",
      "22031998\n",
      "Deutsche\n",
      "17\n",
      "28790\n",
      "Beckedorf\n",
      "\n",
      "0\n",
      "True\n",
      "False\n",
      "1\n",
      "1\n",
      "\n",
      "False\n",
      "\n",
      "1\n",
      "Hochschule Bremen\n",
      "Krause\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "10.09.2024\n",
      "\n",
      "\n",
      "\n",
      "14051984\n",
      "False\n",
      "\n",
      "Amy\n",
      "Amy\n",
      "1\n",
      "USA\n",
      "\n",
      "1\n",
      "\n",
      "False\n",
      "Potsdam\n",
      "Koch\n",
      "Zuckerberg\n",
      "\n",
      "False\n",
      "1\n",
      "Mark\n",
      "\n",
      "0\n",
      "\n",
      "New York\n",
      "\n",
      "\n",
      "1\n",
      "Kalifornien\n",
      "Hacker Way\n",
      "94025\n",
      "Funker\n",
      "True\n",
      "True\n",
      "Kassel\n",
      "121314752741397\n",
      "7\n",
      "Kassel\n",
      "True\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "Nebraska\n",
      "Senator str\n",
      "\n",
      "\n",
      "USA\n",
      "\n",
      "Warren\n",
      "Buffet\n",
      "Ohama\n",
      "\n",
      "Amy\n",
      "1\n",
      "30081930\n",
      "50735\n",
      "94043\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "False\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "False\n",
      "California\n",
      "USA\n",
      "2\n",
      "Berlin\n",
      "Model\n",
      "Brin\n",
      "Sergej\n",
      "21081973\n",
      "5\n",
      "Ruski\n",
      "True\n",
      "Amphitheatre Parkway\n",
      "True\n",
      "2\n",
      "28101995\n",
      "Seatle\n",
      "Bill\n",
      "Gates\n",
      "123456789001001\n",
      "Stuttgart\n",
      "Amy\n",
      "\n",
      "Amy\n",
      "\n",
      "True\n",
      "Kellner\n",
      "\n",
      "\n",
      "Redmond Woods\n",
      "\n",
      "Stuttgart\n",
      "\n",
      "1\n",
      "0\n",
      "148th Ave NE\n",
      "98052\n",
      "USA\n",
      "\n",
      "\n",
      "14\n",
      "True\n",
      "False\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "1\n",
      "\n",
      "Manager\n",
      "Amy\n",
      "Amy\n",
      "True\n",
      "148th Ave NE\n",
      "14\n",
      "USA\n",
      "98052\n",
      "Redmond Woods\n",
      "2\n",
      "24031956\n",
      "Detroid\n",
      "Steve\n",
      "Ballmer\n",
      "True\n",
      "Köln\n",
      "Michigan\n",
      "0\n",
      "\n",
      "1\n",
      "Wismar\n",
      "True\n",
      "Page\n",
      "Larry\n",
      "\n",
      "26031973\n",
      "Amy\n",
      "Amy\n",
      "True\n",
      "Amphitheatre Parkway\n",
      "7\n",
      "Junker\n",
      "False\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "USA\n",
      "24043\n",
      "California\n",
      "\n",
      "\n",
      "28271\n",
      "\n",
      "5\n",
      "Austin\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "17071944\n",
      "Larry\n",
      "Cloud Way\n",
      "1\n",
      "2300\n",
      "False\n",
      "\n",
      "0\n",
      "USA\n",
      "\n",
      "New York\n",
      "\n",
      "False\n",
      "Berlin\n",
      "Ellison\n",
      "True\n",
      "Gas, Wasser,...\n",
      "Schwabingen\n",
      "Karlsruhe\n",
      "informatiker\n",
      "True\n",
      "80538\n",
      "\n",
      "\n",
      "New Mexiko\n",
      "2\n",
      "12011964\n",
      "Albuqerque\n",
      "Jeff\n",
      "Bezos\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Amy\n",
      "True\n",
      "\n",
      "\n",
      "Parkstraße\n",
      "0\n",
      "1\n",
      "1\n",
      "37\n",
      "7\n",
      "DE\n",
      "False\n",
      "\n",
      "Raubix\n",
      "\n",
      "True\n",
      "True\n",
      "Automatisierer\n",
      "Rernard\n",
      "\n",
      "5031949\n",
      "Jeff\n",
      "0\n",
      "München\n",
      "False\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "1\n",
      "Köln\n",
      "1\n",
      "Arnault\n",
      "8\n",
      "München\n",
      "Ger\n",
      "Franzose\n",
      "Leopold str\n",
      "80802\n",
      "Berlin\n",
      "Düsseldorf\n",
      "\n",
      "König\n",
      "\n",
      "True\n",
      "Musk\n",
      "Elon\n",
      "Pretoria\n",
      "28061971\n",
      "2\n",
      "Afrika\n",
      "True\n",
      "Ludwig-Prundte\n",
      "27\n",
      "Ger\n",
      "12526\n",
      "\n",
      "1\n",
      "\n",
      "0\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "False\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "False\n",
      "\n",
      "\n",
      "Musterstadt\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "0\n",
      "\n",
      "\n",
      "Fakeort\n",
      "Bachelor\n",
      "Technische Universität\n",
      "Maschinenbau\n",
      "True\n",
      "12345678910\n",
      "Mülle\n",
      "Max\n",
      "1011995\n",
      "Deutsch\n",
      "Deutsch\n",
      "True\n",
      "Hauptstraße\n",
      "42\n",
      "Deutschland\n",
      "True\n",
      "Doktor\n",
      "Deutsch\n",
      "\n",
      "True\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "Laura\n",
      "Fischer\n",
      "\n",
      "789123\n",
      "Behörde\n",
      "BetriebswirtschaftslehrBetriebswirtschaftslehre\n",
      "IW Globalstadt\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "0\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "10101990\n",
      "Handelsburg\n",
      "Becker\n",
      "False\n",
      "\n",
      "False\n",
      "Deutsch\n",
      "1041990\n",
      "Phantasia\n",
      "Clara\n",
      "Schmidt\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "456874678910112\n",
      "\n",
      "\n",
      "1\n",
      "True\n",
      "True\n",
      "Fotografie\n",
      "Art Akademie Hamburg\n",
      "Master\n",
      "Jonas\n",
      "Fantasiewelt\n",
      "15051995\n",
      "Deutsch\n",
      "Abenteuerweg\n",
      "DE\n",
      "33\n",
      "67890\n",
      "Fantasiewelt\n",
      "Maschinenbau\n",
      "Bachelor\n",
      "True\n",
      "True\n",
      "Weber\n",
      "False\n",
      "1\n",
      "\n",
      "Hochschule Berlin\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "1\n",
      "Fischer\n",
      "\n",
      "0\n",
      "False\n",
      "\n",
      "\n",
      "Studio 2\n",
      "10\n",
      "Kreativallee\n",
      "45678\n",
      "HE\n",
      "5\n",
      "Blumenweg\n",
      "Deutsch\n",
      "2031992\n",
      "Musterstadt\n",
      "Lena\n",
      "Bauer\n",
      "12345\n",
      "Farbenstadt büro\n",
      "True\n",
      "True\n",
      "1\n",
      "Bachelor\n",
      "1\n",
      "Universität Farbenstadt\n",
      "Farbenstadt\n",
      "98765\n",
      "Grafikdesign\n",
      "David\n",
      "Institut Forschungsstadt\n",
      "Umweltwissenschaften\n",
      "True\n",
      "Behörde\n",
      "65432\n",
      "Neumann\n",
      "Klein\n",
      "Grüntal\n",
      "False\n",
      "20\n",
      "Doktor\n",
      "8081988\n",
      "Deutsch\n",
      "True\n",
      "Waldpfad\n",
      "\n",
      "\n",
      "Forscherweg\n",
      "0\n",
      "12\n",
      "ID\n",
      "12321\n",
      "Grüntal\n",
      "1\n",
      "Forschungsstadt\n",
      "32123\n",
      "\n",
      "1\n",
      "\n",
      "False\n",
      "1\n",
      "False\n",
      "\n",
      "1\n",
      "\n",
      "0\n",
      "Hochschule Bau\n",
      "Architektur\n",
      "Diplom\n",
      "True\n",
      "Amt\n",
      "87654\n",
      "Zimmermann\n",
      "Sarah\n",
      "Weber\n",
      "Himmelsdorf\n",
      "16071994\n",
      "Deutsch\n",
      "Blütenstraße\n",
      "22\n",
      "VI\n",
      "55678\n",
      "Himmelsdorf\n",
      "87655\n",
      "Konstruktionsstadt\n",
      "5\n",
      "Planerallee\n",
      "Richter\n",
      "Behörde\n",
      "32198\n",
      "Felix\n",
      "Lehmann\n",
      "Bergdorf\n",
      "9091989\n",
      "Deutsch\n",
      "Österreichisch\n",
      "True\n",
      "Med Fakultät\n",
      "Allgemeinmedizin\n",
      "Doktor\n",
      "True\n",
      "True\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "0\n",
      "1\n",
      "\n",
      "\n",
      "False\n",
      "Schmidt\n",
      "Buchhausen\n",
      "14021991\n",
      "\n",
      "1\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "False\n",
      "\n",
      "\n",
      "\n",
      "Wagner\n",
      "Emily\n",
      "56789\n",
      "Literaturwissenschaft\n",
      "Uni Kulturstadt\n",
      "Deutsch\n",
      "Behörde\n",
      "Doktor\n",
      "True\n",
      "Master of Science\n",
      "TU Berlin\n",
      "Deutsch\n",
      "21061993\n",
      "Oliver\n",
      "Digitalien\n",
      "Neumann\n",
      "Informatik\n",
      "\n",
      "\n",
      "654321\n",
      "\n",
      "\n",
      "True\n",
      "\n",
      "Schwarz\n",
      "False\n",
      "1\n",
      "\n",
      "\n",
      "1\n",
      "True\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "Amt\n",
      "0\n",
      "1\n",
      "\n",
      "\n",
      "1\n",
      "Bremen\n",
      "28219\n",
      "\n",
      "\n",
      "282\n",
      "Stader Str.\n",
      "Deutsch\n",
      "5082004\n",
      "Delmenhorst\n",
      "Peter\n",
      "Peterson\n",
      "True\n",
      "Kaufmann\n",
      "Biemen\n",
      "\n",
      "\n",
      "False\n",
      "False\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "0\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "False\n",
      "\n",
      "False\n",
      "\n",
      "GER\n",
      "Hohentor Universität\n",
      "Informatik\n",
      "Master\n",
      "True\n",
      "Max\n",
      "Max\n",
      "Max\n",
      "Maxstadt\n",
      "1012000\n",
      "DE\n",
      "Maxstraße\n",
      "5\n",
      "57312\n",
      "München\n",
      "Harvard\n",
      "deutsch\n",
      "Main Street\n",
      "7\n",
      "USA\n",
      "31057\n",
      "Boston\n",
      "\n",
      "\n",
      "Boston\n",
      "31061983\n",
      "Computer\n",
      "Bachelor\n",
      "\n",
      "\n",
      "False\n",
      "False\n",
      "1\n",
      "\n",
      "\n",
      "1\n",
      "True\n",
      "356\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Zuckerberg\n",
      "Mark\n",
      "555333678955000\n",
      "Bremeramt\n",
      "Deutsch\n",
      "Master of language\n",
      "True\n",
      "False\n",
      "\n",
      "\n",
      "Hannover\n",
      "0\n",
      "\n",
      "\n",
      "53210\n",
      "POL\n",
      "1032004\n",
      "Bremen\n",
      "Meyer\n",
      "Müller\n",
      "Denis\n",
      "\n",
      "\n",
      "12\n",
      "Karl-Marx-Weg\n",
      "TH Hannover\n",
      "1052018\n",
      "2\n",
      "deutsch\n",
      "polnisch\n",
      "True\n",
      "25319\n",
      "Wizard Master\n",
      "True\n",
      "Harry\n",
      "True\n",
      "Der Weg\n",
      "33\n",
      "NL\n",
      "Amsterdam\n",
      "kroatisch\n",
      "False\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "1\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "Wizard School Hogwarts\n",
      "Magic Potions\n",
      "Potter\n",
      "Lars\n",
      "Berlin\n",
      "12122003\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "Wolfgang\n",
      "Johann\n",
      "Goethe\n",
      "False\n",
      "False\n",
      "\n",
      "\n",
      "Hochschule Hamburg\n",
      "Mathe\n",
      "Bachelor\n",
      "\n",
      "Berlin\n",
      "\n",
      "\n",
      "1\n",
      "1\n",
      "False\n",
      "1\n",
      "\n",
      "29531\n",
      "10101955\n",
      "deutsch\n",
      "Hamburger Weg\n",
      "5\n",
      "GER\n",
      "Hamburg\n",
      "Stege\n",
      "\n",
      "356\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Universität Leipzig\n",
      "Chemie\n",
      "Master\n",
      "True\n",
      "Max\n",
      "Leipzig\n",
      "1012001\n",
      "polnisch\n",
      "Leipzig Straße\n",
      "3\n",
      "GER\n",
      "29317\n",
      "Leipzig\n",
      "1\n",
      "False\n",
      "\n",
      "False\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "Chicago\n",
      "Master of Science\n",
      "\n",
      "\n",
      "False\n",
      "Computer Engineering\n",
      "State University Chicago\n",
      "deutsch\n",
      "Street 2nd\n",
      "True\n",
      "57310\n",
      "Bremen\n",
      "1\n",
      "Bo\n",
      "\n",
      "Tim\n",
      "USA\n",
      "5\n",
      "\n",
      "1\n",
      "12122003\n",
      "False\n",
      "1\n",
      "\n",
      "354\n",
      "Bo\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "False\n",
      "False\n",
      "\n",
      "Monobachelor\n",
      "Lehramt\n",
      "Universität Heidelberg\n",
      "\n",
      "0\n",
      "\n",
      "1\n",
      "1\n",
      "\n",
      "\n",
      "Heidelberg\n",
      "True\n",
      "Blumen\n",
      "Julia\n",
      "Blumen\n",
      "3032005\n",
      "deutsch\n",
      "Friedrich Straße\n",
      "3\n",
      "GER\n",
      "10135\n",
      "Heidelberg\n",
      "Freiburg\n",
      "Hochschule Albert\n",
      "Soziale Arbeit\n",
      "Bachelor\n",
      "True\n",
      "Smith\n",
      "Luisa\n",
      "Smith\n",
      "New York\n",
      "29052000\n",
      "deutsch\n",
      "Friedensweg\n",
      "5\n",
      "GER\n",
      "79085\n",
      "1\n",
      "\n",
      "\n",
      "False\n",
      "\n",
      "False\n",
      "1\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "0\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "False\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "False\n",
      "GER\n",
      "FH Berlin\n",
      "Informatik\n",
      "Bachelor\n",
      "Mark\n",
      "Max\n",
      "Berlin\n",
      "Berlin\n",
      "30111999\n",
      "deutsch\n",
      "True\n",
      "Karl Straße\n",
      "5\n",
      "51350\n",
      "Bremen\n",
      "True\n",
      "deutsch\n",
      "2\n",
      "14022001\n",
      "Joachim\n",
      "Jochen\n",
      "123456789101112\n",
      "kleines Amt\n",
      "True\n",
      "Bachelor of Science\n",
      "Informatik\n",
      "Hochschule Bremen\n",
      "12\n",
      "DE\n",
      "28757\n",
      "Bremen\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "False\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "Kuhdamm\n",
      "False\n",
      "1\n",
      "\n",
      "Universität Lübeck\n",
      "Data Science\n",
      "Bachelor of Science\n",
      "True\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "False\n",
      "1\n",
      "\n",
      "\n",
      "Kiel\n",
      "Birne\n",
      "Svenja\n",
      "Apfel\n",
      "123456789012345\n",
      "5061999\n",
      "deutsch\n",
      "Hamurg\n",
      "Schnelle Staße\n",
      "67\n",
      "a\n",
      "DE\n",
      "12\n",
      "Verden\n",
      "12345\n",
      "1\n",
      "False\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "False\n",
      "\n",
      "\n",
      "Universität Bremen\n",
      "Medieninformatik\n",
      "Bachelor of Arts\n",
      "True\n",
      "Beil\n",
      "Helga\n",
      "Axt\n",
      "Lübeck\n",
      "2021980\n",
      "deutsch\n",
      "Baumallee\n",
      "1\n",
      "DE\n",
      "1\n",
      "Bremer Str.\n",
      "1\n",
      "28203\n",
      "Bremen\n",
      "1\n",
      "\n",
      "Hochschule Hannover\n",
      "Technische Informatik\n",
      "Bachelor of Science\n",
      "True\n",
      "True\n",
      "Dezernat 1\n",
      "1123411925300\n",
      "Thorsten\n",
      "Thomas\n",
      "Lübeck\n",
      "5121980\n",
      "5\n",
      "französisch\n",
      "italientisch\n",
      "True\n",
      "Lange Str.\n",
      "50\n",
      "a\n",
      "DE\n",
      "12333\n",
      "Wels\n",
      "3560\n",
      "52\n",
      "Bremen\n",
      "1\n",
      "0\n",
      "\n",
      "Kurze Str.\n",
      "Hochschule Hamburg\n",
      "Elektrotechnik\n",
      "Bachelor of Engineering\n",
      "Haus\n",
      "Anne\n",
      "München\n",
      "30101999\n",
      "deutsch\n",
      "Mittelstraße\n",
      "1\n",
      "b\n",
      "DE\n",
      "Verden\n",
      "22305\n",
      "\n",
      "\n",
      "False\n",
      "False\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "False\n",
      "1\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "False\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "1\n",
      "1\n",
      "\n",
      "Bachelor of Engineering\n",
      "Halle\n",
      "33650\n",
      "DE\n",
      "5\n",
      "Spitze Staße\n",
      "polnisch\n",
      "11112011\n",
      "Kiel\n",
      "Zack\n",
      "Elke\n",
      "Zarrath\n",
      "True\n",
      "True\n",
      "Mathematik\n",
      "Universität Hamburg\n",
      "Bermerhaven\n",
      "True\n",
      "12032005\n",
      "z\n",
      "5\n",
      "deutsch\n",
      "DE\n",
      "51234\n",
      "Bremen\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RTW Aachen\n",
      "Maschinenbau\n",
      "Bachelor of Engineering\n",
      "True\n",
      "Tisch\n",
      "Jasmin\n",
      "Stuhl\n",
      "Enge Staße\n",
      "54\n",
      "1\n",
      "1\n",
      "\n",
      "0\n",
      "\n",
      "False\n",
      "\n",
      "Berlin\n",
      "77\n",
      "Hohe Staße\n",
      "\n",
      "1\n",
      "\n",
      "True\n",
      "Jens\n",
      "Teller\n",
      "1\n",
      "0\n",
      "\n",
      "198760234102365\n",
      "Amt Sachsen\n",
      "\n",
      "True\n",
      "\n",
      "True\n",
      "Bachelor of Arts\n",
      "\n",
      "Universität Berlin\n",
      "BetriebswirtschaftslehrBetriebswirtschaftslehre\n",
      "Berlin\n",
      "521917\n",
      "deutsch\n",
      "deutsch\n",
      "b\n",
      "DE\n",
      "15209\n",
      "Bremen\n",
      "True\n",
      "Knopf\n",
      "Hannes\n",
      "111991\n",
      "16705\n",
      "\n",
      "0\n",
      "1\n",
      "DE\n",
      "1\n",
      "Flache Staße\n",
      "deutsch\n",
      "Master of Science\n",
      "False\n",
      "\n",
      "Mechatronik\n",
      "Hochschule Bremerhaven\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "False\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "1\n",
      "\n",
      "\n",
      "Karsten\n",
      "Kupfer\n",
      "Hamburg\n",
      "\n",
      "\n",
      "10101990\n",
      "0\n",
      "\n",
      "deutsch\n",
      "False\n",
      "\n",
      "False\n",
      "\n",
      "\n",
      "1\n",
      "55212\n",
      "Hamburg\n",
      "Universität Kiel\n",
      "Tiefe Staße\n",
      "3001\n",
      "DE\n",
      "Stahl\n",
      "True\n",
      "Master of Science\n",
      "Energietechnik\n"
     ]
    }
   ],
   "source": [
    "# Crop ROI\n",
    "save_path_crops = \"data_zettel/cropped_images\"\n",
    "\n",
    "import cv2\n",
    "def crop(xmin, ymin, xmax, ymax, image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    xmin = int(round(xmin))\n",
    "    ymin = int(round(ymin))\n",
    "    xmax = int(round(xmax))\n",
    "    ymax = int(round(ymax))\n",
    "    imgCropped = image[ymin:ymax, xmin:xmax]\n",
    "    return imgCropped\n",
    "\n",
    "\n",
    "for index, image in enumerate(image_list):\n",
    "    boxes = image.boxes\n",
    "    for i, box in enumerate(boxes):\n",
    "        xmin, ymin, xmax, ymax = np.array(box)\n",
    "        imgCropped = crop(xmin, ymin, xmax, ymax, image.path)\n",
    "        cv2.imwrite(f\"{save_path_crops}/{index}_{i}.jpg\", imgCropped)\n",
    "        with open(f\"{save_path_crops}/{index}_{i}.txt\", 'w') as file:\n",
    "            print(image.values[i])\n",
    "            file.write(image.values[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc51121e5bd01e2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Handwriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617741a46be8f4e3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unsere Klassen\n",
    "import handwriting.load_data as load_data\n",
    "import handwriting.preprocess as preprocess\n",
    "import handwriting.testing_models as testing_models # Use: build_model9v3(img_width, img_height, char) \n",
    "import utils.configs as Config\n",
    "#Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d912de093664402a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cafc2f961d6b8d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config_path = \"utils/configs.json\"\n",
    "config = Config.Config(config_path)\n",
    "\n",
    "# Model Parameter\n",
    "MODEL_SAVE = bool(config.get_model_parameter()[\"save\"])\n",
    "MODEL_NAME = config.get_model_parameter()[\"name\"]\n",
    "IMAGE_WIDTH = config.get_model_parameter()[\"width\"] # default: 1024\n",
    "IMAGE_HEIGHT = config.get_model_parameter()[\"height\"] # default: 64\n",
    "\n",
    "# Directory Parameter\n",
    "MODEL_DIR_NAME = pathlib.Path(os.getcwd()).joinpath(config.get_directory_parameter()[\"model_dir\"])\n",
    "TEST_RESULT_DIR_NAME = pathlib.Path(os.getcwd()).joinpath(config.get_directory_parameter()[\"test_dir\"])\n",
    "DATA_BASE_PATH = config.get_directory_parameter()[\"data_base_path\"]\n",
    "\n",
    "# Training Parameter\n",
    "SAVE_HISTORY = bool(config.get_training_parameter()[\"save_history\"])\n",
    "EPOCHS = config.get_training_parameter()[\"epochs\"]\n",
    "BATCH_SIZE = config.get_training_parameter()[\"batch_size\"] # default: 32 - 48\n",
    "TF_SEED = config.get_training_parameter()[\"tf_seed\"] # default: 42\n",
    "LEARNING_RATE = config.get_training_parameter()[\"learning_rate\"]\n",
    "PATIENCE = config.get_training_parameter()[\"patience\"] # default: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50ebf19d620853",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be0da09e6b20c3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Default: seed = 42\n",
    "# np.random.seed(TF_SEED)\n",
    "# tf.random.set_seed(TF_SEED)\n",
    "\n",
    "# Random\n",
    "#seed = random.randint(1, 1000)\n",
    "#np.random.seed(seed)\n",
    "#tf.random.set_seed(seed)\n",
    "print(LEARNING_RATE)\n",
    "print(TF_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e96e3bacfefa84",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load_data.print_samples(DATA_BASE_PATH)\n",
    "if False: # IAM Dataset\n",
    "    x_train_img_paths, y_train_labels = load_data.get_train_data()\n",
    "    x_val_img_paths, y_val_labels = load_data.get_validation_data()\n",
    "    #x_test_img_paths, y_test_labels = load_data.get_test_data()\n",
    "    \n",
    "#TODO\n",
    "# need  x_train_img_paths, y_train_labels =\n",
    "#       x_val_img_paths, y_val_labels =\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc94188289acd0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f\"Training path: {x_train_img_paths[0:2]}\", y_train_labels[0:2])\n",
    "print(f\"Validation path: {x_val_img_paths[0:2]}\", y_val_labels[0:2])\n",
    "#print(f\"Testing path: {x_test_img_paths[0:2]}\", y_test_labels[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d396ce20431c83",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c72e5da9634ba",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Has to be here because load data functions need to be called before\n",
    "import handwriting.tokenizer as tokenizer\n",
    "import handwriting.custom_image_generator as cgi\n",
    "\n",
    "# takes eternity\n",
    "#x_train, y_train = tokenizer.prepare_data(x_train_img_paths, y_train_labels) \n",
    "#x_test, y_test = tokenizer.prepare_data(x_test_img_paths, y_test_labels)\n",
    "\n",
    "#train_generator = cgi.CustomImageGenerator(x_train_img_paths, y_train_labels, BATCH_SIZE, IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "\n",
    "train_ds = tokenizer.prepare_dataset(x_train_img_paths, y_train_labels, (IMAGE_WIDTH,IMAGE_HEIGHT),BATCH_SIZE)\n",
    "val_ds = tokenizer.prepare_dataset(x_val_img_paths, y_val_labels,(IMAGE_WIDTH,IMAGE_HEIGHT),BATCH_SIZE)\n",
    "#test_ds = tokenizer.prepare_dataset(x_test_img_paths, y_test_labels,(IMAGE_WIDTH,IMAGE_HEIGHT),BATCH_SIZE)\n",
    "#aug_train_ds = tokenizer.prepare_augmented_dataset(x_train_img_paths, y_train_labels, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5267aa06119792c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Show Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1843d431baf541",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for data in train_ds.take(1):\n",
    "    images, labels = data[\"image\"], data[\"label\"]\n",
    "\n",
    "    ax = plt.subplots(4, 4, figsize=(32, 8))[1]\n",
    "\n",
    "    for i in range(16):\n",
    "        img = images[i]\n",
    "        img = tf.image.flip_left_right(img)\n",
    "        img = tf.transpose(img, perm=[1, 0, 2])\n",
    "        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n",
    "        img = img[:, :, 0]\n",
    "\n",
    "        # Gather indices where label!= padding_token.\n",
    "        label = labels[i]\n",
    "        indices = tf.gather(label, tf.where(tf.math.not_equal(label, tokenizer.padding_token)))\n",
    "        # Convert to string.\n",
    "        label = tf.strings.reduce_join(tokenizer.num_to_char(indices))\n",
    "        label = label.numpy().decode(\"utf-8\")\n",
    "\n",
    "        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
    "        ax[i // 4, i % 4].set_title(label)\n",
    "        ax[i // 4, i % 4].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a37a927a1a58b2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d0b142ed5b54cf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To see the augmentations from CustomImageGenerator\n",
    "train_generator = cgi.CustomImageGenerator(x_train_img_paths, y_train_labels, tokenizer.batch_size, IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "\n",
    "example_batch = train_generator[0]\n",
    "augmented_images = example_batch[0]['image']\n",
    "\n",
    "num_to_plot = 4\n",
    "fig, axes = plt.subplots(1, num_to_plot, figsize=(10, 10))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(np.squeeze(augmented_images[i]), cmap='gray')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322476a450778bc6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomBrightness(0.5,value_range=(0, 1), seed=TF_SEED),\n",
    "        tf.keras.layers.RandomContrast(0.5,seed=TF_SEED)\n",
    "    ]\n",
    ")\n",
    "\n",
    "for data in train_ds.take(1):\n",
    "    images, labels = data[\"image\"], data[\"label\"]\n",
    "\n",
    "# Display the original image\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(images[0].numpy(), cmap='gray', vmin=0, vmax=1)\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "# Apply data augmentation to the image\n",
    "augmented_images = data_augmentation(images, training=True)\n",
    "\n",
    "# Display the augmented images\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 4, i + 2)\n",
    "    plt.imshow(augmented_images[i].numpy(), cmap='gray', vmin=0, vmax=1)\n",
    "    plt.title(f\"Augmented Image {i+1}\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de342f6f643d2f8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9c9f0a326f83ce",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_keras_string =\"_weights.keras\"\n",
    "\n",
    "def model_load_weights_if_exists(model):\n",
    "    MODEL_MODEL_PATH = MODEL_NAME\n",
    "    MODEL_WEIGHT_PATH = MODEL_NAME + weights_keras_string\n",
    "    model_path = os.path.join(MODEL_DIR_NAME, MODEL_MODEL_PATH)\n",
    "    model_weight_path = os.path.join(model_path, MODEL_WEIGHT_PATH)\n",
    "    print(model_path)\n",
    "    if os.path.exists(model_path):\n",
    "        print(\"Resuming Training where we left off!\")\n",
    "        model.load_weights(model_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678df9fcdf15f347",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    model_load_weights_if_exists(model)\n",
    "        \n",
    "    prediction_model = keras.models.Model(model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output)\n",
    "    # checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "    early_stopping = EarlyStopping(patience=PATIENCE, restore_best_weights=True)\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=PATIENCE * 0.2, min_lr=1e-6, verbose=1)\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=[reduce_lr, early_stopping])    \n",
    "    return prediction_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ef162ef12836ce",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Default\n",
    "# model = testing_models.build_model_default(IMAGE_WIDTH, IMAGE_HEIGHT, char, MODEL_NAME)\n",
    "\n",
    "char = len(tokenizer.char_to_num.get_vocabulary())\n",
    "model = testing_models.build_model9v3_random(IMAGE_WIDTH, IMAGE_HEIGHT, char, LEARNING_RATE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9ce7165e15a145",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "prediction_model, history = train_model(model)\n",
    "\n",
    "total_duration = time.time() - start_time\n",
    "print(\"Gesamte Trainingsdauer: {time}s\".format(time=round(total_duration)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc27d01fe397042",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Plot helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e443bfc89b1a8fea",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_history(history, name, dir_path, save_fig):\n",
    "    \"\"\"\n",
    "    Plottet die Historie des Trainings eines Models und speichert die in einem Verzeichnis ab \n",
    "\n",
    "    :param history: Das trainierte Modell\n",
    "    :param name: Name, wie das Modell gespeicht werden soll\n",
    "    :param name: Verzeichniss, wo der Plot gespeichert weren soll\n",
    "    :return: void\n",
    "    \"\"\"\n",
    "    metrics = history.history\n",
    "    _, ax1 = plt.subplots()\n",
    "\n",
    "    # Plot für Trainings- und Validierungsverluste\n",
    "    ax1.plot(metrics['loss'], label='Training Loss', color='blue')\n",
    "    ax1.plot(metrics['val_loss'], label='Validation Loss', color='red')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss', color='black')\n",
    "    ax1.tick_params('y', colors='black')\n",
    "    ax1.legend(loc='upper left', bbox_to_anchor=(0.0, 0.95))  \n",
    "\n",
    "    # Zweite Y-Achse für die Lernrate\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(metrics['lr'], label='Learning Rate', color='green')\n",
    "    ax2.set_ylabel('Learning Rate', color='black')\n",
    "    \n",
    "    ax2.set_yscale('log')  # Verwende logarithmische Skala für die Lernrate\n",
    "    \n",
    "    ax2.tick_params('y', colors='black')\n",
    "    ax2.yaxis.set_major_formatter(StrMethodFormatter('{x:1.0e}'))\n",
    "    ax2.legend(loc='upper right', bbox_to_anchor=(1.0, 0.95))  \n",
    "    \n",
    "    if save_fig:\n",
    "        plt.title('Name: '+name)\n",
    "        path = os.path.join(dir_path, name + '_history.png')\n",
    "        plt.savefig(path)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2d89800205cdc0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_dir(path_to_dir):\n",
    "    isExist = os.path.exists(path_to_dir)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_to_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c285abdfcc81c8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A utility function to decode the output of the network.\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    # Use greedy search. For complex tasks, you can use beam search.\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][:, :load_data.max_len]\n",
    "    # Iterate over the results and get back the text.\n",
    "    output_text = []\n",
    "    for res in results:\n",
    "        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n",
    "        res = tf.strings.reduce_join(tokenizer.num_to_char(res)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(res)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e2678f21bfbbb9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_evaluation(name, dir_path, save_fig):\n",
    "    for batch in test_ds.take(1):\n",
    "        batch_images = batch[\"image\"]\n",
    "        _, ax = plt.subplots(4, 4, figsize=(32, 8))\n",
    "\n",
    "        preds = prediction_model.predict(batch_images)\n",
    "        pred_texts = decode_batch_predictions(preds)\n",
    "\n",
    "        for i in range(16):\n",
    "            img = batch_images[i]\n",
    "            img = tf.image.flip_left_right(img)\n",
    "            img = tf.transpose(img, perm=[1, 0, 2])\n",
    "            img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n",
    "            img = img[:, :, 0]\n",
    "\n",
    "            title = f\"Prediction: {pred_texts[i]}\"\n",
    "            ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
    "            ax[i // 4, i % 4].set_title(title)\n",
    "            ax[i // 4, i % 4].axis(\"off\")   \n",
    "    if save_fig:\n",
    "        path = os.path.join(dir_path, name + '_result.png')\n",
    "        plt.savefig(path)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46158f62a4aac633",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d958dca138b01f54",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_new_plot_name(model_name, names, format):\n",
    "    import re\n",
    "    pattern = r\"\\d+\"\n",
    "    max_number = 0\n",
    "    for name in names:\n",
    "        tmp_name = name.replace(model_name,\"\")\n",
    "        number = int(re.findall(pattern,tmp_name)[0])\n",
    "        if number > max_number:\n",
    "            max_number = number\n",
    "            \n",
    "    new_model_name = model_name + \"V_\" + str(max_number + 1)\n",
    "    return format.replace(model_name,new_model_name)\n",
    "        \n",
    "if not os.path.exists(TEST_RESULT_DIR_NAME):\n",
    "            create_dir(TEST_RESULT_DIR_NAME)\n",
    "files_with_model_name = [file for file in os.listdir(TEST_RESULT_DIR_NAME) if MODEL_NAME in file]\n",
    "metrics = history.history\n",
    "\n",
    "NAME = \"{name}_{epoch}E_{height}H_{width}W_{loss}L_{val_loss}VL_{time}s\".format(\n",
    "    name=MODEL_NAME, epoch=history.epoch[-1], height=IMAGE_HEIGHT, width=IMAGE_WIDTH,\n",
    "    loss=round(metrics['loss'][-1],2), val_loss=round(metrics['val_loss'][-1], 2), time=round(total_duration))\n",
    "\n",
    "if not files_with_model_name:\n",
    "    if SAVE_HISTORY:\n",
    "        plot_history(history, NAME, TEST_RESULT_DIR_NAME, True)\n",
    "        plot_evaluation(NAME, TEST_RESULT_DIR_NAME, True)\n",
    "else:\n",
    "    new_name = create_new_plot_name(MODEL_NAME,files_with_model_name, NAME)\n",
    "    plot_history(history, new_name, TEST_RESULT_DIR_NAME, True)\n",
    "    plot_evaluation(new_name, TEST_RESULT_DIR_NAME, True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e38b9c0b0ad1538",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde914d352e2192",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODEL_SAVE:\n",
    "    if not os.path.exists(MODEL_DIR_NAME):\n",
    "        create_dir(MODEL_DIR_NAME)\n",
    "    model_path = os.path.join(MODEL_DIR_NAME, \"{model_name}\".format(model_name=MODEL_NAME))\n",
    "    model.save(model_path)\n",
    "    model.save_weights(os.path.join(model_path, f\"{MODEL_NAME}{weights_keras_string}\"), overwrite=True, save_format=None, options=None)\n",
    "    json_string = model.to_json()\n",
    "\n",
    "    with open(os.path.join(model_path, f\"{MODEL_NAME}.json\"),'w') as f:\n",
    "        f.write(json_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bdeface7466e95",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28498a62598e4bb8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
